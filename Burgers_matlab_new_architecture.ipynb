{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.7.6-final"
    },
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Burgers_matlab_new_architecture.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayem-eee-kuet/pinn-research/blob/master/Burgers_matlab_new_architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0JA8VImDOoR",
        "outputId": "89bdaa40-f1ff-4f95-ca87-5f7d4897f8e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install --upgrade pyDOE\n",
        "# !sudo apt-get install texlive-latex-recommended \n",
        "# !sudo apt install texlive-latex-extra\n",
        "# !sudo apt install dvipng\n",
        "# !sudo apt-get install texlive-latex-base\n",
        "# !sudo apt-get install texlive-fonts-recommended\n",
        "# !sudo apt-get install texlive-fonts-extra\n",
        "# !sudo apt-get install texlive-latex-extra"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pyDOE in /usr/local/lib/python3.6/dist-packages (0.3.8)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from pyDOE) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from pyDOE) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZkePg5-DQUx"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ABHRvyxDVUL",
        "outputId": "6b7a773a-18a8-4688-f4a5-207f14e73b4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5rpzj4sDOoj",
        "outputId": "e045de12-fdf0-415c-d29b-e461ab556d61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sys\n",
        "# sys.path.insert(0, './Utilities/')\n",
        "sys.path.insert(0, '/content/drive/My Drive/ColabNotebooks/PINN/Utilities/')\n",
        "# from SmoothSolutionBurgers import data_gen\n",
        "import matplotlib\n",
        "matplotlib.rcParams['text.usetex']=False\n",
        "matplotlib.rcParams['text.latex.unicode']=False\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from plotting import newfig, savefig\n",
        "from pyDOE import lhs\n",
        "from scipy.interpolate import griddata\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf  # tf v1.x\n",
        "import time\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: MatplotlibDeprecationWarning: \n",
            "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwdqLx68DOo1"
      },
      "source": [
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)\n",
        "np.set_printoptions(threshold=sys.maxsize)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riDZEnkhDOpB"
      },
      "source": [
        "class PhysicsInformedNN:\n",
        "    # Initialize the class\n",
        "    # def __init__(self, XX_energy, X_u, u, X_f, layers, lb, ub, nu):\n",
        "    def __init__(self, X_u, u, X_f, layers, lb, ub, nu):\n",
        "\n",
        "        self.lb = lb\n",
        "        self.ub = ub\n",
        "\n",
        "        # self.x_energy = XX_energy[:, 0:1] # energy x\n",
        "        # # print(self.x_energy.shape)\n",
        "        # self.t_energy = XX_energy[:, 1:2] # energy t\n",
        "\n",
        "        self.x_u = X_u[:, 0:1]  # training x\n",
        "        self.t_u = X_u[:, 1:2]  # training t\n",
        "\n",
        "        self.x_f = X_f[:, 0:1]  # collocation point x\n",
        "        # print(self.x_f.shape)\n",
        "        self.t_f = X_f[:, 1:2]  # collocation point t\n",
        "\n",
        "        self.u = u  # u(t,x) in BC and IC\n",
        "\n",
        "        self.layers = layers\n",
        "        self.nu = nu\n",
        "\n",
        "        # Initialize NNs\n",
        "        self.weights, self.biases = self.initialize_NN(layers)\n",
        "        # self.weights, self.biases, self.acti_param = self.initialize_NN(layers)\n",
        "\n",
        "        # tf placeholders and graph\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                                     log_device_placement=True))\n",
        "\n",
        "        self.x_u_tf = tf.placeholder(\n",
        "            tf.float32, shape=[None, self.x_u.shape[1]])\n",
        "        self.t_u_tf = tf.placeholder(\n",
        "            tf.float32, shape=[None, self.t_u.shape[1]])\n",
        "        self.u_tf = tf.placeholder(\n",
        "            tf.float32, shape=[None, self.u.shape[1]])\n",
        "\n",
        "        self.x_f_tf = tf.placeholder(\n",
        "            tf.float32, shape=[None, self.x_f.shape[1]])\n",
        "        self.t_f_tf = tf.placeholder(\n",
        "            tf.float32, shape=[None, self.t_f.shape[1]])\n",
        "\n",
        "        # self.x_energy_tf = tf.placeholder(\n",
        "        #     tf.float32, shape=[None, self.x_energy.shape[1]])\n",
        "        # # print(XX_energy_tf.shape)\n",
        "        # self.t_energy_tf = tf.placeholder(\n",
        "        #     tf.float32, shape=[None, self.t_energy.shape[1]])\n",
        "\n",
        "        self.u_pred = self.net_u(self.x_u_tf, self.t_u_tf) # t is not const here\n",
        "        self.f_pred = self.net_f(self.x_f_tf, self.t_f_tf)\n",
        "        # self.u_conv = self.net_u(self.x_energy_tf, self.t_energy_tf) \n",
        "\n",
        "        self.loss = tf.reduce_mean(tf.square(self.u_tf - self.u_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.f_pred)) # + self.S(self.acti_param)\n",
        "                    \n",
        "                    # + tf.square(np.pi - 2*np.pi*tf.reduce_mean(self.u_conv)) \n",
        "        # self.loss = tf.reduce_mean(tf.square(self.u_tf - self.u_pred)) + \\\n",
        "        #             tf.square(0 - 2*tf.reduce_mean(self.u_conv))\n",
        "            # New loss function\n",
        "            # tf.reduce_mean(tf.square(self.u_conv))\n",
        "\n",
        "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss,\n",
        "                                                                method='L-BFGS-B',\n",
        "                                                                options={'maxiter': 5*10**4,\n",
        "                                                                         'maxfun': 5*10**4,\n",
        "                                                                         'maxcor': 50,\n",
        "                                                                         'maxls': 50,\n",
        "                                                                         'ftol': 1.0 * np.finfo(float).eps})\n",
        "\n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "\n",
        "    def S(self, a):  # Slope recovery term\n",
        "        y = 0\n",
        "        for i in range(0, len(a)):\n",
        "            y += tf.exp(tf.reduce_mean(a[i]))\n",
        "        slope_term = 1 / (tf.reduce_mean(y))\n",
        "        return slope_term\n",
        "\n",
        "    def initialize_NN(self, layers):\n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers)\n",
        "        for l in range(0, num_layers - 1):\n",
        "            # print(\"l = \", l)\n",
        "            W = self.xavier_init(size=[layers[l], layers[l + 1]])\n",
        "            # print(W.shape)\n",
        "            b = tf.Variable(tf.zeros([1, layers[l + 1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            # print(b.shape)\n",
        "            weights.append(W)\n",
        "            biases.append(b)\n",
        "        return weights, biases\n",
        "\n",
        "    # def initialize_NN(self, layers):\n",
        "    #     weights = []\n",
        "    #     biases = []\n",
        "    #     acti_param = []\n",
        "    #     num_layers = len(layers)\n",
        "    #     for l in range(0, num_layers - 1):\n",
        "    #         W = self.xavier_init(size=[layers[l], layers[l + 1]])\n",
        "    #         b = tf.Variable(tf.zeros([1, layers[l + 1]], dtype=tf.float32), dtype=tf.float32)\n",
        "\n",
        "    #         # Neuron wise activation slope\n",
        "    #         a = tf.Variable(tf.constant(0.1, shape=[1, layers[1 + l]]))\n",
        "    #         weights.append(W)\n",
        "    #         biases.append(b)\n",
        "    #         acti_param.append(a)\n",
        "    #     return weights, biases, acti_param\n",
        "\n",
        "    def xavier_init(self, size):\n",
        "        in_dim = size[0] # H = 2.0 * (X - self.lb) / (self.ub - self.lb) - 1.0\n",
        "        out_dim = size[1]\n",
        "        xavier_stddev = np.sqrt(2 / (in_dim + out_dim))\n",
        "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
        "\n",
        "\n",
        "    # ## Modified architecture\n",
        "    # def neural_net(self, X, weights, biases, acti_param):\n",
        "    #     num_layers = len(weights) + 1\n",
        "    #     H = X #2.0 * (X - self.lb) / (self.ub - self.lb) - 1.0\n",
        "    #     for l in range(0, num_layers - 2):\n",
        "    #         W = weights[l]\n",
        "    #         b = biases[l]\n",
        "    #         a = acti_param[l]\n",
        "    #         if l % 2 == 0:\n",
        "    #             H = tf.sin(tf.multiply(tf.multiply(10.0, a),tf.add(tf.matmul(H, W), b)))\n",
        "    #         else:\n",
        "    #             H = tf.tanh(tf.multiply(tf.multiply(10.0, a),tf.add(tf.matmul(H, W), b)))\n",
        "    #     W = weights[-1]\n",
        "    #     b = biases[-1]\n",
        "    #     # a = acti_param[]\n",
        "    #     Y = tf.add(tf.matmul(H, W), b)\n",
        "    #     return Y\n",
        "\n",
        "\n",
        "    def neural_net(self, X, weights, biases):\n",
        "        num_layers = len(weights) + 1\n",
        "\n",
        "        H = 2.0 * (X - self.lb) / (self.ub - self.lb) - 1.0\n",
        "        for l in range(0, num_layers - 2):\n",
        "            W = weights[l]\n",
        "            b = biases[l]\n",
        "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        W = weights[-1]\n",
        "        b = biases[-1]\n",
        "        Y = tf.add(tf.matmul(H, W), b)\n",
        "        return Y\n",
        "\n",
        "    def net_u(self, x, t):\n",
        "        u = self.neural_net(tf.concat([x, t], 1), self.weights, self.biases)\n",
        "        # u = self.neural_net(tf.concat([x, t], 1), self.weights, self.biases, self.acti_param)\n",
        "        return u\n",
        "\n",
        "    def net_f(self, x, t):\n",
        "        u = self.net_u(x, t)\n",
        "        u_t = tf.gradients(u, t)[0]\n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        u_xx = tf.gradients(u_x, x)[0]\n",
        "        f = u_t + u * u_x - self.nu * u_xx\n",
        "        return f\n",
        "\n",
        "    def callback(self, loss): #, x_energy_tf, t_energy_tf):\n",
        "        # U_energy = tf.reduce_mean(2*np.pi*self.u_conv)\n",
        "        # l = []\n",
        "        # l.append(loss)\n",
        "        # return l\n",
        "        print('Loss:', loss)\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        tf_dict = {self.x_u_tf: self.x_u,  self.t_u_tf: self.t_u, self.u_tf: self.u, self.x_f_tf: self.x_f, self.t_f_tf: self.t_f}\n",
        "\n",
        "        self.optimizer.minimize(self.sess,\n",
        "                                feed_dict=tf_dict,\n",
        "                                fetches=[self.loss],\n",
        "                                loss_callback=self.callback)\n",
        "\n",
        "    def predict(self, X_star):\n",
        "        u_star = self.sess.run(\n",
        "            self.u_pred, {self.x_u_tf: X_star[:, 0:1], self.t_u_tf: X_star[:, 1:2]})\n",
        "        f_star = self.sess.run(\n",
        "            self.f_pred, {self.x_f_tf: X_star[:, 0:1], self.t_f_tf: X_star[:, 1:2]})\n",
        "\n",
        "        return u_star, f_star\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "opQdNo4dDOpK",
        "outputId": "f4baa54b-f562-4f63-bfaa-5b9b8933fef6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### Data loading and processing \n",
        "nu = 0.01 / np.pi\n",
        "noise = 0.0\n",
        "\n",
        "N_u = 100\n",
        "# N_u = int(sys.argv[1])\n",
        "# print(N_u)\n",
        "N_f = 10**4\n",
        "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
        "# layers = [2, 20, 20, 1]\n",
        "# layers = [2, 3, 1]\n",
        "\n",
        "# data = scipy.io.loadmat('./Data/burgers_shock.mat')\n",
        "data = scipy.io.loadmat('/content/drive/My Drive/ColabNotebooks/PINN/Data/burgers_shock.mat')\n",
        "\n",
        "t = data['t'].flatten()[:, None]\n",
        "x = data['x'].flatten()[:, None]\n",
        "Exact = np.real(data['usol']).T\n",
        "# # print(t)\n",
        "# # print(\"Okay here\")\n",
        "# # print(Exact.flatten()[:, None])\n",
        "# print(Exact.shape)\n",
        "# # print(t[25])\n",
        "\n",
        "# # print(t)\n",
        "# # print(x)\n",
        "\n",
        "X, T = np.meshgrid(x, t)\n",
        "\n",
        "# print(T.shape)\n",
        "\n",
        "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
        "\n",
        "u_star = Exact.flatten()[:, None]\n",
        "\n",
        "# # # Doman bounds\n",
        "lb = X_star.min(0)\n",
        "# print(lb)\n",
        "ub = X_star.max(0)\n",
        "# print(ub)\n",
        "# print(X[0:1, :].T)\n",
        "xx1 = np.hstack((X[0:1, :].T, T[0:1, :].T))  # initial condition\n",
        "# print(xx1)\n",
        "# u_ic  # Exact[0:1, :].T  # u_ic # training data on IC\n",
        "uu1 = Exact[0:1, :].T\n",
        "# plt.plot(X[0:1, :].T, uu1)\n",
        "# plt.show()\n",
        "# # print(U_int.shape)\n",
        "# Pi_expect = 2*np.pi*np.mean(uu1)\n",
        "# print(Pi_expect)\n",
        "xx2 = np.hstack((X[:, 0:1], T[:, 0:1]))  # x = -1 boundary condition\n",
        "# print(xx2)\n",
        "uu2 = Exact[:, 0:1]  # u_lbc  #   # traning data on x = -1. Close to 0\n",
        "# uu2 = u_lbc\n",
        "# print(uu2)\n",
        "# # # # plt.plot()\n",
        "xx3 = np.hstack((X[:, -1:], T[:, -1:]))\n",
        "# # # print(xx3.shape)  # x = 1 boundary condition\n",
        "uu3 = Exact[:, -1:]  # traning data on x = 1. Close to 0\n",
        "# print(uu3)\n",
        "# uu3 = u_rbc  # Exact[:, -1:]\n",
        "# print(list(zip(uu2, uu3)))\n",
        "\n",
        "# # # training data: IC + BC points => (t,x)\n",
        "X_u_train = np.vstack([xx1, xx2, xx3])\n",
        "# print(X_u_train)\n",
        "# # # print(\"The shape of X_u_train\", X_u_train.shape)\n",
        "# plt.scatter(X_u_train[:, 1], X_u_train[:, 0], label=\"IC/BC points\")\n",
        "# plt.xlabel(\"t\")\n",
        "# plt.ylabel(\"x\")\n",
        "# # plt.show()\n",
        "# plt.savefig('figures/training_t_x_plane.png')\n",
        "\n",
        "# print(ub - lb)\n",
        "X_f_train = lb + (ub - lb) * lhs(2, N_f)  # collocation point\n",
        "\n",
        "##### ###### ####### Box #### ######## ################\n",
        "box_lb = np.asarray([-0.25, 0.4])\n",
        "box_ub = np.asarray([1.0, 0.6])\n",
        "\n",
        "box_N_f = 2000\n",
        "X_f_train_box = box_lb + (box_ub - box_lb) * lhs(2, box_N_f)  # collocation point\n",
        "\n",
        "X_f_train = np.vstack([X_f_train, X_f_train_box])\n",
        "\n",
        "# print(X_f_train)\n",
        "\n",
        "#### ##### ####### Box #### ########## #################\n",
        "\n",
        "# print(X_f_train[:, 0:1])\n",
        "# plt.scatter(X_f_train[:,1:2], X_f_train[:, 0:1], label=\"Collocation point\")\n",
        "# plt.show()\n",
        "# print(X_f_train)\n",
        "# # print(X_f_train)\n",
        "# ## print(\"The shape of collocation points\", X_f_train.shape)\n",
        "# # print(X_f_train)\n",
        "X_f_train = np.vstack((X_f_train, X_u_train))\n",
        "# plt.scatter(X_f_train[:, 1:2], X_f_train[:, 0:1])\n",
        "# # plt.show()\n",
        "# # print(X_f_train)\n",
        "# # combination of the values at BC and IC = u_train\n",
        "u_train = np.vstack([uu1, uu2, uu3])\n",
        "# # print(\"The shape of u_train\", u_train.shape)\n",
        "# print(u_train)\n",
        "\n",
        "# # Randomly pick the 100 points form X_u_train\n",
        "idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
        "# print(idx.shape)\n",
        "X_u_train = X_u_train[idx, :]  # Final training data\n",
        "# print(X_u_train)\n",
        "# plt.plot(X_u_train[:, 1:2], X_u_train[:, 0:1], 'kx', label=\"Training points\")\n",
        "# plt.xlabel(\"t\")\n",
        "# plt.ylabel(\"x\")\n",
        "# plt.legend(frameon=True, loc='best')\n",
        "\n",
        "# plt.legend(loc='best', bbox_to_anchor=(0.5, -0.05)) #, shadow=True, ncol=2)\n",
        "u_train = u_train[idx, :]  # Final training data\n",
        "\n",
        "print(X.shape)\n",
        "print(T.shape)\n",
        "# ############ Data point for Energy #################\n",
        "# ## Goal: take all data point at snapshot t = t    #\n",
        "#                 ###############                   #\n",
        "# idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
        "# XX_energy = np.hstack([X[10:11, :].T, T[10:11, :].T])\n",
        "# index = np.random.choice(XX_energy.shape[0], 10, replace=False)\n",
        "# # # print(idx)\n",
        "# XX_energy = XX_energy[index, :]\n",
        "# # plt.savefig('figures/training_t_x_plane.png')\n",
        "# savefig('figures/total_training_dataset')\n",
        "# plt.scatter(XX_energy[:, 1:2], XX_energy[:, 0:1])\n",
        "# plt.show()\n",
        "# ###################################################"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 256)\n",
            "(100, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXKP9We2jpgi"
      },
      "source": [
        "# # box_lb = np.hstack([-0.25 0.4], [1 0.6]\n",
        "# box_lb = np.asarray([-0.25, 0.4])\n",
        "# box_ub = np.asarray([1.0, 0.6])\n",
        "\n",
        "# box_N_f = 200\n",
        "# X_f_train_box = box_lb + (box_ub - box_lb) * lhs(2, box_N_f)  # collocation point\n",
        "# # print(X_f_train_box)\n",
        "# plt.scatter(X_f_train_box[:,1:2], X_f_train_box[:, 0:1], label=\"Collocation point\")\n",
        "# # plt.show()\n",
        "# # print(X_f_train)\n",
        "# # # print(X_f_train)\n",
        "# # ## print(\"The shape of collocation points\", X_f_train.shape)\n",
        "# # # print(X_f_train)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "0sthQCe_DOpX"
      },
      "source": [
        "# data = scipy.io.loadmat('./Data/data_testing_150s.mat')\n",
        "# # data = scipy.io.loadmat('Data/data_testing.mat')\n",
        "\n",
        "# t = data['t'].flatten()[:, None]\n",
        "# x = data['x'].flatten()[:, None]\n",
        "# usol = np.real(data['usol']).T\n",
        "# print(type(t[-2]))\n",
        "# FinalTime = float(t[-2])\n",
        "# FinalTime = round(FinalTime,3)\n",
        "# fig, axes = plt.subplots(nrows=2, ncols=1)  # , figsize=(6, 4))\n",
        "#     # fig.tight_layout()\n",
        "#     # ax = plt.subplot(211)\n",
        "#     # plt.plot(x, u_IC, 'r', label=\"initial condition\")\n",
        "# axes[0].plot(x, usol[0, :], 'r', label=\"initial condition\")\n",
        "# axes[0].plot(x, usol[-1, :], 'g--', label=\"final\")\n",
        "# axes[0].legend()\n",
        "# axes[0].set_xlabel('$x$')\n",
        "# axes[0].set_ylabel('$u(t,x)$')\n",
        "# axes[0].set_title('Numerical Solution at final time = ' + str(FinalTime) + 's')\n",
        "\n",
        "# h = axes[1].imshow(np.real(usol.T), interpolation='nearest', cmap='jet',\n",
        "#           extent=[t.min(), t.max(), x.min(), x.max()], origin='lower', aspect='auto')\n",
        "\n",
        "# divider = make_axes_locatable(axes[1])\n",
        "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "# fig.colorbar(h, cax=cax)\n",
        "# axes[1].set_xlabel('$t$')\n",
        "# axes[1].set_ylabel('$x$')\n",
        "# axes[1].set_title('Solution on t-x plane')\n",
        "\n",
        "# # fig.suptitle('Numerical Solver', fontsize=12)\n",
        "# fig.tight_layout()\n",
        "# savefig('figures/numerical_exact_solution_150')\n",
        "# # fig.savefig('./figures/numerical_exact_solution.png')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "rt7iNw0NDOpg",
        "outputId": "9c0cce70-8b97-4611-c9cc-73c9a6c5ff1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "############## model ##################\n",
        "# model = PhysicsInformedNN(XX_energy, X_u_train, u_train, X_f_train, layers, lb, ub, nu)\n",
        "model = PhysicsInformedNN(X_u_train, u_train, X_f_train, layers, lb, ub, nu)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "j3H7oK3lDOpp",
        "outputId": "7c4e9c23-a38f-40c9-c295-885a933cb3cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "############## Training ############\n",
        "start_time = time.time()\n",
        "model.train()  # training\n",
        "elapsed = time.time() - start_time\n",
        "hours, rem = divmod(elapsed, 3600)\n",
        "minutes, seconds = divmod(rem, 60)\n",
        "print('Training time: {:0>2}:{:0>2}:{:05.2f}'.format(\n",
        "    int(hours), int(minutes), seconds))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Loss: 7.333437e-05\n",
            "Loss: 7.3199895e-05\n",
            "Loss: 7.3062634e-05\n",
            "Loss: 7.2973875e-05\n",
            "Loss: 7.293656e-05\n",
            "Loss: 7.291185e-05\n",
            "Loss: 7.28945e-05\n",
            "Loss: 7.2887735e-05\n",
            "Loss: 7.316427e-05\n",
            "Loss: 7.28254e-05\n",
            "Loss: 7.277634e-05\n",
            "Loss: 7.273157e-05\n",
            "Loss: 7.2709365e-05\n",
            "Loss: 7.267933e-05\n",
            "Loss: 7.2646704e-05\n",
            "Loss: 7.523598e-05\n",
            "Loss: 7.260076e-05\n",
            "Loss: 7.254195e-05\n",
            "Loss: 7.244066e-05\n",
            "Loss: 7.239334e-05\n",
            "Loss: 7.232813e-05\n",
            "Loss: 7.22541e-05\n",
            "Loss: 7.217343e-05\n",
            "Loss: 7.213071e-05\n",
            "Loss: 7.209368e-05\n",
            "Loss: 7.2022776e-05\n",
            "Loss: 7.191383e-05\n",
            "Loss: 7.2625786e-05\n",
            "Loss: 7.189791e-05\n",
            "Loss: 7.1818984e-05\n",
            "Loss: 7.1766415e-05\n",
            "Loss: 7.16823e-05\n",
            "Loss: 7.16167e-05\n",
            "Loss: 7.154033e-05\n",
            "Loss: 7.15088e-05\n",
            "Loss: 7.14714e-05\n",
            "Loss: 7.191888e-05\n",
            "Loss: 7.1464005e-05\n",
            "Loss: 7.144249e-05\n",
            "Loss: 7.144644e-05\n",
            "Loss: 7.1424016e-05\n",
            "Loss: 7.140341e-05\n",
            "Loss: 7.138916e-05\n",
            "Loss: 7.134153e-05\n",
            "Loss: 7.129627e-05\n",
            "Loss: 7.128422e-05\n",
            "Loss: 7.126874e-05\n",
            "Loss: 7.1200055e-05\n",
            "Loss: 7.117562e-05\n",
            "Loss: 7.1125236e-05\n",
            "Loss: 7.1057155e-05\n",
            "Loss: 7.095931e-05\n",
            "Loss: 7.087095e-05\n",
            "Loss: 7.542621e-05\n",
            "Loss: 7.083282e-05\n",
            "Loss: 7.077536e-05\n",
            "Loss: 7.072292e-05\n",
            "Loss: 7.070293e-05\n",
            "Loss: 7.066344e-05\n",
            "Loss: 7.0612274e-05\n",
            "Loss: 7.051695e-05\n",
            "Loss: 7.044937e-05\n",
            "Loss: 7.0400696e-05\n",
            "Loss: 7.033806e-05\n",
            "Loss: 7.0279486e-05\n",
            "Loss: 7.0206086e-05\n",
            "Loss: 7.0131806e-05\n",
            "Loss: 7.0063084e-05\n",
            "Loss: 6.999167e-05\n",
            "Loss: 6.992889e-05\n",
            "Loss: 6.987316e-05\n",
            "Loss: 6.982223e-05\n",
            "Loss: 7.019069e-05\n",
            "Loss: 6.980564e-05\n",
            "Loss: 6.9728565e-05\n",
            "Loss: 7.003978e-05\n",
            "Loss: 6.969142e-05\n",
            "Loss: 6.959618e-05\n",
            "Loss: 6.945033e-05\n",
            "Loss: 6.933786e-05\n",
            "Loss: 6.9253714e-05\n",
            "Loss: 6.936086e-05\n",
            "Loss: 6.9192836e-05\n",
            "Loss: 6.915319e-05\n",
            "Loss: 6.909777e-05\n",
            "Loss: 6.905412e-05\n",
            "Loss: 6.899435e-05\n",
            "Loss: 6.890175e-05\n",
            "Loss: 6.883052e-05\n",
            "Loss: 6.867302e-05\n",
            "Loss: 6.86025e-05\n",
            "Loss: 6.88446e-05\n",
            "Loss: 6.849756e-05\n",
            "Loss: 6.841507e-05\n",
            "Loss: 6.834238e-05\n",
            "Loss: 6.832659e-05\n",
            "Loss: 6.827795e-05\n",
            "Loss: 6.824134e-05\n",
            "Loss: 6.820105e-05\n",
            "Loss: 6.812917e-05\n",
            "Loss: 6.804473e-05\n",
            "Loss: 6.870182e-05\n",
            "Loss: 6.7885034e-05\n",
            "Loss: 6.7779976e-05\n",
            "Loss: 6.754898e-05\n",
            "Loss: 6.7472276e-05\n",
            "Loss: 6.737412e-05\n",
            "Loss: 6.720523e-05\n",
            "Loss: 7.233519e-05\n",
            "Loss: 6.7186804e-05\n",
            "Loss: 6.705432e-05\n",
            "Loss: 6.700892e-05\n",
            "Loss: 6.695803e-05\n",
            "Loss: 6.689019e-05\n",
            "Loss: 6.7650406e-05\n",
            "Loss: 6.688156e-05\n",
            "Loss: 6.682398e-05\n",
            "Loss: 6.672206e-05\n",
            "Loss: 6.665266e-05\n",
            "Loss: 6.660669e-05\n",
            "Loss: 6.654139e-05\n",
            "Loss: 6.6487104e-05\n",
            "Loss: 6.641296e-05\n",
            "Loss: 6.633371e-05\n",
            "Loss: 6.862334e-05\n",
            "Loss: 6.632056e-05\n",
            "Loss: 6.6405206e-05\n",
            "Loss: 6.6268585e-05\n",
            "Loss: 6.633038e-05\n",
            "Loss: 6.621377e-05\n",
            "Loss: 6.616208e-05\n",
            "Loss: 6.6047265e-05\n",
            "Loss: 6.597548e-05\n",
            "Loss: 6.586689e-05\n",
            "Loss: 6.581959e-05\n",
            "Loss: 6.5783825e-05\n",
            "Loss: 6.5719505e-05\n",
            "Loss: 6.565705e-05\n",
            "Loss: 6.5546614e-05\n",
            "Loss: 6.5465385e-05\n",
            "Loss: 6.535212e-05\n",
            "Loss: 6.530393e-05\n",
            "Loss: 6.533749e-05\n",
            "Loss: 6.52896e-05\n",
            "Loss: 6.526899e-05\n",
            "Loss: 6.525387e-05\n",
            "Loss: 6.5238855e-05\n",
            "Loss: 6.520852e-05\n",
            "Loss: 6.5166045e-05\n",
            "Loss: 6.507282e-05\n",
            "Loss: 6.4988024e-05\n",
            "Loss: 6.492982e-05\n",
            "Loss: 6.4900705e-05\n",
            "Loss: 6.488021e-05\n",
            "Loss: 6.486074e-05\n",
            "Loss: 6.484588e-05\n",
            "Loss: 6.4817374e-05\n",
            "Loss: 6.4786786e-05\n",
            "Loss: 6.474611e-05\n",
            "Loss: 6.466957e-05\n",
            "Loss: 6.46192e-05\n",
            "Loss: 6.4556116e-05\n",
            "Loss: 6.4511645e-05\n",
            "Loss: 6.445891e-05\n",
            "Loss: 6.4398904e-05\n",
            "Loss: 6.436698e-05\n",
            "Loss: 6.471832e-05\n",
            "Loss: 6.435649e-05\n",
            "Loss: 6.431561e-05\n",
            "Loss: 6.4261985e-05\n",
            "Loss: 6.41806e-05\n",
            "Loss: 6.410324e-05\n",
            "Loss: 6.415191e-05\n",
            "Loss: 6.4076456e-05\n",
            "Loss: 6.403025e-05\n",
            "Loss: 6.399579e-05\n",
            "Loss: 6.394448e-05\n",
            "Loss: 6.39006e-05\n",
            "Loss: 6.385658e-05\n",
            "Loss: 6.3811705e-05\n",
            "Loss: 6.3746746e-05\n",
            "Loss: 6.369842e-05\n",
            "Loss: 6.363839e-05\n",
            "Loss: 6.361326e-05\n",
            "Loss: 6.35396e-05\n",
            "Loss: 6.418589e-05\n",
            "Loss: 6.3509666e-05\n",
            "Loss: 6.345756e-05\n",
            "Loss: 6.3347456e-05\n",
            "Loss: 6.330655e-05\n",
            "Loss: 6.3195475e-05\n",
            "Loss: 6.3615254e-05\n",
            "Loss: 6.3137966e-05\n",
            "Loss: 6.307317e-05\n",
            "Loss: 6.297746e-05\n",
            "Loss: 6.2931926e-05\n",
            "Loss: 6.2906576e-05\n",
            "Loss: 6.285356e-05\n",
            "Loss: 6.2832674e-05\n",
            "Loss: 6.280082e-05\n",
            "Loss: 6.291586e-05\n",
            "Loss: 6.279226e-05\n",
            "Loss: 6.281758e-05\n",
            "Loss: 6.277305e-05\n",
            "Loss: 6.275409e-05\n",
            "Loss: 6.269468e-05\n",
            "Loss: 6.263751e-05\n",
            "Loss: 6.25569e-05\n",
            "Loss: 6.246388e-05\n",
            "Loss: 6.306849e-05\n",
            "Loss: 6.243668e-05\n",
            "Loss: 6.234045e-05\n",
            "Loss: 6.223463e-05\n",
            "Loss: 6.214022e-05\n",
            "Loss: 6.205298e-05\n",
            "Loss: 6.198852e-05\n",
            "Loss: 6.36022e-05\n",
            "Loss: 6.19796e-05\n",
            "Loss: 6.212898e-05\n",
            "Loss: 6.195047e-05\n",
            "Loss: 6.19131e-05\n",
            "Loss: 6.189669e-05\n",
            "Loss: 6.18787e-05\n",
            "Loss: 6.1858824e-05\n",
            "Loss: 6.1828534e-05\n",
            "Loss: 6.178293e-05\n",
            "Loss: 6.172312e-05\n",
            "Loss: 6.167884e-05\n",
            "Loss: 6.164444e-05\n",
            "Loss: 6.1589206e-05\n",
            "Loss: 6.155513e-05\n",
            "Loss: 6.150196e-05\n",
            "Loss: 6.146415e-05\n",
            "Loss: 6.1431805e-05\n",
            "Loss: 6.1404426e-05\n",
            "Loss: 6.1366365e-05\n",
            "Loss: 6.133328e-05\n",
            "Loss: 6.128681e-05\n",
            "Loss: 6.124477e-05\n",
            "Loss: 6.118826e-05\n",
            "Loss: 6.113402e-05\n",
            "Loss: 6.111808e-05\n",
            "Loss: 6.1058876e-05\n",
            "Loss: 6.0971885e-05\n",
            "Loss: 6.0909373e-05\n",
            "Loss: 6.084886e-05\n",
            "Loss: 6.0762173e-05\n",
            "Loss: 6.0692946e-05\n",
            "Loss: 6.076799e-05\n",
            "Loss: 6.0674854e-05\n",
            "Loss: 6.0634582e-05\n",
            "Loss: 6.0586244e-05\n",
            "Loss: 6.053463e-05\n",
            "Loss: 6.04955e-05\n",
            "Loss: 6.0501363e-05\n",
            "Loss: 6.0478673e-05\n",
            "Loss: 6.0440972e-05\n",
            "Loss: 6.041209e-05\n",
            "Loss: 6.0334904e-05\n",
            "Loss: 6.0283874e-05\n",
            "Loss: 6.0372502e-05\n",
            "Loss: 6.0252285e-05\n",
            "Loss: 6.0177525e-05\n",
            "Loss: 6.0099173e-05\n",
            "Loss: 6.0480037e-05\n",
            "Loss: 6.0060567e-05\n",
            "Loss: 5.995482e-05\n",
            "Loss: 5.9809943e-05\n",
            "Loss: 6.329524e-05\n",
            "Loss: 5.978978e-05\n",
            "Loss: 5.9658392e-05\n",
            "Loss: 5.9590697e-05\n",
            "Loss: 5.9971717e-05\n",
            "Loss: 5.9576414e-05\n",
            "Loss: 5.9542996e-05\n",
            "Loss: 5.9505288e-05\n",
            "Loss: 5.942749e-05\n",
            "Loss: 5.935062e-05\n",
            "Loss: 5.926513e-05\n",
            "Loss: 6.134366e-05\n",
            "Loss: 5.9205486e-05\n",
            "Loss: 5.9106715e-05\n",
            "Loss: 5.8926522e-05\n",
            "Loss: 5.8869908e-05\n",
            "Loss: 5.8762827e-05\n",
            "Loss: 6.567994e-05\n",
            "Loss: 5.875234e-05\n",
            "Loss: 5.872681e-05\n",
            "Loss: 5.8692425e-05\n",
            "Loss: 5.865278e-05\n",
            "Loss: 5.872587e-05\n",
            "Loss: 5.8631533e-05\n",
            "Loss: 5.859849e-05\n",
            "Loss: 5.8539605e-05\n",
            "Loss: 5.850601e-05\n",
            "Loss: 5.860637e-05\n",
            "Loss: 5.8481553e-05\n",
            "Loss: 5.840694e-05\n",
            "Loss: 5.8356996e-05\n",
            "Loss: 5.834046e-05\n",
            "Loss: 5.8316804e-05\n",
            "Loss: 5.830118e-05\n",
            "Loss: 5.835002e-05\n",
            "Loss: 5.8287205e-05\n",
            "Loss: 5.8266403e-05\n",
            "Loss: 5.8206584e-05\n",
            "Loss: 5.8133344e-05\n",
            "Loss: 5.8066023e-05\n",
            "Loss: 5.7928846e-05\n",
            "Loss: 5.800199e-05\n",
            "Loss: 5.7864494e-05\n",
            "Loss: 5.7791807e-05\n",
            "Loss: 5.771543e-05\n",
            "Loss: 5.7787656e-05\n",
            "Loss: 5.769836e-05\n",
            "Loss: 5.766297e-05\n",
            "Loss: 5.7602374e-05\n",
            "Loss: 5.7499037e-05\n",
            "Loss: 5.743443e-05\n",
            "Loss: 5.739342e-05\n",
            "Loss: 5.7376852e-05\n",
            "Loss: 5.728156e-05\n",
            "Loss: 5.7167013e-05\n",
            "Loss: 5.7118887e-05\n",
            "Loss: 5.7102254e-05\n",
            "Loss: 5.7026115e-05\n",
            "Loss: 5.6937646e-05\n",
            "Loss: 5.7008823e-05\n",
            "Loss: 5.684608e-05\n",
            "Loss: 5.6782676e-05\n",
            "Loss: 5.672603e-05\n",
            "Loss: 5.6717567e-05\n",
            "Loss: 5.6681612e-05\n",
            "Loss: 5.6663645e-05\n",
            "Loss: 5.665044e-05\n",
            "Loss: 5.6640907e-05\n",
            "Loss: 5.6620484e-05\n",
            "Loss: 5.658459e-05\n",
            "Loss: 5.6539528e-05\n",
            "Loss: 5.6420147e-05\n",
            "Loss: 5.635916e-05\n",
            "Loss: 5.631516e-05\n",
            "Loss: 5.623819e-05\n",
            "Loss: 5.620129e-05\n",
            "Loss: 5.614901e-05\n",
            "Loss: 5.6965022e-05\n",
            "Loss: 5.6140525e-05\n",
            "Loss: 5.609663e-05\n",
            "Loss: 5.6024255e-05\n",
            "Loss: 5.5943332e-05\n",
            "Loss: 5.5847373e-05\n",
            "Loss: 5.651616e-05\n",
            "Loss: 5.5807985e-05\n",
            "Loss: 5.5752615e-05\n",
            "Loss: 5.5606364e-05\n",
            "Loss: 5.5538905e-05\n",
            "Loss: 5.5460892e-05\n",
            "Loss: 5.538704e-05\n",
            "Loss: 5.5348057e-05\n",
            "Loss: 5.5309476e-05\n",
            "Loss: 5.532175e-05\n",
            "Loss: 5.5288707e-05\n",
            "Loss: 5.5241573e-05\n",
            "Loss: 5.5189932e-05\n",
            "Loss: 5.515182e-05\n",
            "Loss: 5.51272e-05\n",
            "Loss: 5.511009e-05\n",
            "Loss: 5.5088236e-05\n",
            "Loss: 5.5057328e-05\n",
            "Loss: 5.527349e-05\n",
            "Loss: 5.5048597e-05\n",
            "Loss: 5.501924e-05\n",
            "Loss: 5.493957e-05\n",
            "Loss: 5.4892676e-05\n",
            "Loss: 5.4838747e-05\n",
            "Loss: 5.488174e-05\n",
            "Loss: 5.482386e-05\n",
            "Loss: 5.478602e-05\n",
            "Loss: 5.472223e-05\n",
            "Loss: 5.4626256e-05\n",
            "Loss: 5.4590637e-05\n",
            "Loss: 5.4494325e-05\n",
            "Loss: 5.446362e-05\n",
            "Loss: 5.4441218e-05\n",
            "Loss: 5.4416825e-05\n",
            "Loss: 5.4394965e-05\n",
            "Loss: 5.4437405e-05\n",
            "Loss: 5.4385484e-05\n",
            "Loss: 5.4362365e-05\n",
            "Loss: 5.434768e-05\n",
            "Loss: 5.4351825e-05\n",
            "Loss: 5.433605e-05\n",
            "Loss: 5.4323376e-05\n",
            "Loss: 5.4294593e-05\n",
            "Loss: 5.4271033e-05\n",
            "Loss: 5.424943e-05\n",
            "Loss: 5.4216376e-05\n",
            "Loss: 5.4315395e-05\n",
            "Loss: 5.419738e-05\n",
            "Loss: 5.418536e-05\n",
            "Loss: 5.4128082e-05\n",
            "Loss: 5.4095857e-05\n",
            "Loss: 5.405324e-05\n",
            "Loss: 5.3977787e-05\n",
            "Loss: 5.409354e-05\n",
            "Loss: 5.3949887e-05\n",
            "Loss: 5.3879867e-05\n",
            "Loss: 5.3840435e-05\n",
            "Loss: 5.3802716e-05\n",
            "Loss: 5.3739583e-05\n",
            "Loss: 5.3690484e-05\n",
            "Loss: 5.3638276e-05\n",
            "Loss: 5.4188742e-05\n",
            "Loss: 5.361165e-05\n",
            "Loss: 5.35818e-05\n",
            "Loss: 5.3450378e-05\n",
            "Loss: 5.3378608e-05\n",
            "Loss: 5.327016e-05\n",
            "Loss: 5.3207914e-05\n",
            "Loss: 5.3140247e-05\n",
            "Loss: 5.309443e-05\n",
            "Loss: 5.3069576e-05\n",
            "Loss: 5.3048254e-05\n",
            "Loss: 5.3031756e-05\n",
            "Loss: 5.303166e-05\n",
            "Loss: 5.3016527e-05\n",
            "Loss: 5.2983367e-05\n",
            "Loss: 5.2947653e-05\n",
            "Loss: 5.293834e-05\n",
            "Loss: 5.3000313e-05\n",
            "Loss: 5.2880507e-05\n",
            "Loss: 5.2832303e-05\n",
            "Loss: 5.277805e-05\n",
            "Loss: 5.273497e-05\n",
            "Loss: 5.2667878e-05\n",
            "Loss: 5.253536e-05\n",
            "Loss: 5.2444346e-05\n",
            "Loss: 5.233961e-05\n",
            "Loss: 5.2296447e-05\n",
            "Loss: 5.252315e-05\n",
            "Loss: 5.2286603e-05\n",
            "Loss: 5.2234238e-05\n",
            "Loss: 5.219985e-05\n",
            "Loss: 5.2151114e-05\n",
            "Loss: 5.2117874e-05\n",
            "Loss: 5.207341e-05\n",
            "Loss: 5.1974825e-05\n",
            "Loss: 5.718099e-05\n",
            "Loss: 5.1948005e-05\n",
            "Loss: 5.1998395e-05\n",
            "Loss: 5.1928484e-05\n",
            "Loss: 5.18738e-05\n",
            "Loss: 5.1854313e-05\n",
            "Loss: 5.19604e-05\n",
            "Loss: 5.1839415e-05\n",
            "Loss: 5.1813877e-05\n",
            "Loss: 5.178585e-05\n",
            "Loss: 5.1737738e-05\n",
            "Loss: 5.167887e-05\n",
            "Loss: 5.1614123e-05\n",
            "Loss: 5.1551506e-05\n",
            "Loss: 5.143868e-05\n",
            "Loss: 5.137968e-05\n",
            "Loss: 5.130294e-05\n",
            "Loss: 5.1223808e-05\n",
            "Loss: 5.115042e-05\n",
            "Loss: 5.1017407e-05\n",
            "Loss: 5.091593e-05\n",
            "Loss: 5.088391e-05\n",
            "Loss: 5.0803854e-05\n",
            "Loss: 5.0767972e-05\n",
            "Loss: 5.0731283e-05\n",
            "Loss: 5.068697e-05\n",
            "Loss: 5.0989656e-05\n",
            "Loss: 5.0643772e-05\n",
            "Loss: 5.052697e-05\n",
            "Loss: 5.0478066e-05\n",
            "Loss: 5.0447496e-05\n",
            "Loss: 5.0422703e-05\n",
            "Loss: 5.039231e-05\n",
            "Loss: 5.0377283e-05\n",
            "Loss: 5.034039e-05\n",
            "Loss: 5.0403658e-05\n",
            "Loss: 5.0314677e-05\n",
            "Loss: 5.0263367e-05\n",
            "Loss: 5.0216713e-05\n",
            "Loss: 5.0158993e-05\n",
            "Loss: 5.0071456e-05\n",
            "Loss: 5.001782e-05\n",
            "Loss: 4.9965704e-05\n",
            "Loss: 4.9935687e-05\n",
            "Loss: 4.9872673e-05\n",
            "Loss: 4.9815928e-05\n",
            "Loss: 4.9730294e-05\n",
            "Loss: 4.9627582e-05\n",
            "Loss: 4.976454e-05\n",
            "Loss: 4.958288e-05\n",
            "Loss: 4.951035e-05\n",
            "Loss: 4.9453047e-05\n",
            "Loss: 4.937167e-05\n",
            "Loss: 4.934171e-05\n",
            "Loss: 4.932382e-05\n",
            "Loss: 4.930477e-05\n",
            "Loss: 4.92998e-05\n",
            "Loss: 4.9280916e-05\n",
            "Loss: 4.9246974e-05\n",
            "Loss: 4.925595e-05\n",
            "Loss: 4.922688e-05\n",
            "Loss: 5.1429895e-05\n",
            "Loss: 4.9214585e-05\n",
            "Loss: 4.9190774e-05\n",
            "Loss: 4.91697e-05\n",
            "Loss: 4.9219227e-05\n",
            "Loss: 4.9153798e-05\n",
            "Loss: 4.9122827e-05\n",
            "Loss: 4.9054972e-05\n",
            "Loss: 4.9017613e-05\n",
            "Loss: 4.89342e-05\n",
            "Loss: 5.0301183e-05\n",
            "Loss: 4.892534e-05\n",
            "Loss: 4.886563e-05\n",
            "Loss: 4.879231e-05\n",
            "Loss: 4.870649e-05\n",
            "Loss: 4.8602924e-05\n",
            "Loss: 4.8547838e-05\n",
            "Loss: 4.8504615e-05\n",
            "Loss: 4.8470596e-05\n",
            "Loss: 4.8453094e-05\n",
            "Loss: 4.844219e-05\n",
            "Loss: 4.84224e-05\n",
            "Loss: 4.8386806e-05\n",
            "Loss: 4.987733e-05\n",
            "Loss: 4.8367754e-05\n",
            "Loss: 4.8324146e-05\n",
            "Loss: 4.821365e-05\n",
            "Loss: 4.8182847e-05\n",
            "Loss: 4.814547e-05\n",
            "Loss: 4.861958e-05\n",
            "Loss: 4.810679e-05\n",
            "Loss: 4.808388e-05\n",
            "Loss: 4.8058264e-05\n",
            "Loss: 4.80302e-05\n",
            "Loss: 4.801212e-05\n",
            "Loss: 4.7979163e-05\n",
            "Loss: 4.7954094e-05\n",
            "Loss: 4.7935428e-05\n",
            "Loss: 4.791563e-05\n",
            "Loss: 4.78929e-05\n",
            "Loss: 4.7869085e-05\n",
            "Loss: 4.7843416e-05\n",
            "Loss: 4.7811318e-05\n",
            "Loss: 4.8586444e-05\n",
            "Loss: 4.7795813e-05\n",
            "Loss: 4.773125e-05\n",
            "Loss: 4.772549e-05\n",
            "Loss: 4.767955e-05\n",
            "Loss: 4.7637688e-05\n",
            "Loss: 4.7615966e-05\n",
            "Loss: 4.7592715e-05\n",
            "Loss: 4.756471e-05\n",
            "Loss: 4.75462e-05\n",
            "Loss: 4.7518435e-05\n",
            "Loss: 4.7478712e-05\n",
            "Loss: 4.7447647e-05\n",
            "Loss: 4.7399422e-05\n",
            "Loss: 4.735341e-05\n",
            "Loss: 4.7342066e-05\n",
            "Loss: 4.7264708e-05\n",
            "Loss: 4.7383874e-05\n",
            "Loss: 4.722838e-05\n",
            "Loss: 4.7195837e-05\n",
            "Loss: 4.716544e-05\n",
            "Loss: 4.7134898e-05\n",
            "Loss: 4.7089077e-05\n",
            "Loss: 4.7046742e-05\n",
            "Loss: 4.7012767e-05\n",
            "Loss: 4.699765e-05\n",
            "Loss: 4.6967907e-05\n",
            "Loss: 4.6932822e-05\n",
            "Loss: 4.688928e-05\n",
            "Loss: 4.685556e-05\n",
            "Loss: 4.685616e-05\n",
            "Loss: 4.6840913e-05\n",
            "Loss: 4.6827154e-05\n",
            "Loss: 4.680231e-05\n",
            "Loss: 4.6789908e-05\n",
            "Loss: 4.677036e-05\n",
            "Loss: 4.7144244e-05\n",
            "Loss: 4.6763562e-05\n",
            "Loss: 4.6747944e-05\n",
            "Loss: 4.6726847e-05\n",
            "Loss: 4.6718225e-05\n",
            "Loss: 4.66935e-05\n",
            "Loss: 4.6718727e-05\n",
            "Loss: 4.6676538e-05\n",
            "Loss: 4.664273e-05\n",
            "Loss: 4.659438e-05\n",
            "Loss: 4.6544534e-05\n",
            "Loss: 4.650486e-05\n",
            "Loss: 4.646244e-05\n",
            "Loss: 4.6422778e-05\n",
            "Loss: 4.638893e-05\n",
            "Loss: 4.6359906e-05\n",
            "Loss: 4.6320143e-05\n",
            "Loss: 4.6296966e-05\n",
            "Loss: 4.6287598e-05\n",
            "Loss: 4.6260106e-05\n",
            "Loss: 4.623912e-05\n",
            "Loss: 4.6176414e-05\n",
            "Loss: 4.6115776e-05\n",
            "Loss: 4.603782e-05\n",
            "Loss: 4.8035123e-05\n",
            "Loss: 4.598603e-05\n",
            "Loss: 4.5918998e-05\n",
            "Loss: 4.586789e-05\n",
            "Loss: 4.582398e-05\n",
            "Loss: 4.572318e-05\n",
            "Loss: 5.1833806e-05\n",
            "Loss: 4.569808e-05\n",
            "Loss: 4.561873e-05\n",
            "Loss: 4.5538975e-05\n",
            "Loss: 4.5517765e-05\n",
            "Loss: 4.549878e-05\n",
            "Loss: 4.548638e-05\n",
            "Loss: 4.547689e-05\n",
            "Loss: 4.543931e-05\n",
            "Loss: 4.5820205e-05\n",
            "Loss: 4.5418827e-05\n",
            "Loss: 4.5382643e-05\n",
            "Loss: 4.5337572e-05\n",
            "Loss: 4.6269928e-05\n",
            "Loss: 4.5311048e-05\n",
            "Loss: 4.5267898e-05\n",
            "Loss: 4.5172015e-05\n",
            "Loss: 4.5509296e-05\n",
            "Loss: 4.515618e-05\n",
            "Loss: 4.5109788e-05\n",
            "Loss: 4.5065313e-05\n",
            "Loss: 4.504154e-05\n",
            "Loss: 4.501382e-05\n",
            "Loss: 4.500788e-05\n",
            "Loss: 4.894913e-05\n",
            "Loss: 4.4975175e-05\n",
            "Loss: 4.494035e-05\n",
            "Loss: 4.4917753e-05\n",
            "Loss: 4.4897723e-05\n",
            "Loss: 4.4884422e-05\n",
            "Loss: 4.4943692e-05\n",
            "Loss: 4.4863395e-05\n",
            "Loss: 4.4832504e-05\n",
            "Loss: 4.4781846e-05\n",
            "Loss: 4.4752145e-05\n",
            "Loss: 4.47321e-05\n",
            "Loss: 4.4696775e-05\n",
            "Loss: 4.4721633e-05\n",
            "Loss: 4.4675144e-05\n",
            "Loss: 4.463475e-05\n",
            "Loss: 4.460191e-05\n",
            "Loss: 4.4558597e-05\n",
            "Loss: 4.4798027e-05\n",
            "Loss: 4.453851e-05\n",
            "Loss: 4.4482364e-05\n",
            "Loss: 4.4410684e-05\n",
            "Loss: 4.4331104e-05\n",
            "Loss: 4.4285567e-05\n",
            "Loss: 4.4231383e-05\n",
            "Loss: 4.417503e-05\n",
            "Loss: 4.4128697e-05\n",
            "Loss: 4.4055465e-05\n",
            "Loss: 4.400014e-05\n",
            "Loss: 4.3910353e-05\n",
            "Loss: 4.3830114e-05\n",
            "Loss: 4.4277527e-05\n",
            "Loss: 4.377877e-05\n",
            "Loss: 4.3717428e-05\n",
            "Loss: 4.3631324e-05\n",
            "Loss: 4.359037e-05\n",
            "Loss: 4.3548083e-05\n",
            "Loss: 4.3480482e-05\n",
            "Loss: 4.347314e-05\n",
            "Loss: 4.345124e-05\n",
            "Loss: 4.4533106e-05\n",
            "Loss: 4.3442808e-05\n",
            "Loss: 4.340495e-05\n",
            "Loss: 4.3319196e-05\n",
            "Loss: 4.3264794e-05\n",
            "Loss: 4.3229717e-05\n",
            "Loss: 4.319484e-05\n",
            "Loss: 4.312814e-05\n",
            "Loss: 4.3194865e-05\n",
            "Loss: 4.3101936e-05\n",
            "Loss: 4.3052543e-05\n",
            "Loss: 4.3036416e-05\n",
            "Loss: 4.3056705e-05\n",
            "Loss: 4.301837e-05\n",
            "Loss: 4.29952e-05\n",
            "Loss: 4.2958352e-05\n",
            "Loss: 4.3192456e-05\n",
            "Loss: 4.2940344e-05\n",
            "Loss: 4.2890093e-05\n",
            "Loss: 4.2846415e-05\n",
            "Loss: 4.2818952e-05\n",
            "Loss: 4.2789747e-05\n",
            "Loss: 4.281797e-05\n",
            "Loss: 4.2763015e-05\n",
            "Loss: 4.2713353e-05\n",
            "Loss: 4.2642605e-05\n",
            "Loss: 4.2616477e-05\n",
            "Loss: 4.259488e-05\n",
            "Loss: 4.257249e-05\n",
            "Loss: 4.2554937e-05\n",
            "Loss: 5.028974e-05\n",
            "Loss: 4.2549465e-05\n",
            "Loss: 4.251617e-05\n",
            "Loss: 4.247414e-05\n",
            "Loss: 4.244283e-05\n",
            "Loss: 4.241203e-05\n",
            "Loss: 4.2388754e-05\n",
            "Loss: 4.2362717e-05\n",
            "Loss: 4.2339074e-05\n",
            "Loss: 4.2291056e-05\n",
            "Loss: 4.225977e-05\n",
            "Loss: 4.2215706e-05\n",
            "Loss: 4.218749e-05\n",
            "Loss: 4.2167216e-05\n",
            "Loss: 4.2157386e-05\n",
            "Loss: 4.2147145e-05\n",
            "Loss: 4.2144435e-05\n",
            "Loss: 4.2132982e-05\n",
            "Loss: 4.212714e-05\n",
            "Loss: 4.211479e-05\n",
            "Loss: 4.2097174e-05\n",
            "Loss: 4.2071697e-05\n",
            "Loss: 4.255346e-05\n",
            "Loss: 4.2068456e-05\n",
            "Loss: 4.2037802e-05\n",
            "Loss: 4.19927e-05\n",
            "Loss: 4.195404e-05\n",
            "Loss: 4.197157e-05\n",
            "Loss: 4.1930783e-05\n",
            "Loss: 4.1912594e-05\n",
            "Loss: 4.189186e-05\n",
            "Loss: 4.18755e-05\n",
            "Loss: 4.1835312e-05\n",
            "Loss: 4.1950836e-05\n",
            "Loss: 4.1814983e-05\n",
            "Loss: 4.1760068e-05\n",
            "Loss: 4.1663712e-05\n",
            "Loss: 4.1603987e-05\n",
            "Loss: 4.15595e-05\n",
            "Loss: 4.1520267e-05\n",
            "Loss: 4.149026e-05\n",
            "Loss: 4.1478153e-05\n",
            "Loss: 4.146893e-05\n",
            "Loss: 4.1454958e-05\n",
            "Loss: 4.14461e-05\n",
            "Loss: 4.1387375e-05\n",
            "Loss: 4.1355393e-05\n",
            "Loss: 4.1327494e-05\n",
            "Loss: 4.131117e-05\n",
            "Loss: 4.1295727e-05\n",
            "Loss: 4.1275838e-05\n",
            "Loss: 4.126638e-05\n",
            "Loss: 4.124905e-05\n",
            "Loss: 4.1232088e-05\n",
            "Loss: 4.1216867e-05\n",
            "Loss: 4.1204745e-05\n",
            "Loss: 4.1174026e-05\n",
            "Loss: 4.115045e-05\n",
            "Loss: 4.1123087e-05\n",
            "Loss: 4.1098385e-05\n",
            "Loss: 4.1081883e-05\n",
            "Loss: 4.1073334e-05\n",
            "Loss: 4.106438e-05\n",
            "Loss: 4.1049767e-05\n",
            "Loss: 4.103752e-05\n",
            "Loss: 4.1007635e-05\n",
            "Loss: 4.099821e-05\n",
            "Loss: 4.2414336e-05\n",
            "Loss: 4.0996023e-05\n",
            "Loss: 4.0979037e-05\n",
            "Loss: 4.096891e-05\n",
            "Loss: 4.0960284e-05\n",
            "Loss: 4.0959414e-05\n",
            "Loss: 4.0949628e-05\n",
            "Loss: 4.0935793e-05\n",
            "Loss: 4.0913776e-05\n",
            "Loss: 4.118383e-05\n",
            "Loss: 4.0902796e-05\n",
            "Loss: 4.087513e-05\n",
            "Loss: 4.2518725e-05\n",
            "Loss: 4.0853192e-05\n",
            "Loss: 4.0826377e-05\n",
            "Loss: 4.0782754e-05\n",
            "Loss: 4.137285e-05\n",
            "Loss: 4.0775667e-05\n",
            "Loss: 4.0732913e-05\n",
            "Loss: 4.0698593e-05\n",
            "Loss: 4.065295e-05\n",
            "Loss: 4.0618444e-05\n",
            "Loss: 4.0579882e-05\n",
            "Loss: 4.0541072e-05\n",
            "Loss: 4.051486e-05\n",
            "Loss: 4.0488383e-05\n",
            "Loss: 4.0444644e-05\n",
            "Loss: 4.040439e-05\n",
            "Loss: 4.0378676e-05\n",
            "Loss: 4.0729003e-05\n",
            "Loss: 4.036961e-05\n",
            "Loss: 4.034261e-05\n",
            "Loss: 4.0279767e-05\n",
            "Loss: 4.19126e-05\n",
            "Loss: 4.023309e-05\n",
            "Loss: 4.0185038e-05\n",
            "Loss: 4.0132265e-05\n",
            "Loss: 4.0107538e-05\n",
            "Loss: 4.0042032e-05\n",
            "Loss: 0.00011402991\n",
            "Loss: 4.003248e-05\n",
            "Loss: 3.999887e-05\n",
            "Loss: 4.004227e-05\n",
            "Loss: 3.9958955e-05\n",
            "Loss: 3.9889776e-05\n",
            "Loss: 3.979038e-05\n",
            "Loss: 3.9743594e-05\n",
            "Loss: 3.970273e-05\n",
            "Loss: 3.9659928e-05\n",
            "Loss: 3.9610528e-05\n",
            "Loss: 3.957605e-05\n",
            "Loss: 3.9543254e-05\n",
            "Loss: 3.949255e-05\n",
            "Loss: 3.9426537e-05\n",
            "Loss: 3.93675e-05\n",
            "Loss: 3.9329076e-05\n",
            "Loss: 3.9306597e-05\n",
            "Loss: 3.9274953e-05\n",
            "Loss: 3.924743e-05\n",
            "Loss: 3.9228114e-05\n",
            "Loss: 3.9205723e-05\n",
            "Loss: 3.9167262e-05\n",
            "Loss: 4.2221152e-05\n",
            "Loss: 3.9149774e-05\n",
            "Loss: 3.9132254e-05\n",
            "Loss: 3.9036175e-05\n",
            "Loss: 3.8985876e-05\n",
            "Loss: 3.894788e-05\n",
            "Loss: 3.8912858e-05\n",
            "Loss: 3.88754e-05\n",
            "Loss: 3.8825852e-05\n",
            "Loss: 3.877429e-05\n",
            "Loss: 3.8780534e-05\n",
            "Loss: 3.875126e-05\n",
            "Loss: 3.997772e-05\n",
            "Loss: 3.874214e-05\n",
            "Loss: 3.8716047e-05\n",
            "Loss: 3.8669783e-05\n",
            "Loss: 3.8641876e-05\n",
            "Loss: 3.858502e-05\n",
            "Loss: 3.8529062e-05\n",
            "Loss: 3.8486873e-05\n",
            "Loss: 3.8454855e-05\n",
            "Loss: 3.843972e-05\n",
            "Loss: 3.8413003e-05\n",
            "Loss: 3.8393395e-05\n",
            "Loss: 3.834306e-05\n",
            "Loss: 3.8395236e-05\n",
            "Loss: 3.833289e-05\n",
            "Loss: 3.8271835e-05\n",
            "Loss: 3.8216156e-05\n",
            "Loss: 3.817216e-05\n",
            "Loss: 3.812921e-05\n",
            "Loss: 3.8090435e-05\n",
            "Loss: 3.807436e-05\n",
            "Loss: 3.8054382e-05\n",
            "Loss: 3.802425e-05\n",
            "Loss: 3.808531e-05\n",
            "Loss: 3.8011047e-05\n",
            "Loss: 3.80592e-05\n",
            "Loss: 3.7990707e-05\n",
            "Loss: 3.797378e-05\n",
            "Loss: 3.794253e-05\n",
            "Loss: 3.7926817e-05\n",
            "Loss: 3.791052e-05\n",
            "Loss: 3.789557e-05\n",
            "Loss: 3.784307e-05\n",
            "Loss: 4.408732e-05\n",
            "Loss: 3.7833906e-05\n",
            "Loss: 3.7820442e-05\n",
            "Loss: 3.7791713e-05\n",
            "Loss: 3.7771824e-05\n",
            "Loss: 3.7943188e-05\n",
            "Loss: 3.7759903e-05\n",
            "Loss: 3.7739897e-05\n",
            "Loss: 3.7703667e-05\n",
            "Loss: 3.765827e-05\n",
            "Loss: 3.7600596e-05\n",
            "Loss: 3.759662e-05\n",
            "Loss: 3.7549522e-05\n",
            "Loss: 3.7456546e-05\n",
            "Loss: 3.731608e-05\n",
            "Loss: 3.7285423e-05\n",
            "Loss: 3.7265618e-05\n",
            "Loss: 3.7261798e-05\n",
            "Loss: 3.725062e-05\n",
            "Loss: 3.723152e-05\n",
            "Loss: 3.7225782e-05\n",
            "Loss: 3.7214566e-05\n",
            "Loss: 3.7198824e-05\n",
            "Loss: 3.7172962e-05\n",
            "Loss: 3.7138685e-05\n",
            "Loss: 3.7103775e-05\n",
            "Loss: 3.7080557e-05\n",
            "Loss: 3.705824e-05\n",
            "Loss: 3.7041398e-05\n",
            "Loss: 3.7008525e-05\n",
            "Loss: 3.72645e-05\n",
            "Loss: 3.6979334e-05\n",
            "Loss: 3.700359e-05\n",
            "Loss: 3.6960337e-05\n",
            "Loss: 3.693587e-05\n",
            "Loss: 3.7035483e-05\n",
            "Loss: 3.691872e-05\n",
            "Loss: 3.690129e-05\n",
            "Loss: 3.688459e-05\n",
            "Loss: 3.686788e-05\n",
            "Loss: 3.6840942e-05\n",
            "Loss: 3.682053e-05\n",
            "Loss: 3.6802503e-05\n",
            "Loss: 3.7592526e-05\n",
            "Loss: 3.6791207e-05\n",
            "Loss: 3.6764097e-05\n",
            "Loss: 3.6730926e-05\n",
            "Loss: 3.671519e-05\n",
            "Loss: 3.6702204e-05\n",
            "Loss: 3.665576e-05\n",
            "Loss: 3.659949e-05\n",
            "Loss: 3.659127e-05\n",
            "Loss: 3.653051e-05\n",
            "Loss: 3.6511803e-05\n",
            "Loss: 3.6511727e-05\n",
            "Loss: 3.6502624e-05\n",
            "Loss: 3.6487196e-05\n",
            "Loss: 3.647357e-05\n",
            "Loss: 3.645575e-05\n",
            "Loss: 3.6431906e-05\n",
            "Loss: 3.6399746e-05\n",
            "Loss: 3.6369052e-05\n",
            "Loss: 3.6340396e-05\n",
            "Loss: 3.6297184e-05\n",
            "Loss: 3.624548e-05\n",
            "Loss: 3.620066e-05\n",
            "Loss: 3.615318e-05\n",
            "Loss: 3.6125995e-05\n",
            "Loss: 3.609889e-05\n",
            "Loss: 3.6076388e-05\n",
            "Loss: 3.6051708e-05\n",
            "Loss: 3.602738e-05\n",
            "Loss: 3.6001526e-05\n",
            "Loss: 3.599074e-05\n",
            "Loss: 3.7528338e-05\n",
            "Loss: 3.5984827e-05\n",
            "Loss: 3.5964833e-05\n",
            "Loss: 3.5948873e-05\n",
            "Loss: 3.5933546e-05\n",
            "Loss: 3.59079e-05\n",
            "Loss: 3.589769e-05\n",
            "Loss: 3.5893838e-05\n",
            "Loss: 3.5884055e-05\n",
            "Loss: 3.587622e-05\n",
            "Loss: 3.5869092e-05\n",
            "Loss: 3.5871308e-05\n",
            "Loss: 3.5861194e-05\n",
            "Loss: 3.5851535e-05\n",
            "Loss: 3.5840945e-05\n",
            "Loss: 3.5831574e-05\n",
            "Loss: 3.5815952e-05\n",
            "Loss: 3.5801546e-05\n",
            "Loss: 3.5807825e-05\n",
            "Loss: 3.5785128e-05\n",
            "Loss: 3.579235e-05\n",
            "Loss: 3.5772904e-05\n",
            "Loss: 3.5760564e-05\n",
            "Loss: 3.574763e-05\n",
            "Loss: 3.5738234e-05\n",
            "Loss: 3.5724977e-05\n",
            "Loss: 3.6808182e-05\n",
            "Loss: 3.571571e-05\n",
            "Loss: 3.5703655e-05\n",
            "Loss: 3.5675665e-05\n",
            "Loss: 3.5659723e-05\n",
            "Loss: 3.5638583e-05\n",
            "Loss: 3.5651065e-05\n",
            "Loss: 3.5631743e-05\n",
            "Loss: 3.562211e-05\n",
            "Loss: 3.561036e-05\n",
            "Loss: 3.5608733e-05\n",
            "Loss: 3.5602203e-05\n",
            "Loss: 3.5594217e-05\n",
            "Loss: 3.557538e-05\n",
            "Loss: 3.5898418e-05\n",
            "Loss: 3.556977e-05\n",
            "Loss: 3.5550514e-05\n",
            "Loss: 3.556515e-05\n",
            "Loss: 3.5532998e-05\n",
            "Loss: 3.551537e-05\n",
            "Loss: 3.5495596e-05\n",
            "Loss: 3.5536166e-05\n",
            "Loss: 3.5480454e-05\n",
            "Loss: 3.5448742e-05\n",
            "Loss: 3.5392564e-05\n",
            "Loss: 3.5309735e-05\n",
            "Loss: 3.5278004e-05\n",
            "Loss: 3.523034e-05\n",
            "Loss: 3.5210665e-05\n",
            "Loss: 3.5167308e-05\n",
            "Loss: 3.5134028e-05\n",
            "Loss: 3.5105702e-05\n",
            "Loss: 3.5085708e-05\n",
            "Loss: 3.5072582e-05\n",
            "Loss: 3.5062498e-05\n",
            "Loss: 3.5041463e-05\n",
            "Loss: 3.504296e-05\n",
            "Loss: 3.5034995e-05\n",
            "Loss: 3.5067555e-05\n",
            "Loss: 3.5021858e-05\n",
            "Loss: 3.501563e-05\n",
            "Loss: 3.4998364e-05\n",
            "Loss: 3.4984903e-05\n",
            "Loss: 3.4963636e-05\n",
            "Loss: 3.49459e-05\n",
            "Loss: 3.491032e-05\n",
            "Loss: 3.4919947e-05\n",
            "Loss: 3.4903143e-05\n",
            "Loss: 3.4892902e-05\n",
            "Loss: 3.488991e-05\n",
            "Loss: 3.4863915e-05\n",
            "Loss: 3.482745e-05\n",
            "Loss: 3.4785786e-05\n",
            "Loss: 3.4757766e-05\n",
            "Loss: 3.500952e-05\n",
            "Loss: 3.474982e-05\n",
            "Loss: 3.470767e-05\n",
            "Loss: 3.4649245e-05\n",
            "Loss: 3.461972e-05\n",
            "Loss: 3.458385e-05\n",
            "Loss: 3.456548e-05\n",
            "Loss: 3.455103e-05\n",
            "Loss: 3.4538487e-05\n",
            "Loss: 3.4531105e-05\n",
            "Loss: 3.452413e-05\n",
            "Loss: 3.4517267e-05\n",
            "Loss: 3.4508972e-05\n",
            "Loss: 3.4496687e-05\n",
            "Loss: 3.4485172e-05\n",
            "Loss: 3.4479468e-05\n",
            "Loss: 3.4468823e-05\n",
            "Loss: 3.448993e-05\n",
            "Loss: 3.445844e-05\n",
            "Loss: 3.444009e-05\n",
            "Loss: 3.4419914e-05\n",
            "Loss: 3.4402095e-05\n",
            "Loss: 3.438677e-05\n",
            "Loss: 3.4371613e-05\n",
            "Loss: 3.43624e-05\n",
            "Loss: 3.4351702e-05\n",
            "Loss: 3.4340155e-05\n",
            "Loss: 3.4337783e-05\n",
            "Loss: 3.4290795e-05\n",
            "Loss: 3.4267505e-05\n",
            "Loss: 3.424595e-05\n",
            "Loss: 3.4230303e-05\n",
            "Loss: 3.4217926e-05\n",
            "Loss: 3.420895e-05\n",
            "Loss: 3.4197867e-05\n",
            "Loss: 3.4193563e-05\n",
            "Loss: 3.4174383e-05\n",
            "Loss: 3.4163102e-05\n",
            "Loss: 3.415784e-05\n",
            "Loss: 3.415029e-05\n",
            "Loss: 3.4270233e-05\n",
            "Loss: 3.4145254e-05\n",
            "Loss: 3.4139965e-05\n",
            "Loss: 3.410631e-05\n",
            "Loss: 3.408485e-05\n",
            "Loss: 3.40653e-05\n",
            "Loss: 3.4045694e-05\n",
            "Loss: 3.402417e-05\n",
            "Loss: 3.400866e-05\n",
            "Loss: 3.3993096e-05\n",
            "Loss: 3.397178e-05\n",
            "Loss: 3.3941393e-05\n",
            "Loss: 3.4050812e-05\n",
            "Loss: 3.3928936e-05\n",
            "Loss: 3.3909142e-05\n",
            "Loss: 3.3890374e-05\n",
            "Loss: 3.388151e-05\n",
            "Loss: 3.386554e-05\n",
            "Loss: 3.4158562e-05\n",
            "Loss: 3.386209e-05\n",
            "Loss: 3.3852662e-05\n",
            "Loss: 3.382958e-05\n",
            "Loss: 3.4016273e-05\n",
            "Loss: 3.382101e-05\n",
            "Loss: 3.380123e-05\n",
            "Loss: 3.3792185e-05\n",
            "Loss: 3.3776632e-05\n",
            "Loss: 3.3769113e-05\n",
            "Loss: 3.376051e-05\n",
            "Loss: 3.3800763e-05\n",
            "Loss: 3.375852e-05\n",
            "Loss: 3.3753822e-05\n",
            "Loss: 3.3741417e-05\n",
            "Loss: 3.371237e-05\n",
            "Loss: 3.3676355e-05\n",
            "Loss: 3.366464e-05\n",
            "Loss: 3.3674256e-05\n",
            "Loss: 3.3661043e-05\n",
            "Loss: 3.3655306e-05\n",
            "Loss: 3.3647033e-05\n",
            "Loss: 3.3640295e-05\n",
            "Loss: 3.3624474e-05\n",
            "Loss: 3.3658627e-05\n",
            "Loss: 3.3617944e-05\n",
            "Loss: 3.3582437e-05\n",
            "Loss: 3.35469e-05\n",
            "Loss: 3.3512668e-05\n",
            "Loss: 3.3505843e-05\n",
            "Loss: 3.364453e-05\n",
            "Loss: 3.3504475e-05\n",
            "Loss: 3.348261e-05\n",
            "Loss: 3.344971e-05\n",
            "Loss: 3.4108685e-05\n",
            "Loss: 3.3432254e-05\n",
            "Loss: 3.3391043e-05\n",
            "Loss: 3.3364155e-05\n",
            "Loss: 3.333609e-05\n",
            "Loss: 3.4263507e-05\n",
            "Loss: 3.331517e-05\n",
            "Loss: 3.3282777e-05\n",
            "Loss: 3.3242937e-05\n",
            "Loss: 3.3229357e-05\n",
            "Loss: 3.3859214e-05\n",
            "Loss: 3.3223823e-05\n",
            "Loss: 3.3184464e-05\n",
            "Loss: 3.3158827e-05\n",
            "Loss: 3.3109976e-05\n",
            "Loss: 3.309117e-05\n",
            "Loss: 3.3074113e-05\n",
            "Loss: 3.3043045e-05\n",
            "Loss: 3.3019518e-05\n",
            "Loss: 3.299286e-05\n",
            "Loss: 3.29738e-05\n",
            "Loss: 3.294438e-05\n",
            "Loss: 3.2910277e-05\n",
            "Loss: 3.2862743e-05\n",
            "Loss: 3.2828204e-05\n",
            "Loss: 3.2799642e-05\n",
            "Loss: 3.2775668e-05\n",
            "Loss: 3.2747663e-05\n",
            "Loss: 3.2721793e-05\n",
            "Loss: 3.2704425e-05\n",
            "Loss: 3.2692726e-05\n",
            "Loss: 3.2758635e-05\n",
            "Loss: 3.2690416e-05\n",
            "Loss: 3.2681353e-05\n",
            "Loss: 3.267689e-05\n",
            "Loss: 3.2657837e-05\n",
            "Loss: 3.265862e-05\n",
            "Loss: 3.2652933e-05\n",
            "Loss: 3.264056e-05\n",
            "Loss: 3.2625758e-05\n",
            "Loss: 3.260941e-05\n",
            "Loss: 3.2592427e-05\n",
            "Loss: 3.2589523e-05\n",
            "Loss: 3.2592834e-05\n",
            "Loss: 3.257153e-05\n",
            "Loss: 3.2550877e-05\n",
            "Loss: 3.2527718e-05\n",
            "Loss: 3.2507185e-05\n",
            "Loss: 3.2488046e-05\n",
            "Loss: 3.247918e-05\n",
            "Loss: 3.2444514e-05\n",
            "Loss: 3.239688e-05\n",
            "Loss: 3.2362193e-05\n",
            "Loss: 3.2304706e-05\n",
            "Loss: 3.2287593e-05\n",
            "Loss: 3.221901e-05\n",
            "Loss: 3.218305e-05\n",
            "Loss: 3.2195865e-05\n",
            "Loss: 3.216372e-05\n",
            "Loss: 3.2130334e-05\n",
            "Loss: 3.2117914e-05\n",
            "Loss: 3.210577e-05\n",
            "Loss: 3.2078155e-05\n",
            "Loss: 3.2054948e-05\n",
            "Loss: 3.2044638e-05\n",
            "Loss: 3.20369e-05\n",
            "Loss: 3.202348e-05\n",
            "Loss: 3.2015458e-05\n",
            "Loss: 3.2003827e-05\n",
            "Loss: 3.1987558e-05\n",
            "Loss: 3.1966407e-05\n",
            "Loss: 3.193556e-05\n",
            "Loss: 3.1925018e-05\n",
            "Loss: 3.190007e-05\n",
            "Loss: 3.1884887e-05\n",
            "Loss: 3.1868654e-05\n",
            "Loss: 3.1858937e-05\n",
            "Loss: 3.189256e-05\n",
            "Loss: 3.1856838e-05\n",
            "Loss: 3.1858388e-05\n",
            "Loss: 3.1852265e-05\n",
            "Loss: 3.1848158e-05\n",
            "Loss: 3.184297e-05\n",
            "Loss: 3.183787e-05\n",
            "Loss: 3.1829484e-05\n",
            "Loss: 3.1817654e-05\n",
            "Loss: 3.18045e-05\n",
            "Loss: 3.2632663e-05\n",
            "Loss: 3.1799238e-05\n",
            "Loss: 3.1785028e-05\n",
            "Loss: 3.177514e-05\n",
            "Loss: 3.2178043e-05\n",
            "Loss: 3.176843e-05\n",
            "Loss: 3.1750267e-05\n",
            "Loss: 3.173523e-05\n",
            "Loss: 3.1720378e-05\n",
            "Loss: 3.2069125e-05\n",
            "Loss: 3.171676e-05\n",
            "Loss: 3.170761e-05\n",
            "Loss: 3.1696e-05\n",
            "Loss: 3.1671072e-05\n",
            "Loss: 3.164635e-05\n",
            "Loss: 3.1635576e-05\n",
            "Loss: 3.1631847e-05\n",
            "Loss: 3.1602234e-05\n",
            "Loss: 3.1585943e-05\n",
            "Loss: 3.1561936e-05\n",
            "Loss: 3.154102e-05\n",
            "Loss: 3.1517204e-05\n",
            "Loss: 3.3510183e-05\n",
            "Loss: 3.151085e-05\n",
            "Loss: 3.148921e-05\n",
            "Loss: 3.1458352e-05\n",
            "Loss: 3.1437696e-05\n",
            "Loss: 3.1403804e-05\n",
            "Loss: 3.1375857e-05\n",
            "Loss: 3.134483e-05\n",
            "Loss: 3.1315023e-05\n",
            "Loss: 3.1297663e-05\n",
            "Loss: 3.129126e-05\n",
            "Loss: 3.128443e-05\n",
            "Loss: 3.1274172e-05\n",
            "Loss: 3.1280586e-05\n",
            "Loss: 3.1268588e-05\n",
            "Loss: 3.12552e-05\n",
            "Loss: 3.124286e-05\n",
            "Loss: 3.1233605e-05\n",
            "Loss: 3.1223448e-05\n",
            "Loss: 3.120907e-05\n",
            "Loss: 3.118714e-05\n",
            "Loss: 3.1626652e-05\n",
            "Loss: 3.1183183e-05\n",
            "Loss: 3.1165477e-05\n",
            "Loss: 3.117859e-05\n",
            "Loss: 3.1155752e-05\n",
            "Loss: 3.1142754e-05\n",
            "Loss: 3.110171e-05\n",
            "Loss: 3.1072574e-05\n",
            "Loss: 3.1067124e-05\n",
            "Loss: 3.1041778e-05\n",
            "Loss: 3.1032814e-05\n",
            "Loss: 3.1021937e-05\n",
            "Loss: 3.1010346e-05\n",
            "Loss: 3.1004052e-05\n",
            "Loss: 3.099933e-05\n",
            "Loss: 3.0995325e-05\n",
            "Loss: 3.09852e-05\n",
            "Loss: 3.1097938e-05\n",
            "Loss: 3.0978e-05\n",
            "Loss: 3.097329e-05\n",
            "Loss: 3.096633e-05\n",
            "Loss: 3.096362e-05\n",
            "Loss: 3.0941803e-05\n",
            "Loss: 3.1273397e-05\n",
            "Loss: 3.0935425e-05\n",
            "Loss: 3.0902804e-05\n",
            "Loss: 3.0890846e-05\n",
            "Loss: 3.0876137e-05\n",
            "Loss: 3.0866177e-05\n",
            "Loss: 3.0851385e-05\n",
            "Loss: 3.0924366e-05\n",
            "Loss: 3.0841024e-05\n",
            "Loss: 3.083511e-05\n",
            "Loss: 3.0822783e-05\n",
            "Loss: 3.084534e-05\n",
            "Loss: 3.0818403e-05\n",
            "Loss: 3.0809806e-05\n",
            "Loss: 3.0790627e-05\n",
            "Loss: 3.0778443e-05\n",
            "Loss: 3.0783216e-05\n",
            "Loss: 3.0762774e-05\n",
            "Loss: 3.0737618e-05\n",
            "Loss: 3.071616e-05\n",
            "Loss: 3.069673e-05\n",
            "Loss: 3.066808e-05\n",
            "Loss: 3.0646715e-05\n",
            "Loss: 3.062842e-05\n",
            "Loss: 3.0657495e-05\n",
            "Loss: 3.0623385e-05\n",
            "Loss: 3.060996e-05\n",
            "Loss: 3.0567502e-05\n",
            "Loss: 3.0535582e-05\n",
            "Loss: 3.0497513e-05\n",
            "Loss: 3.0478852e-05\n",
            "Loss: 3.0480089e-05\n",
            "Loss: 3.0465653e-05\n",
            "Loss: 3.0455993e-05\n",
            "Loss: 3.0430636e-05\n",
            "Loss: 3.040639e-05\n",
            "Loss: 3.0382846e-05\n",
            "Loss: 3.0359754e-05\n",
            "Loss: 3.0328583e-05\n",
            "Loss: 3.0278095e-05\n",
            "Loss: 3.2843465e-05\n",
            "Loss: 3.026184e-05\n",
            "Loss: 3.0234198e-05\n",
            "Loss: 3.0202482e-05\n",
            "Loss: 3.0183623e-05\n",
            "Loss: 3.015182e-05\n",
            "Loss: 3.0129424e-05\n",
            "Loss: 3.014417e-05\n",
            "Loss: 3.0118528e-05\n",
            "Loss: 3.0106079e-05\n",
            "Loss: 3.0092604e-05\n",
            "Loss: 3.0085881e-05\n",
            "Loss: 3.0072531e-05\n",
            "Loss: 3.00539e-05\n",
            "Loss: 3.0043095e-05\n",
            "Loss: 3.0029167e-05\n",
            "Loss: 3.0011091e-05\n",
            "Loss: 3.0005971e-05\n",
            "Loss: 2.9980503e-05\n",
            "Loss: 2.9971474e-05\n",
            "Loss: 3.0018962e-05\n",
            "Loss: 2.9961471e-05\n",
            "Loss: 2.994615e-05\n",
            "Loss: 2.9910867e-05\n",
            "Loss: 2.9886542e-05\n",
            "Loss: 2.9840809e-05\n",
            "Loss: 2.979974e-05\n",
            "Loss: 3.9282888e-05\n",
            "Loss: 2.978065e-05\n",
            "Loss: 2.972376e-05\n",
            "Loss: 2.966627e-05\n",
            "Loss: 2.9630619e-05\n",
            "Loss: 2.9604378e-05\n",
            "Loss: 2.9586448e-05\n",
            "Loss: 2.9558767e-05\n",
            "Loss: 2.952389e-05\n",
            "Loss: 2.9500008e-05\n",
            "Loss: 2.9479423e-05\n",
            "Loss: 2.946744e-05\n",
            "Loss: 2.9448716e-05\n",
            "Loss: 2.944029e-05\n",
            "Loss: 2.9434379e-05\n",
            "Loss: 2.9404691e-05\n",
            "Loss: 2.9377528e-05\n",
            "Loss: 2.9349145e-05\n",
            "Loss: 2.9422257e-05\n",
            "Loss: 2.9335866e-05\n",
            "Loss: 2.9312454e-05\n",
            "Loss: 2.9287294e-05\n",
            "Loss: 2.9841925e-05\n",
            "Loss: 2.9282299e-05\n",
            "Loss: 2.9258776e-05\n",
            "Loss: 2.9230034e-05\n",
            "Loss: 2.935841e-05\n",
            "Loss: 2.9205614e-05\n",
            "Loss: 2.9149962e-05\n",
            "Loss: 2.9116345e-05\n",
            "Loss: 2.9099945e-05\n",
            "Loss: 2.907827e-05\n",
            "Loss: 2.905836e-05\n",
            "Loss: 2.904924e-05\n",
            "Loss: 2.9336185e-05\n",
            "Loss: 2.9033145e-05\n",
            "Loss: 2.9009168e-05\n",
            "Loss: 2.8984714e-05\n",
            "Loss: 2.894704e-05\n",
            "Loss: 2.900819e-05\n",
            "Loss: 2.8933857e-05\n",
            "Loss: 2.9501092e-05\n",
            "Loss: 2.8895096e-05\n",
            "Loss: 2.8873474e-05\n",
            "Loss: 2.9394036e-05\n",
            "Loss: 2.8836595e-05\n",
            "Loss: 2.8819431e-05\n",
            "Loss: 2.880367e-05\n",
            "Loss: 2.8773986e-05\n",
            "Loss: 2.8774832e-05\n",
            "Loss: 2.8757915e-05\n",
            "Loss: 2.8721148e-05\n",
            "Loss: 2.869362e-05\n",
            "Loss: 2.86516e-05\n",
            "Loss: 2.8615306e-05\n",
            "Loss: 2.8587585e-05\n",
            "Loss: 2.8826089e-05\n",
            "Loss: 2.8581242e-05\n",
            "Loss: 2.8567987e-05\n",
            "Loss: 2.855017e-05\n",
            "Loss: 2.8522514e-05\n",
            "Loss: 2.8487808e-05\n",
            "Loss: 2.8472403e-05\n",
            "Loss: 2.8458513e-05\n",
            "Loss: 2.8444329e-05\n",
            "Loss: 2.8437984e-05\n",
            "Loss: 2.8429178e-05\n",
            "Loss: 2.8417468e-05\n",
            "Loss: 2.9593004e-05\n",
            "Loss: 2.8413979e-05\n",
            "Loss: 2.8398787e-05\n",
            "Loss: 2.8384591e-05\n",
            "Loss: 2.8373172e-05\n",
            "Loss: 2.8361399e-05\n",
            "Loss: 2.8721643e-05\n",
            "Loss: 2.8359544e-05\n",
            "Loss: 2.8346478e-05\n",
            "Loss: 2.8315306e-05\n",
            "Loss: 2.8293955e-05\n",
            "Loss: 2.828275e-05\n",
            "Loss: 2.8273327e-05\n",
            "Loss: 2.8262326e-05\n",
            "Loss: 2.8247432e-05\n",
            "Loss: 2.8231969e-05\n",
            "Loss: 2.8221444e-05\n",
            "Loss: 2.8208995e-05\n",
            "Loss: 2.8193816e-05\n",
            "Loss: 2.8164155e-05\n",
            "Loss: 5.656239e-05\n",
            "Loss: 2.8151688e-05\n",
            "Loss: 2.806579e-05\n",
            "Loss: 2.8013943e-05\n",
            "Loss: 2.7955532e-05\n",
            "Loss: 2.7908944e-05\n",
            "Loss: 2.7878925e-05\n",
            "Loss: 2.7863442e-05\n",
            "Loss: 2.7834103e-05\n",
            "Loss: 2.7794005e-05\n",
            "Loss: 2.7764341e-05\n",
            "Loss: 2.7734906e-05\n",
            "Loss: 2.7717342e-05\n",
            "Loss: 2.7706074e-05\n",
            "Loss: 2.770023e-05\n",
            "Loss: 2.8000313e-05\n",
            "Loss: 2.7697264e-05\n",
            "Loss: 2.7684098e-05\n",
            "Loss: 2.766645e-05\n",
            "Loss: 2.7649246e-05\n",
            "Loss: 2.7628777e-05\n",
            "Loss: 2.7596316e-05\n",
            "Loss: 2.7540947e-05\n",
            "Loss: 2.7515973e-05\n",
            "Loss: 2.7505574e-05\n",
            "Loss: 2.7492693e-05\n",
            "Loss: 2.7473434e-05\n",
            "Loss: 2.7445607e-05\n",
            "Loss: 2.745534e-05\n",
            "Loss: 2.7429101e-05\n",
            "Loss: 2.7405153e-05\n",
            "Loss: 2.7376587e-05\n",
            "Loss: 2.7361551e-05\n",
            "Loss: 3.107821e-05\n",
            "Loss: 2.735895e-05\n",
            "Loss: 2.7336118e-05\n",
            "Loss: 2.730681e-05\n",
            "Loss: 2.7279924e-05\n",
            "Loss: 2.7255108e-05\n",
            "Loss: 2.7231641e-05\n",
            "Loss: 2.7197098e-05\n",
            "Loss: 2.723818e-05\n",
            "Loss: 2.7181084e-05\n",
            "Loss: 2.7156637e-05\n",
            "Loss: 2.7128539e-05\n",
            "Loss: 2.710287e-05\n",
            "Loss: 2.707809e-05\n",
            "Loss: 2.7054677e-05\n",
            "Loss: 2.7039108e-05\n",
            "Loss: 2.7029273e-05\n",
            "Loss: 2.7200958e-05\n",
            "Loss: 2.701908e-05\n",
            "Loss: 2.7003583e-05\n",
            "Loss: 2.6986916e-05\n",
            "Loss: 2.6973437e-05\n",
            "Loss: 2.6958662e-05\n",
            "Loss: 2.6944157e-05\n",
            "Loss: 2.6930595e-05\n",
            "Loss: 2.691198e-05\n",
            "Loss: 2.689844e-05\n",
            "Loss: 2.6890553e-05\n",
            "Loss: 2.6880058e-05\n",
            "Loss: 2.6865178e-05\n",
            "Loss: 2.6845019e-05\n",
            "Loss: 2.682594e-05\n",
            "Loss: 2.7394333e-05\n",
            "Loss: 2.6820686e-05\n",
            "Loss: 2.6792362e-05\n",
            "Loss: 2.6766687e-05\n",
            "Loss: 2.6755886e-05\n",
            "Loss: 2.674394e-05\n",
            "Loss: 2.6735082e-05\n",
            "Loss: 2.6720569e-05\n",
            "Loss: 2.6711432e-05\n",
            "Loss: 2.669477e-05\n",
            "Loss: 2.667994e-05\n",
            "Loss: 2.6668975e-05\n",
            "Loss: 2.6650909e-05\n",
            "Loss: 2.662389e-05\n",
            "Loss: 2.6671842e-05\n",
            "Loss: 2.6616039e-05\n",
            "Loss: 2.6608215e-05\n",
            "Loss: 2.658403e-05\n",
            "Loss: 2.6552487e-05\n",
            "Loss: 2.651237e-05\n",
            "Loss: 2.6478294e-05\n",
            "Loss: 2.6450862e-05\n",
            "Loss: 2.6443244e-05\n",
            "Loss: 2.6432985e-05\n",
            "Loss: 2.6416432e-05\n",
            "Loss: 2.6413349e-05\n",
            "Loss: 2.6417207e-05\n",
            "Loss: 2.640666e-05\n",
            "Loss: 2.6403335e-05\n",
            "Loss: 2.6398086e-05\n",
            "Loss: 2.6381806e-05\n",
            "Loss: 2.635966e-05\n",
            "Loss: 2.7004926e-05\n",
            "Loss: 2.6359703e-05\n",
            "Loss: 2.6359707e-05\n",
            "Loss: 2.6360654e-05\n",
            "Loss: 2.6360856e-05\n",
            "Loss: 2.6359477e-05\n",
            "Loss: 2.6359477e-05\n",
            "Loss: 2.6360103e-05\n",
            "Loss: 2.635948e-05\n",
            "Loss: 2.6359477e-05\n",
            "Loss: 2.6359477e-05\n",
            "Loss: 2.6359477e-05\n",
            "Loss: 2.6359477e-05\n",
            "Loss: 2.6359477e-05\n",
            "Loss: 2.635948e-05\n",
            "Loss: 2.6359477e-05\n",
            "Loss: 5.131073e-05\n",
            "Loss: 2.6359612e-05\n",
            "Loss: 2.6360154e-05\n",
            "Loss: 2.6359532e-05\n",
            "Loss: 2.6360378e-05\n",
            "Loss: 2.6359463e-05\n",
            "Loss: 2.63595e-05\n",
            "Loss: 2.6359463e-05\n",
            "Loss: 2.6359463e-05\n",
            "Loss: 2.6359581e-05\n",
            "Loss: 2.6359463e-05\n",
            "Loss: 2.6359463e-05\n",
            "Loss: 2.6359463e-05\n",
            "Loss: 2.6359463e-05\n",
            "Loss: 2.6359463e-05\n",
            "Loss: 2.635947e-05\n",
            "Loss: 2.6359463e-05\n",
            "Loss: 5.1322208e-05\n",
            "Loss: 2.636017e-05\n",
            "Loss: 2.6359588e-05\n",
            "Loss: 2.6359581e-05\n",
            "Loss: 2.6361491e-05\n",
            "Loss: 2.6359676e-05\n",
            "Loss: 2.6359463e-05\n",
            "Loss: 2.6359463e-05\n",
            "Loss: 2.635947e-05\n",
            "Loss: 2.6359463e-05\n",
            "Loss: 2.6359463e-05\n",
            "Loss: 2.6359452e-05\n",
            "Loss: 2.6359452e-05\n",
            "Loss: 2.6359452e-05\n",
            "Loss: 2.635947e-05\n",
            "Loss: 2.6359452e-05\n",
            "Loss: 2.6359452e-05\n",
            "Loss: 2.6359452e-05\n",
            "Loss: 2.6359452e-05\n",
            "Loss: 2.6359452e-05\n",
            "Loss: 2.6359452e-05\n",
            "Loss: 2.6359452e-05\n",
            "Loss: 2.6533975e-05\n",
            "Loss: 2.6359401e-05\n",
            "Loss: 2.6347854e-05\n",
            "Loss: 2.634781e-05\n",
            "Loss: 2.634204e-05\n",
            "Loss: 2.8700857e-05\n",
            "Loss: 2.633995e-05\n",
            "Loss: 2.637053e-05\n",
            "Loss: 2.632703e-05\n",
            "Loss: 2.6316227e-05\n",
            "Loss: 2.6296879e-05\n",
            "Loss: 2.6284277e-05\n",
            "Loss: 2.6285532e-05\n",
            "Loss: 2.6264297e-05\n",
            "Loss: 2.6230855e-05\n",
            "Loss: 2.6216125e-05\n",
            "Loss: 2.6208574e-05\n",
            "Loss: 2.6201673e-05\n",
            "Loss: 2.6192047e-05\n",
            "Loss: 2.618246e-05\n",
            "Loss: 2.617443e-05\n",
            "Loss: 2.6169528e-05\n",
            "Loss: 2.6172684e-05\n",
            "Loss: 2.6163596e-05\n",
            "Loss: 2.614205e-05\n",
            "Loss: 2.6121355e-05\n",
            "Loss: 2.610533e-05\n",
            "Loss: 2.6098902e-05\n",
            "Loss: 2.6088184e-05\n",
            "Loss: 2.6075615e-05\n",
            "Loss: 2.6618372e-05\n",
            "Loss: 2.6068585e-05\n",
            "Loss: 2.6046562e-05\n",
            "Loss: 2.6037153e-05\n",
            "Loss: 2.5983309e-05\n",
            "Loss: 2.5963496e-05\n",
            "Loss: 2.5932679e-05\n",
            "Loss: 2.5894107e-05\n",
            "Loss: 2.5849575e-05\n",
            "Loss: 2.581067e-05\n",
            "Loss: 2.578624e-05\n",
            "Loss: 2.5771737e-05\n",
            "Loss: 2.5750782e-05\n",
            "Loss: 2.5736092e-05\n",
            "Loss: 2.5720827e-05\n",
            "Loss: 2.572702e-05\n",
            "Loss: 2.5715002e-05\n",
            "Loss: 2.5703155e-05\n",
            "Loss: 2.5690297e-05\n",
            "Loss: 2.5677591e-05\n",
            "Loss: 2.5666966e-05\n",
            "Loss: 2.5648575e-05\n",
            "Loss: 2.5621104e-05\n",
            "Loss: 2.6010566e-05\n",
            "Loss: 2.5615456e-05\n",
            "Loss: 2.5585228e-05\n",
            "Loss: 2.5536443e-05\n",
            "Loss: 2.546692e-05\n",
            "Loss: 9.595553e-05\n",
            "Loss: 2.5535752e-05\n",
            "Loss: 2.5464042e-05\n",
            "Loss: 2.5432471e-05\n",
            "Loss: 2.5419116e-05\n",
            "Loss: 2.5407888e-05\n",
            "Loss: 2.5403962e-05\n",
            "Loss: 2.5400033e-05\n",
            "Loss: 2.5394993e-05\n",
            "Loss: 2.5391157e-05\n",
            "Loss: 2.5379888e-05\n",
            "Loss: 2.5355956e-05\n",
            "Loss: 2.531814e-05\n",
            "Loss: 2.5286781e-05\n",
            "Loss: 2.5295085e-05\n",
            "Loss: 2.5275951e-05\n",
            "Loss: 2.5258352e-05\n",
            "Loss: 2.5249932e-05\n",
            "Loss: 2.523e-05\n",
            "Loss: 2.5219191e-05\n",
            "Loss: 2.525148e-05\n",
            "Loss: 2.5211026e-05\n",
            "Loss: 2.5192301e-05\n",
            "Loss: 2.5176907e-05\n",
            "Loss: 2.5159707e-05\n",
            "Loss: 2.5129964e-05\n",
            "Loss: 2.5111092e-05\n",
            "Loss: 2.5084484e-05\n",
            "Loss: 2.5055979e-05\n",
            "Loss: 2.509507e-05\n",
            "Loss: 2.5034522e-05\n",
            "Loss: 2.501367e-05\n",
            "Loss: 2.498537e-05\n",
            "Loss: 2.4975112e-05\n",
            "Loss: 2.4951514e-05\n",
            "Loss: 2.4931995e-05\n",
            "Loss: 2.4906061e-05\n",
            "Loss: 2.489087e-05\n",
            "Loss: 2.4858544e-05\n",
            "Loss: 2.4814497e-05\n",
            "Loss: 2.4795276e-05\n",
            "Loss: 2.4782315e-05\n",
            "Loss: 2.4776124e-05\n",
            "Loss: 2.4765182e-05\n",
            "Loss: 2.4741752e-05\n",
            "Loss: 2.470738e-05\n",
            "Loss: 2.4675037e-05\n",
            "Loss: 2.4653553e-05\n",
            "Loss: 2.4653355e-05\n",
            "Loss: 2.46427e-05\n",
            "Loss: 2.4629717e-05\n",
            "Loss: 2.4607267e-05\n",
            "Loss: 2.4594592e-05\n",
            "Loss: 2.457494e-05\n",
            "Loss: 2.456347e-05\n",
            "Loss: 2.5348036e-05\n",
            "Loss: 2.4555153e-05\n",
            "Loss: 2.4536743e-05\n",
            "Loss: 2.4509924e-05\n",
            "Loss: 3.479383e-05\n",
            "Loss: 2.4508197e-05\n",
            "Loss: 2.4485715e-05\n",
            "Loss: 2.6330852e-05\n",
            "Loss: 2.4485289e-05\n",
            "Loss: 2.446488e-05\n",
            "Loss: 2.4434828e-05\n",
            "Loss: 2.4474792e-05\n",
            "Loss: 2.4422e-05\n",
            "Loss: 2.4417657e-05\n",
            "Loss: 2.4404044e-05\n",
            "Loss: 2.4400128e-05\n",
            "Loss: 2.4386734e-05\n",
            "Loss: 2.4374578e-05\n",
            "Loss: 2.4353389e-05\n",
            "Loss: 2.442033e-05\n",
            "Loss: 2.4340892e-05\n",
            "Loss: 2.432241e-05\n",
            "Loss: 2.427555e-05\n",
            "Loss: 2.4258206e-05\n",
            "Loss: 2.4245812e-05\n",
            "Loss: 2.4237004e-05\n",
            "Loss: 2.4229877e-05\n",
            "Loss: 2.421546e-05\n",
            "Loss: 2.4202634e-05\n",
            "Loss: 2.422661e-05\n",
            "Loss: 2.4194887e-05\n",
            "Loss: 2.416856e-05\n",
            "Loss: 2.41604e-05\n",
            "Loss: 2.4143897e-05\n",
            "Loss: 2.4138057e-05\n",
            "Loss: 2.4131572e-05\n",
            "Loss: 2.4127667e-05\n",
            "Loss: 2.4116574e-05\n",
            "Loss: 2.4105328e-05\n",
            "Loss: 2.408323e-05\n",
            "Loss: 2.4063445e-05\n",
            "Loss: 2.4038092e-05\n",
            "Loss: 2.401941e-05\n",
            "Loss: 2.4008037e-05\n",
            "Loss: 2.4001141e-05\n",
            "Loss: 2.4077332e-05\n",
            "Loss: 2.3999244e-05\n",
            "Loss: 2.3989414e-05\n",
            "Loss: 2.3961295e-05\n",
            "Loss: 2.3930232e-05\n",
            "Loss: 2.3909972e-05\n",
            "Loss: 2.3883913e-05\n",
            "Loss: 2.3908804e-05\n",
            "Loss: 2.386551e-05\n",
            "Loss: 2.3844055e-05\n",
            "Loss: 2.3828421e-05\n",
            "Loss: 2.3819346e-05\n",
            "Loss: 2.379496e-05\n",
            "Loss: 2.3783254e-05\n",
            "Loss: 2.3773471e-05\n",
            "Loss: 2.3763994e-05\n",
            "Loss: 2.372939e-05\n",
            "Loss: 2.370796e-05\n",
            "Loss: 2.3693303e-05\n",
            "Loss: 2.3683484e-05\n",
            "Loss: 2.3670502e-05\n",
            "Loss: 2.3656055e-05\n",
            "Loss: 2.364565e-05\n",
            "Loss: 2.3625029e-05\n",
            "Loss: 2.3612574e-05\n",
            "Loss: 2.360049e-05\n",
            "Loss: 2.35847e-05\n",
            "Loss: 2.3559433e-05\n",
            "Loss: 2.3526845e-05\n",
            "Loss: 2.3489032e-05\n",
            "Loss: 2.4346027e-05\n",
            "Loss: 2.3468725e-05\n",
            "Loss: 2.3447366e-05\n",
            "Loss: 2.341948e-05\n",
            "Loss: 2.341007e-05\n",
            "Loss: 2.3502458e-05\n",
            "Loss: 2.3405588e-05\n",
            "Loss: 2.3383946e-05\n",
            "Loss: 2.3371205e-05\n",
            "Loss: 2.3349094e-05\n",
            "Loss: 2.3332686e-05\n",
            "Loss: 2.3313803e-05\n",
            "Loss: 2.3302222e-05\n",
            "Loss: 2.3286435e-05\n",
            "Loss: 2.327506e-05\n",
            "Loss: 2.3264623e-05\n",
            "Loss: 2.3254692e-05\n",
            "Loss: 2.3778266e-05\n",
            "Loss: 2.325054e-05\n",
            "Loss: 2.3239521e-05\n",
            "Loss: 2.3216655e-05\n",
            "Loss: 2.3197159e-05\n",
            "Loss: 2.3174132e-05\n",
            "Loss: 2.31572e-05\n",
            "Loss: 2.3149229e-05\n",
            "Loss: 2.3139526e-05\n",
            "Loss: 2.313465e-05\n",
            "Loss: 2.3273471e-05\n",
            "Loss: 2.3130753e-05\n",
            "Loss: 2.311573e-05\n",
            "Loss: 2.310274e-05\n",
            "Loss: 2.3100205e-05\n",
            "Loss: 2.3086222e-05\n",
            "Loss: 2.3082259e-05\n",
            "Loss: 2.3076507e-05\n",
            "Loss: 2.3071105e-05\n",
            "Loss: 2.306526e-05\n",
            "Loss: 2.3057928e-05\n",
            "Loss: 2.3070763e-05\n",
            "Loss: 2.3050641e-05\n",
            "Loss: 2.3033328e-05\n",
            "Loss: 2.3015475e-05\n",
            "Loss: 2.3011246e-05\n",
            "Loss: 2.2998438e-05\n",
            "Loss: 2.299542e-05\n",
            "Loss: 2.2988328e-05\n",
            "Loss: 2.29848e-05\n",
            "Loss: 2.2978928e-05\n",
            "Loss: 2.2968477e-05\n",
            "Loss: 2.2960463e-05\n",
            "Loss: 2.2950751e-05\n",
            "Loss: 2.2938246e-05\n",
            "Loss: 2.2924469e-05\n",
            "Loss: 2.2915603e-05\n",
            "Loss: 2.289707e-05\n",
            "Loss: 2.288052e-05\n",
            "Loss: 2.2873524e-05\n",
            "Loss: 2.285416e-05\n",
            "Loss: 2.2838514e-05\n",
            "Loss: 2.2826676e-05\n",
            "Loss: 2.2818238e-05\n",
            "Loss: 2.2807448e-05\n",
            "Loss: 2.279479e-05\n",
            "Loss: 2.2783797e-05\n",
            "Loss: 2.2771676e-05\n",
            "Loss: 2.2761113e-05\n",
            "Loss: 2.2750664e-05\n",
            "Loss: 2.2733815e-05\n",
            "Loss: 2.2715696e-05\n",
            "Loss: 2.26961e-05\n",
            "Loss: 2.2686947e-05\n",
            "Loss: 2.2681652e-05\n",
            "Loss: 2.2676712e-05\n",
            "Loss: 2.2669028e-05\n",
            "Loss: 2.2653372e-05\n",
            "Loss: 2.2701692e-05\n",
            "Loss: 2.2644304e-05\n",
            "Loss: 2.2823837e-05\n",
            "Loss: 2.2640157e-05\n",
            "Loss: 2.2628348e-05\n",
            "Loss: 2.2620323e-05\n",
            "Loss: 2.2696233e-05\n",
            "Loss: 2.261663e-05\n",
            "Loss: 2.2612536e-05\n",
            "Loss: 2.259807e-05\n",
            "Loss: 2.2590062e-05\n",
            "Loss: 2.2581982e-05\n",
            "Loss: 2.2653128e-05\n",
            "Loss: 2.2579137e-05\n",
            "Loss: 2.2573398e-05\n",
            "Loss: 2.2565184e-05\n",
            "Loss: 2.2560836e-05\n",
            "Loss: 2.2553098e-05\n",
            "Loss: 2.2548189e-05\n",
            "Loss: 2.254375e-05\n",
            "Loss: 2.2539356e-05\n",
            "Loss: 2.253182e-05\n",
            "Loss: 2.2538588e-05\n",
            "Loss: 2.2526578e-05\n",
            "Loss: 2.2519871e-05\n",
            "Loss: 2.2515263e-05\n",
            "Loss: 2.250939e-05\n",
            "Loss: 2.2506663e-05\n",
            "Loss: 2.2498582e-05\n",
            "Loss: 2.2495837e-05\n",
            "Loss: 2.249397e-05\n",
            "Loss: 2.2489341e-05\n",
            "Loss: 2.248826e-05\n",
            "Loss: 2.2485461e-05\n",
            "Loss: 2.2483448e-05\n",
            "Loss: 2.2479491e-05\n",
            "Loss: 2.2477827e-05\n",
            "Loss: 2.2473236e-05\n",
            "Loss: 2.2464912e-05\n",
            "Loss: 2.2453267e-05\n",
            "Loss: 2.2439537e-05\n",
            "Loss: 2.2422133e-05\n",
            "Loss: 2.2410833e-05\n",
            "Loss: 2.2400904e-05\n",
            "Loss: 2.23972e-05\n",
            "Loss: 2.239016e-05\n",
            "Loss: 2.2384906e-05\n",
            "Loss: 2.2375876e-05\n",
            "Loss: 2.2360402e-05\n",
            "Loss: 2.2339918e-05\n",
            "Loss: 2.23192e-05\n",
            "Loss: 2.2707234e-05\n",
            "Loss: 2.2312583e-05\n",
            "Loss: 2.23018e-05\n",
            "Loss: 2.2282871e-05\n",
            "Loss: 2.2266948e-05\n",
            "Loss: 2.2256454e-05\n",
            "Loss: 2.2247708e-05\n",
            "Loss: 2.245018e-05\n",
            "Loss: 2.224552e-05\n",
            "Loss: 2.2233771e-05\n",
            "Loss: 2.3158169e-05\n",
            "Loss: 2.222586e-05\n",
            "Loss: 2.2266911e-05\n",
            "Loss: 2.2222099e-05\n",
            "Loss: 2.2209246e-05\n",
            "Loss: 2.220158e-05\n",
            "Loss: 2.219438e-05\n",
            "Loss: 2.2185879e-05\n",
            "Loss: 2.2179871e-05\n",
            "Loss: 2.2171484e-05\n",
            "Loss: 2.2162254e-05\n",
            "Loss: 2.2157832e-05\n",
            "Loss: 2.2151113e-05\n",
            "Loss: 2.2144643e-05\n",
            "Loss: 2.2137083e-05\n",
            "Loss: 2.2129503e-05\n",
            "Loss: 2.2119033e-05\n",
            "Loss: 2.2114158e-05\n",
            "Loss: 2.2110497e-05\n",
            "Loss: 2.2105625e-05\n",
            "Loss: 2.2103639e-05\n",
            "Loss: 2.210028e-05\n",
            "Loss: 2.2090395e-05\n",
            "Loss: 2.2075928e-05\n",
            "Loss: 2.2067808e-05\n",
            "Loss: 2.2059063e-05\n",
            "Loss: 2.8613973e-05\n",
            "Loss: 2.205717e-05\n",
            "Loss: 2.2050262e-05\n",
            "Loss: 2.203791e-05\n",
            "Loss: 2.2029752e-05\n",
            "Loss: 2.2016762e-05\n",
            "Loss: 2.2041388e-05\n",
            "Loss: 2.2002563e-05\n",
            "Loss: 2.1987531e-05\n",
            "Loss: 2.1965545e-05\n",
            "Loss: 2.1957847e-05\n",
            "Loss: 2.1944858e-05\n",
            "Loss: 2.1931486e-05\n",
            "Loss: 2.217998e-05\n",
            "Loss: 2.1916227e-05\n",
            "Loss: 2.1895801e-05\n",
            "Loss: 2.1863982e-05\n",
            "Loss: 2.185429e-05\n",
            "Loss: 2.1841473e-05\n",
            "Loss: 2.1829097e-05\n",
            "Loss: 2.1813945e-05\n",
            "Loss: 2.1791273e-05\n",
            "Loss: 2.1769547e-05\n",
            "Loss: 2.1792514e-05\n",
            "Loss: 2.175577e-05\n",
            "Loss: 2.1737327e-05\n",
            "Loss: 2.1723903e-05\n",
            "Loss: 2.1718291e-05\n",
            "Loss: 2.1704138e-05\n",
            "Loss: 2.1682754e-05\n",
            "Loss: 2.1667223e-05\n",
            "Loss: 2.1665084e-05\n",
            "Loss: 2.1655447e-05\n",
            "Loss: 2.1651658e-05\n",
            "Loss: 2.1666203e-05\n",
            "Loss: 2.1636853e-05\n",
            "Loss: 2.1622556e-05\n",
            "Loss: 2.1603804e-05\n",
            "Loss: 2.1575208e-05\n",
            "Loss: 2.1541759e-05\n",
            "Loss: 2.158287e-05\n",
            "Loss: 2.152601e-05\n",
            "Loss: 2.1508564e-05\n",
            "Loss: 2.1488084e-05\n",
            "Loss: 2.1466152e-05\n",
            "Loss: 2.143978e-05\n",
            "Loss: 2.142e-05\n",
            "Loss: 2.1387927e-05\n",
            "Loss: 2.1367308e-05\n",
            "Loss: 2.1353795e-05\n",
            "Loss: 2.1352114e-05\n",
            "Loss: 2.13487e-05\n",
            "Loss: 2.1348116e-05\n",
            "Loss: 2.153145e-05\n",
            "Loss: 2.1347005e-05\n",
            "Loss: 2.1339563e-05\n",
            "Loss: 2.1329353e-05\n",
            "Loss: 2.131646e-05\n",
            "Loss: 2.1306974e-05\n",
            "Loss: 2.129683e-05\n",
            "Loss: 2.1288344e-05\n",
            "Loss: 2.1278533e-05\n",
            "Loss: 2.1271011e-05\n",
            "Loss: 2.1264468e-05\n",
            "Loss: 2.1260928e-05\n",
            "Loss: 2.1252827e-05\n",
            "Loss: 2.1250933e-05\n",
            "Loss: 2.1226177e-05\n",
            "Loss: 2.1214262e-05\n",
            "Loss: 2.120075e-05\n",
            "Loss: 2.1185235e-05\n",
            "Loss: 2.1173204e-05\n",
            "Loss: 2.1163845e-05\n",
            "Loss: 2.115946e-05\n",
            "Loss: 2.1154041e-05\n",
            "Loss: 2.1149577e-05\n",
            "Loss: 2.114088e-05\n",
            "Loss: 2.1138581e-05\n",
            "Loss: 2.1129927e-05\n",
            "Loss: 2.1123684e-05\n",
            "Loss: 2.111293e-05\n",
            "Loss: 2.1103155e-05\n",
            "Loss: 2.112273e-05\n",
            "Loss: 2.1092215e-05\n",
            "Loss: 2.107659e-05\n",
            "Loss: 2.1058166e-05\n",
            "Loss: 2.1041684e-05\n",
            "Loss: 2.1012871e-05\n",
            "Loss: 2.0999338e-05\n",
            "Loss: 2.1006976e-05\n",
            "Loss: 2.0994685e-05\n",
            "Loss: 2.0985619e-05\n",
            "Loss: 2.0973523e-05\n",
            "Loss: 2.0954514e-05\n",
            "Loss: 2.0939544e-05\n",
            "Loss: 2.092595e-05\n",
            "Loss: 2.090376e-05\n",
            "Loss: 2.154872e-05\n",
            "Loss: 2.089666e-05\n",
            "Loss: 2.0879572e-05\n",
            "Loss: 2.085419e-05\n",
            "Loss: 2.0840174e-05\n",
            "Loss: 2.0833835e-05\n",
            "Loss: 2.0828706e-05\n",
            "Loss: 2.0822317e-05\n",
            "Loss: 2.0815463e-05\n",
            "Loss: 2.120523e-05\n",
            "Loss: 2.0812806e-05\n",
            "Loss: 2.0805091e-05\n",
            "Loss: 2.0797386e-05\n",
            "Loss: 2.0793454e-05\n",
            "Loss: 2.078825e-05\n",
            "Loss: 2.0814343e-05\n",
            "Loss: 2.0784482e-05\n",
            "Loss: 2.0779049e-05\n",
            "Loss: 2.0774074e-05\n",
            "Loss: 2.077164e-05\n",
            "Loss: 2.0765943e-05\n",
            "Loss: 2.0794021e-05\n",
            "Loss: 2.076373e-05\n",
            "Loss: 2.0760164e-05\n",
            "Loss: 2.0754514e-05\n",
            "Loss: 2.0752268e-05\n",
            "Loss: 2.0747795e-05\n",
            "Loss: 2.0741934e-05\n",
            "Loss: 2.1534568e-05\n",
            "Loss: 2.074067e-05\n",
            "Loss: 2.073081e-05\n",
            "Loss: 2.0718911e-05\n",
            "Loss: 2.0706255e-05\n",
            "Loss: 2.0694717e-05\n",
            "Loss: 2.0714991e-05\n",
            "Loss: 2.0688232e-05\n",
            "Loss: 2.067898e-05\n",
            "Loss: 2.0669298e-05\n",
            "Loss: 2.0660007e-05\n",
            "Loss: 2.0699057e-05\n",
            "Loss: 2.0655945e-05\n",
            "Loss: 2.0651147e-05\n",
            "Loss: 2.0644584e-05\n",
            "Loss: 2.0640302e-05\n",
            "Loss: 2.0631816e-05\n",
            "Loss: 2.0638125e-05\n",
            "Loss: 2.0625017e-05\n",
            "Loss: 2.0614667e-05\n",
            "Loss: 2.0602723e-05\n",
            "Loss: 2.0584192e-05\n",
            "Loss: 2.0573349e-05\n",
            "Loss: 2.0566427e-05\n",
            "Loss: 2.0563568e-05\n",
            "Loss: 2.05637e-05\n",
            "Loss: 2.056174e-05\n",
            "Loss: 2.0557996e-05\n",
            "Loss: 2.0549369e-05\n",
            "Loss: 2.0547954e-05\n",
            "Loss: 2.0542222e-05\n",
            "Loss: 2.053409e-05\n",
            "Loss: 2.0525436e-05\n",
            "Loss: 2.0502217e-05\n",
            "Loss: 2.049006e-05\n",
            "Loss: 2.0599986e-05\n",
            "Loss: 2.048257e-05\n",
            "Loss: 2.047078e-05\n",
            "Loss: 2.0462803e-05\n",
            "Loss: 2.0453906e-05\n",
            "Loss: 2.043282e-05\n",
            "Loss: 2.0408841e-05\n",
            "Loss: 2.1125106e-05\n",
            "Loss: 2.0407108e-05\n",
            "Loss: 2.039312e-05\n",
            "Loss: 2.0387017e-05\n",
            "Loss: 2.038002e-05\n",
            "Loss: 2.0376923e-05\n",
            "Loss: 2.036108e-05\n",
            "Loss: 2.038512e-05\n",
            "Loss: 2.0353142e-05\n",
            "Loss: 2.0344018e-05\n",
            "Loss: 2.0335565e-05\n",
            "Loss: 2.0332162e-05\n",
            "Loss: 2.0320196e-05\n",
            "Loss: 2.0306248e-05\n",
            "Loss: 2.0281164e-05\n",
            "Loss: 2.0247906e-05\n",
            "Loss: 2.024951e-05\n",
            "Loss: 2.0218313e-05\n",
            "Loss: 2.0197109e-05\n",
            "Loss: 2.2129023e-05\n",
            "Loss: 2.0191423e-05\n",
            "Loss: 2.0183392e-05\n",
            "Loss: 2.0171941e-05\n",
            "Loss: 2.0152655e-05\n",
            "Loss: 2.0136538e-05\n",
            "Loss: 2.0780531e-05\n",
            "Loss: 2.0135152e-05\n",
            "Loss: 2.012787e-05\n",
            "Loss: 2.012148e-05\n",
            "Loss: 2.0111303e-05\n",
            "Loss: 2.0109906e-05\n",
            "Loss: 2.0101972e-05\n",
            "Loss: 2.0098123e-05\n",
            "Loss: 2.0093607e-05\n",
            "Loss: 2.0087788e-05\n",
            "Loss: 2.0079615e-05\n",
            "Loss: 2.0067046e-05\n",
            "Loss: 2.004625e-05\n",
            "Loss: 2.0026675e-05\n",
            "Loss: 2.0004343e-05\n",
            "Loss: 1.9992089e-05\n",
            "Loss: 1.9979983e-05\n",
            "Loss: 1.997319e-05\n",
            "Loss: 1.995353e-05\n",
            "Loss: 1.993911e-05\n",
            "Loss: 1.99243e-05\n",
            "Loss: 1.9900146e-05\n",
            "Loss: 1.9891517e-05\n",
            "Loss: 1.9882287e-05\n",
            "Loss: 1.987389e-05\n",
            "Loss: 1.9871204e-05\n",
            "Loss: 1.9869804e-05\n",
            "Loss: 1.9867894e-05\n",
            "Loss: 1.9864437e-05\n",
            "Loss: 1.985956e-05\n",
            "Loss: 1.9853638e-05\n",
            "Loss: 1.9846324e-05\n",
            "Loss: 2.0002588e-05\n",
            "Loss: 1.9843254e-05\n",
            "Loss: 1.9830735e-05\n",
            "Loss: 1.9821468e-05\n",
            "Loss: 1.9810905e-05\n",
            "Loss: 1.9805488e-05\n",
            "Loss: 1.9796458e-05\n",
            "Loss: 1.9791009e-05\n",
            "Loss: 1.9788877e-05\n",
            "Loss: 1.9786214e-05\n",
            "Loss: 1.9776928e-05\n",
            "Loss: 1.9769497e-05\n",
            "Loss: 1.9761033e-05\n",
            "Loss: 1.9762652e-05\n",
            "Loss: 1.9756077e-05\n",
            "Loss: 1.9751742e-05\n",
            "Loss: 1.9744872e-05\n",
            "Loss: 1.973868e-05\n",
            "Loss: 1.973122e-05\n",
            "Loss: 1.9690786e-05\n",
            "Loss: 1.9679148e-05\n",
            "Loss: 1.967353e-05\n",
            "Loss: 1.9665706e-05\n",
            "Loss: 1.9652822e-05\n",
            "Loss: 1.9639787e-05\n",
            "Loss: 1.9629992e-05\n",
            "Loss: 1.9656422e-05\n",
            "Loss: 1.961925e-05\n",
            "Loss: 1.9611558e-05\n",
            "Loss: 1.960213e-05\n",
            "Loss: 1.9592091e-05\n",
            "Loss: 1.9566078e-05\n",
            "Loss: 1.9545114e-05\n",
            "Loss: 1.9531106e-05\n",
            "Loss: 1.9511466e-05\n",
            "Loss: 1.9498604e-05\n",
            "Loss: 1.9487037e-05\n",
            "Loss: 1.9473093e-05\n",
            "Loss: 1.9459054e-05\n",
            "Loss: 1.9446861e-05\n",
            "Loss: 1.9434578e-05\n",
            "Loss: 1.9423176e-05\n",
            "Loss: 1.9411913e-05\n",
            "Loss: 1.9392357e-05\n",
            "Loss: 1.9383593e-05\n",
            "Loss: 1.9427383e-05\n",
            "Loss: 1.938068e-05\n",
            "Loss: 1.9372592e-05\n",
            "Loss: 1.9369123e-05\n",
            "Loss: 1.935475e-05\n",
            "Loss: 1.9364683e-05\n",
            "Loss: 1.9345092e-05\n",
            "Loss: 1.9335337e-05\n",
            "Loss: 1.9330368e-05\n",
            "Loss: 1.9328487e-05\n",
            "Loss: 1.9324269e-05\n",
            "Loss: 1.931508e-05\n",
            "Loss: 1.9305302e-05\n",
            "Loss: 1.9338135e-05\n",
            "Loss: 1.9295934e-05\n",
            "Loss: 1.9283665e-05\n",
            "Loss: 1.927294e-05\n",
            "Loss: 1.925891e-05\n",
            "Loss: 1.9626277e-05\n",
            "Loss: 1.9241916e-05\n",
            "Loss: 1.9226427e-05\n",
            "Loss: 1.9212108e-05\n",
            "Loss: 1.9196696e-05\n",
            "Loss: 1.918368e-05\n",
            "Loss: 1.9163406e-05\n",
            "Loss: 1.913742e-05\n",
            "Loss: 2.0921792e-05\n",
            "Loss: 1.9130377e-05\n",
            "Loss: 1.9116795e-05\n",
            "Loss: 1.9101079e-05\n",
            "Loss: 1.9141906e-05\n",
            "Loss: 1.909393e-05\n",
            "Loss: 1.9087014e-05\n",
            "Loss: 1.910201e-05\n",
            "Loss: 1.9076619e-05\n",
            "Loss: 1.9065967e-05\n",
            "Loss: 1.9057254e-05\n",
            "Loss: 1.9053583e-05\n",
            "Loss: 1.9046402e-05\n",
            "Loss: 1.903731e-05\n",
            "Loss: 1.9028532e-05\n",
            "Loss: 1.9021769e-05\n",
            "Loss: 1.9014504e-05\n",
            "Loss: 1.9006253e-05\n",
            "Loss: 1.8986158e-05\n",
            "Loss: 1.8981578e-05\n",
            "Loss: 1.8969935e-05\n",
            "Loss: 1.8965055e-05\n",
            "Loss: 1.8958688e-05\n",
            "Loss: 1.895507e-05\n",
            "Loss: 1.8953964e-05\n",
            "Loss: 1.8948675e-05\n",
            "Loss: 1.8947065e-05\n",
            "Loss: 1.8942117e-05\n",
            "Loss: 1.8926841e-05\n",
            "Loss: 1.8917843e-05\n",
            "Loss: 1.8963017e-05\n",
            "Loss: 1.8913184e-05\n",
            "Loss: 1.889597e-05\n",
            "Loss: 1.8893446e-05\n",
            "Loss: 1.8885008e-05\n",
            "Loss: 1.888116e-05\n",
            "Loss: 1.887665e-05\n",
            "Loss: 1.8870312e-05\n",
            "Loss: 1.8961458e-05\n",
            "Loss: 1.8867602e-05\n",
            "Loss: 1.8860976e-05\n",
            "Loss: 1.885847e-05\n",
            "Loss: 1.8853465e-05\n",
            "Loss: 1.8850626e-05\n",
            "Loss: 1.8865623e-05\n",
            "Loss: 1.8848077e-05\n",
            "Loss: 1.8843293e-05\n",
            "Loss: 1.8837785e-05\n",
            "Loss: 1.8833602e-05\n",
            "Loss: 1.8827523e-05\n",
            "Loss: 1.881551e-05\n",
            "Loss: 1.8797047e-05\n",
            "Loss: 1.8784316e-05\n",
            "Loss: 1.8776664e-05\n",
            "Loss: 1.8772114e-05\n",
            "Loss: 1.8759927e-05\n",
            "Loss: 1.8742578e-05\n",
            "Loss: 1.8726661e-05\n",
            "Loss: 1.8715382e-05\n",
            "Loss: 1.8707884e-05\n",
            "Loss: 1.8697485e-05\n",
            "Loss: 1.8683462e-05\n",
            "Loss: 1.8732264e-05\n",
            "Loss: 1.8678595e-05\n",
            "Loss: 1.8673669e-05\n",
            "Loss: 1.8773786e-05\n",
            "Loss: 1.8664412e-05\n",
            "Loss: 1.8654584e-05\n",
            "Loss: 1.864587e-05\n",
            "Loss: 1.862484e-05\n",
            "Loss: 1.8611021e-05\n",
            "Loss: 1.8601213e-05\n",
            "Loss: 1.8591705e-05\n",
            "Loss: 1.8585068e-05\n",
            "Loss: 1.8577824e-05\n",
            "Loss: 1.8569608e-05\n",
            "Loss: 1.8560864e-05\n",
            "Loss: 1.85527e-05\n",
            "Loss: 1.8541186e-05\n",
            "Loss: 1.852956e-05\n",
            "Loss: 1.8558614e-05\n",
            "Loss: 1.8526214e-05\n",
            "Loss: 1.8516663e-05\n",
            "Loss: 1.851289e-05\n",
            "Loss: 1.8507157e-05\n",
            "Loss: 1.8500761e-05\n",
            "Loss: 1.8819266e-05\n",
            "Loss: 1.8499697e-05\n",
            "Loss: 1.8490387e-05\n",
            "Loss: 1.8480085e-05\n",
            "Loss: 1.8467217e-05\n",
            "Loss: 1.8458313e-05\n",
            "Loss: 1.8453193e-05\n",
            "Loss: 1.8482278e-05\n",
            "Loss: 1.844596e-05\n",
            "Loss: 1.843781e-05\n",
            "Loss: 1.8424269e-05\n",
            "Loss: 1.8419727e-05\n",
            "Loss: 1.8413406e-05\n",
            "Loss: 1.8409268e-05\n",
            "Loss: 1.8397528e-05\n",
            "Loss: 1.8384815e-05\n",
            "Loss: 1.8373306e-05\n",
            "Loss: 1.8363737e-05\n",
            "Loss: 1.8380977e-05\n",
            "Loss: 1.8355457e-05\n",
            "Loss: 1.8416225e-05\n",
            "Loss: 1.8349618e-05\n",
            "Loss: 1.834166e-05\n",
            "Loss: 1.8325472e-05\n",
            "Loss: 1.8309604e-05\n",
            "Loss: 1.8294833e-05\n",
            "Loss: 1.8364994e-05\n",
            "Loss: 1.8289455e-05\n",
            "Loss: 1.8280985e-05\n",
            "Loss: 1.8269993e-05\n",
            "Loss: 1.826084e-05\n",
            "Loss: 1.8252616e-05\n",
            "Loss: 1.8245486e-05\n",
            "Loss: 1.8241379e-05\n",
            "Loss: 1.8238636e-05\n",
            "Loss: 1.8236307e-05\n",
            "Loss: 1.8231038e-05\n",
            "Loss: 1.8271518e-05\n",
            "Loss: 1.8229695e-05\n",
            "Loss: 1.8226008e-05\n",
            "Loss: 1.8222332e-05\n",
            "Loss: 1.8219733e-05\n",
            "Loss: 1.8214909e-05\n",
            "Loss: 1.8212253e-05\n",
            "Loss: 1.8205847e-05\n",
            "Loss: 1.8202143e-05\n",
            "Loss: 1.8197961e-05\n",
            "Loss: 1.8195527e-05\n",
            "Loss: 1.8188597e-05\n",
            "Loss: 1.8177665e-05\n",
            "Loss: 1.8177312e-05\n",
            "Loss: 1.8169316e-05\n",
            "Loss: 1.8159655e-05\n",
            "Loss: 1.8147946e-05\n",
            "Loss: 1.8145858e-05\n",
            "Loss: 1.814129e-05\n",
            "Loss: 1.8135102e-05\n",
            "Loss: 1.8126933e-05\n",
            "Loss: 1.8123894e-05\n",
            "Loss: 1.9740097e-05\n",
            "Loss: 1.8121693e-05\n",
            "Loss: 1.8119032e-05\n",
            "Loss: 1.8113788e-05\n",
            "Loss: 1.8107003e-05\n",
            "Loss: 1.8106766e-05\n",
            "Loss: 1.8093959e-05\n",
            "Loss: 1.8086846e-05\n",
            "Loss: 1.8073879e-05\n",
            "Loss: 1.8065142e-05\n",
            "Loss: 1.8053739e-05\n",
            "Loss: 1.8077e-05\n",
            "Loss: 1.8049348e-05\n",
            "Loss: 1.804523e-05\n",
            "Loss: 1.80389e-05\n",
            "Loss: 1.8031178e-05\n",
            "Loss: 1.801763e-05\n",
            "Loss: 1.800971e-05\n",
            "Loss: 1.8008375e-05\n",
            "Loss: 1.800272e-05\n",
            "Loss: 1.800069e-05\n",
            "Loss: 1.7993287e-05\n",
            "Loss: 1.7986422e-05\n",
            "Loss: 1.7979353e-05\n",
            "Loss: 1.7973112e-05\n",
            "Loss: 1.7960165e-05\n",
            "Loss: 1.7956543e-05\n",
            "Loss: 1.7940218e-05\n",
            "Loss: 1.7930171e-05\n",
            "Loss: 1.7923872e-05\n",
            "Loss: 1.7918755e-05\n",
            "Loss: 1.7919563e-05\n",
            "Loss: 1.7913566e-05\n",
            "Loss: 1.7902596e-05\n",
            "Loss: 1.7892955e-05\n",
            "Loss: 1.7879354e-05\n",
            "Loss: 1.7863043e-05\n",
            "Loss: 1.7873843e-05\n",
            "Loss: 1.785887e-05\n",
            "Loss: 1.785178e-05\n",
            "Loss: 1.78462e-05\n",
            "Loss: 1.7843779e-05\n",
            "Loss: 1.784298e-05\n",
            "Loss: 1.7839198e-05\n",
            "Loss: 1.7867758e-05\n",
            "Loss: 1.7835468e-05\n",
            "Loss: 1.783074e-05\n",
            "Loss: 1.7816545e-05\n",
            "Loss: 1.780949e-05\n",
            "Loss: 1.7797523e-05\n",
            "Loss: 1.7789482e-05\n",
            "Loss: 1.779904e-05\n",
            "Loss: 1.7786626e-05\n",
            "Loss: 1.7782882e-05\n",
            "Loss: 1.7776993e-05\n",
            "Loss: 1.7770457e-05\n",
            "Loss: 1.7762122e-05\n",
            "Loss: 1.776663e-05\n",
            "Loss: 1.7759015e-05\n",
            "Loss: 1.7749899e-05\n",
            "Loss: 1.7742612e-05\n",
            "Loss: 1.7732074e-05\n",
            "Loss: 1.772591e-05\n",
            "Loss: 1.7716773e-05\n",
            "Loss: 1.770879e-05\n",
            "Loss: 1.7694929e-05\n",
            "Loss: 1.7683053e-05\n",
            "Loss: 1.7669616e-05\n",
            "Loss: 1.7659659e-05\n",
            "Loss: 1.7656017e-05\n",
            "Loss: 1.7647959e-05\n",
            "Loss: 1.7645963e-05\n",
            "Loss: 1.7641427e-05\n",
            "Loss: 1.7637396e-05\n",
            "Loss: 1.7628314e-05\n",
            "Loss: 1.7644517e-05\n",
            "Loss: 1.7623552e-05\n",
            "Loss: 1.7619284e-05\n",
            "Loss: 1.7615663e-05\n",
            "Loss: 1.7612783e-05\n",
            "Loss: 1.760796e-05\n",
            "Loss: 1.7603545e-05\n",
            "Loss: 1.7592798e-05\n",
            "Loss: 1.7586786e-05\n",
            "Loss: 1.7582517e-05\n",
            "Loss: 1.7576036e-05\n",
            "Loss: 1.7570896e-05\n",
            "Loss: 1.7814751e-05\n",
            "Loss: 1.756396e-05\n",
            "Loss: 1.755839e-05\n",
            "Loss: 1.7550588e-05\n",
            "Loss: 1.7547463e-05\n",
            "Loss: 1.7689188e-05\n",
            "Loss: 1.754461e-05\n",
            "Loss: 1.7532875e-05\n",
            "Loss: 1.75267e-05\n",
            "Loss: 1.7520304e-05\n",
            "Loss: 1.7512539e-05\n",
            "Loss: 1.7505388e-05\n",
            "Loss: 1.7480554e-05\n",
            "Loss: 1.7993867e-05\n",
            "Loss: 1.7472428e-05\n",
            "Loss: 1.746721e-05\n",
            "Loss: 1.747922e-05\n",
            "Loss: 1.7457858e-05\n",
            "Loss: 1.745488e-05\n",
            "Loss: 1.7449887e-05\n",
            "Loss: 1.7435581e-05\n",
            "Loss: 1.7414477e-05\n",
            "Loss: 1.7399121e-05\n",
            "Loss: 1.7512471e-05\n",
            "Loss: 1.7391088e-05\n",
            "Loss: 1.7383489e-05\n",
            "Loss: 1.7375276e-05\n",
            "Loss: 1.7370987e-05\n",
            "Loss: 1.7364328e-05\n",
            "Loss: 1.7360222e-05\n",
            "Loss: 1.7353002e-05\n",
            "Loss: 1.7349148e-05\n",
            "Loss: 1.7343915e-05\n",
            "Loss: 1.7336293e-05\n",
            "Loss: 1.7325438e-05\n",
            "Loss: 1.731994e-05\n",
            "Loss: 1.7351222e-05\n",
            "Loss: 1.7311728e-05\n",
            "Loss: 1.730058e-05\n",
            "Loss: 1.729207e-05\n",
            "Loss: 1.728342e-05\n",
            "Loss: 1.7278078e-05\n",
            "Loss: 1.7269982e-05\n",
            "Loss: 1.7261144e-05\n",
            "Loss: 1.7254033e-05\n",
            "Loss: 1.7247374e-05\n",
            "Loss: 1.7241424e-05\n",
            "Loss: 1.723537e-05\n",
            "Loss: 1.7233877e-05\n",
            "Loss: 1.723031e-05\n",
            "Loss: 1.722908e-05\n",
            "Loss: 1.7226595e-05\n",
            "Loss: 1.7221106e-05\n",
            "Loss: 1.7213624e-05\n",
            "Loss: 1.7723278e-05\n",
            "Loss: 1.721241e-05\n",
            "Loss: 1.720525e-05\n",
            "Loss: 1.7198212e-05\n",
            "Loss: 1.7196518e-05\n",
            "Loss: 1.7194794e-05\n",
            "Loss: 1.719217e-05\n",
            "Loss: 1.7303422e-05\n",
            "Loss: 1.7187933e-05\n",
            "Loss: 1.7183353e-05\n",
            "Loss: 1.7175067e-05\n",
            "Loss: 1.716648e-05\n",
            "Loss: 1.7156546e-05\n",
            "Loss: 1.7144957e-05\n",
            "Loss: 1.7137754e-05\n",
            "Loss: 1.7164315e-05\n",
            "Loss: 1.7128252e-05\n",
            "Loss: 1.7114082e-05\n",
            "Loss: 1.7103419e-05\n",
            "Loss: 1.7099685e-05\n",
            "Loss: 1.709502e-05\n",
            "Loss: 1.711416e-05\n",
            "Loss: 1.7093755e-05\n",
            "Loss: 1.7091996e-05\n",
            "Loss: 1.708794e-05\n",
            "Loss: 1.7086353e-05\n",
            "Loss: 1.7083312e-05\n",
            "Loss: 1.7081065e-05\n",
            "Loss: 1.7079135e-05\n",
            "Loss: 1.707607e-05\n",
            "Loss: 1.7072356e-05\n",
            "Loss: 1.70829e-05\n",
            "Loss: 1.7069888e-05\n",
            "Loss: 1.7064294e-05\n",
            "Loss: 1.7059307e-05\n",
            "Loss: 1.7107377e-05\n",
            "Loss: 1.705689e-05\n",
            "Loss: 1.7051658e-05\n",
            "Loss: 1.704604e-05\n",
            "Loss: 1.7035152e-05\n",
            "Loss: 1.7030301e-05\n",
            "Loss: 1.7023307e-05\n",
            "Loss: 1.7022077e-05\n",
            "Loss: 1.701956e-05\n",
            "Loss: 1.7023933e-05\n",
            "Loss: 1.7015347e-05\n",
            "Loss: 1.7010896e-05\n",
            "Loss: 1.7004413e-05\n",
            "Loss: 1.701444e-05\n",
            "Loss: 1.7003837e-05\n",
            "Loss: 1.700047e-05\n",
            "Loss: 1.6996866e-05\n",
            "Loss: 1.6995302e-05\n",
            "Loss: 1.699291e-05\n",
            "Loss: 1.7006441e-05\n",
            "Loss: 1.6992552e-05\n",
            "Loss: 1.699033e-05\n",
            "Loss: 1.6981408e-05\n",
            "Loss: 1.7003505e-05\n",
            "Loss: 1.6973081e-05\n",
            "Loss: 1.6965038e-05\n",
            "Loss: 1.6958886e-05\n",
            "Loss: 1.695917e-05\n",
            "Loss: 1.695711e-05\n",
            "Loss: 1.6955051e-05\n",
            "Loss: 1.6943522e-05\n",
            "Loss: 1.6936458e-05\n",
            "Loss: 1.6932201e-05\n",
            "Loss: 1.6928097e-05\n",
            "Loss: 1.695983e-05\n",
            "Loss: 1.6926426e-05\n",
            "Loss: 1.692433e-05\n",
            "Loss: 1.6915765e-05\n",
            "Loss: 1.6912507e-05\n",
            "Loss: 1.6907365e-05\n",
            "Loss: 1.689783e-05\n",
            "Loss: 1.6890293e-05\n",
            "Loss: 1.6942036e-05\n",
            "Loss: 1.6883678e-05\n",
            "Loss: 1.6871778e-05\n",
            "Loss: 1.6864426e-05\n",
            "Loss: 1.686642e-05\n",
            "Loss: 1.6859e-05\n",
            "Loss: 1.686199e-05\n",
            "Loss: 1.6858437e-05\n",
            "Loss: 1.6855709e-05\n",
            "Loss: 1.6850307e-05\n",
            "Loss: 1.6847614e-05\n",
            "Loss: 1.6843866e-05\n",
            "Loss: 1.6841821e-05\n",
            "Loss: 1.683892e-05\n",
            "Loss: 1.683518e-05\n",
            "Loss: 1.6863225e-05\n",
            "Loss: 1.6831684e-05\n",
            "Loss: 1.6835083e-05\n",
            "Loss: 1.6828302e-05\n",
            "Loss: 1.6817852e-05\n",
            "Loss: 1.6809932e-05\n",
            "Loss: 1.6807424e-05\n",
            "Loss: 1.6804206e-05\n",
            "Loss: 1.6800319e-05\n",
            "Loss: 1.6797558e-05\n",
            "Loss: 1.6796555e-05\n",
            "Loss: 1.6789198e-05\n",
            "Loss: 1.6788192e-05\n",
            "Loss: 1.6784477e-05\n",
            "Loss: 1.678311e-05\n",
            "Loss: 1.6805794e-05\n",
            "Loss: 1.6782937e-05\n",
            "Loss: 1.6780508e-05\n",
            "Loss: 1.6779115e-05\n",
            "Loss: 1.677603e-05\n",
            "Loss: 1.6774742e-05\n",
            "Loss: 1.6775892e-05\n",
            "Loss: 1.6774457e-05\n",
            "Loss: 1.677168e-05\n",
            "Loss: 1.6858447e-05\n",
            "Loss: 1.6770424e-05\n",
            "Loss: 1.6768165e-05\n",
            "Loss: 1.6766011e-05\n",
            "Loss: 1.6765269e-05\n",
            "Loss: 1.6760474e-05\n",
            "Loss: 1.675288e-05\n",
            "Loss: 1.6765594e-05\n",
            "Loss: 1.675286e-05\n",
            "Loss: 1.6748198e-05\n",
            "Loss: 1.6740189e-05\n",
            "Loss: 1.6734992e-05\n",
            "Loss: 1.6726064e-05\n",
            "Loss: 1.6712265e-05\n",
            "Loss: 1.6793618e-05\n",
            "Loss: 1.670972e-05\n",
            "Loss: 1.67031e-05\n",
            "Loss: 1.6694034e-05\n",
            "Loss: 1.6688839e-05\n",
            "Loss: 1.6680393e-05\n",
            "Loss: 1.6667991e-05\n",
            "Loss: 1.6655104e-05\n",
            "Loss: 1.666967e-05\n",
            "Loss: 1.6651806e-05\n",
            "Loss: 1.664499e-05\n",
            "Loss: 1.6633436e-05\n",
            "Loss: 1.6630112e-05\n",
            "Loss: 1.6636706e-05\n",
            "Loss: 1.6627126e-05\n",
            "Loss: 1.6623464e-05\n",
            "Loss: 1.6623717e-05\n",
            "Loss: 1.6621832e-05\n",
            "Loss: 1.6619113e-05\n",
            "Loss: 1.6613592e-05\n",
            "Loss: 1.6615046e-05\n",
            "Loss: 1.6613803e-05\n",
            "Loss: 1.661319e-05\n",
            "Loss: 1.660433e-05\n",
            "Loss: 1.6596588e-05\n",
            "Loss: 1.6585576e-05\n",
            "Loss: 1.6578484e-05\n",
            "Loss: 1.658714e-05\n",
            "Loss: 1.657556e-05\n",
            "Loss: 1.656133e-05\n",
            "Loss: 1.655389e-05\n",
            "Loss: 1.653991e-05\n",
            "Loss: 1.6526663e-05\n",
            "Loss: 1.6506914e-05\n",
            "Loss: 1.6478678e-05\n",
            "Loss: 1.6529546e-05\n",
            "Loss: 1.6464352e-05\n",
            "Loss: 1.6444843e-05\n",
            "Loss: 1.6433802e-05\n",
            "Loss: 1.6430535e-05\n",
            "Loss: 1.6423755e-05\n",
            "Loss: 1.6420157e-05\n",
            "Loss: 1.643988e-05\n",
            "Loss: 1.6419068e-05\n",
            "Loss: 1.6416148e-05\n",
            "Loss: 1.6418931e-05\n",
            "Loss: 1.641461e-05\n",
            "Loss: 1.6413956e-05\n",
            "Loss: 1.6412114e-05\n",
            "Loss: 1.6420241e-05\n",
            "Loss: 1.6412083e-05\n",
            "Loss: 1.6409922e-05\n",
            "Loss: 1.640355e-05\n",
            "Loss: 1.6625043e-05\n",
            "Loss: 1.6402219e-05\n",
            "Loss: 1.6395803e-05\n",
            "Loss: 1.6386608e-05\n",
            "Loss: 1.6382746e-05\n",
            "Loss: 1.6375896e-05\n",
            "Loss: 1.6371365e-05\n",
            "Loss: 1.6368727e-05\n",
            "Loss: 1.636602e-05\n",
            "Loss: 1.636526e-05\n",
            "Loss: 1.6359856e-05\n",
            "Loss: 1.6357651e-05\n",
            "Loss: 1.6353672e-05\n",
            "Loss: 1.635223e-05\n",
            "Loss: 1.634967e-05\n",
            "Loss: 1.634481e-05\n",
            "Loss: 1.6342152e-05\n",
            "Loss: 1.6337612e-05\n",
            "Loss: 1.6335542e-05\n",
            "Loss: 1.6332893e-05\n",
            "Loss: 1.63298e-05\n",
            "Loss: 1.632515e-05\n",
            "Loss: 1.631681e-05\n",
            "Loss: 1.7383943e-05\n",
            "Loss: 1.6314727e-05\n",
            "Loss: 1.6306432e-05\n",
            "Loss: 1.6298432e-05\n",
            "Loss: 1.6293034e-05\n",
            "Loss: 1.6288297e-05\n",
            "Loss: 1.6284199e-05\n",
            "Loss: 1.6282958e-05\n",
            "Loss: 1.6279191e-05\n",
            "Loss: 1.6276337e-05\n",
            "Loss: 1.627379e-05\n",
            "Loss: 1.6267253e-05\n",
            "Loss: 1.6259235e-05\n",
            "Loss: 1.625198e-05\n",
            "Loss: 1.6247719e-05\n",
            "Loss: 1.6238833e-05\n",
            "Loss: 1.6256834e-05\n",
            "Loss: 1.6239204e-05\n",
            "Loss: 1.624052e-05\n",
            "Loss: 1.6240532e-05\n",
            "Loss: 1.6238497e-05\n",
            "Loss: 1.6238497e-05\n",
            "Loss: 1.6240314e-05\n",
            "Loss: 1.6238582e-05\n",
            "Loss: 1.6238497e-05\n",
            "Loss: 1.6238497e-05\n",
            "Loss: 1.6238455e-05\n",
            "Loss: 1.6238455e-05\n",
            "Loss: 1.6295417e-05\n",
            "Loss: 1.6237964e-05\n",
            "Loss: 1.6235896e-05\n",
            "Loss: 1.62313e-05\n",
            "Loss: 1.6228922e-05\n",
            "Loss: 1.6225686e-05\n",
            "Loss: 1.6222923e-05\n",
            "Loss: 1.6240434e-05\n",
            "Loss: 1.6218075e-05\n",
            "Loss: 1.6212936e-05\n",
            "Loss: 1.6203883e-05\n",
            "Loss: 1.6194888e-05\n",
            "Loss: 1.6191436e-05\n",
            "Loss: 1.6189371e-05\n",
            "Loss: 1.6187107e-05\n",
            "Loss: 1.6186232e-05\n",
            "Loss: 1.6183063e-05\n",
            "Loss: 1.6178128e-05\n",
            "Loss: 1.6484071e-05\n",
            "Loss: 1.6174226e-05\n",
            "Loss: 1.616721e-05\n",
            "Loss: 1.6157765e-05\n",
            "Loss: 1.615777e-05\n",
            "Loss: 1.6155298e-05\n",
            "Loss: 1.6150505e-05\n",
            "Loss: 1.6140943e-05\n",
            "Loss: 1.6135651e-05\n",
            "Loss: 1.652383e-05\n",
            "Loss: 1.6131913e-05\n",
            "Loss: 1.6125661e-05\n",
            "Loss: 1.6117037e-05\n",
            "Loss: 1.6113803e-05\n",
            "Loss: 1.6110584e-05\n",
            "Loss: 1.6108303e-05\n",
            "Loss: 1.6106804e-05\n",
            "Loss: 1.610405e-05\n",
            "Loss: 1.6101869e-05\n",
            "Loss: 1.6099068e-05\n",
            "Loss: 1.6097716e-05\n",
            "Loss: 1.6094846e-05\n",
            "Loss: 1.6868906e-05\n",
            "Loss: 1.6093565e-05\n",
            "Loss: 1.6088796e-05\n",
            "Loss: 1.6084383e-05\n",
            "Loss: 1.6080665e-05\n",
            "Loss: 1.6076527e-05\n",
            "Loss: 1.6076461e-05\n",
            "Loss: 1.6073158e-05\n",
            "Loss: 1.6069931e-05\n",
            "Loss: 1.6290654e-05\n",
            "Loss: 1.6068312e-05\n",
            "Loss: 1.6062757e-05\n",
            "Loss: 1.6053362e-05\n",
            "Loss: 1.6047155e-05\n",
            "Loss: 1.6041864e-05\n",
            "Loss: 1.6039827e-05\n",
            "Loss: 1.6034477e-05\n",
            "Loss: 1.6030188e-05\n",
            "Loss: 1.6027743e-05\n",
            "Loss: 1.602683e-05\n",
            "Loss: 1.625121e-05\n",
            "Loss: 1.6025298e-05\n",
            "Loss: 1.6023552e-05\n",
            "Loss: 1.601834e-05\n",
            "Loss: 1.6011745e-05\n",
            "Loss: 1.6005635e-05\n",
            "Loss: 1.6003385e-05\n",
            "Loss: 1.599539e-05\n",
            "Loss: 1.5989965e-05\n",
            "Loss: 1.5987285e-05\n",
            "Loss: 1.597382e-05\n",
            "Loss: 1.5967555e-05\n",
            "Loss: 1.5960553e-05\n",
            "Loss: 1.5957086e-05\n",
            "Loss: 1.595294e-05\n",
            "Loss: 1.5949716e-05\n",
            "Loss: 1.5948375e-05\n",
            "Loss: 1.5945727e-05\n",
            "Loss: 1.594381e-05\n",
            "Loss: 1.594134e-05\n",
            "Loss: 1.5938587e-05\n",
            "Loss: 1.5933978e-05\n",
            "Loss: 1.593125e-05\n",
            "Loss: 1.593502e-05\n",
            "Loss: 1.592794e-05\n",
            "Loss: 1.5923903e-05\n",
            "Loss: 1.5918333e-05\n",
            "Loss: 1.5917254e-05\n",
            "Loss: 1.5914851e-05\n",
            "Loss: 1.5908874e-05\n",
            "Loss: 1.5906238e-05\n",
            "Loss: 1.5903239e-05\n",
            "Loss: 1.5898491e-05\n",
            "Loss: 1.6013952e-05\n",
            "Loss: 1.5893793e-05\n",
            "Loss: 1.5887073e-05\n",
            "Loss: 1.5874988e-05\n",
            "Loss: 1.6133417e-05\n",
            "Loss: 1.5874066e-05\n",
            "Loss: 1.5869804e-05\n",
            "Loss: 1.5859703e-05\n",
            "Loss: 1.58557e-05\n",
            "Loss: 1.5853087e-05\n",
            "Loss: 1.5850159e-05\n",
            "Loss: 1.5831703e-05\n",
            "Loss: 1.5820182e-05\n",
            "Loss: 1.5982936e-05\n",
            "Loss: 1.5817626e-05\n",
            "Loss: 1.580469e-05\n",
            "Loss: 1.5809883e-05\n",
            "Loss: 1.5801219e-05\n",
            "Loss: 1.5794016e-05\n",
            "Loss: 1.5785792e-05\n",
            "Loss: 1.5895776e-05\n",
            "Loss: 1.5785503e-05\n",
            "Loss: 1.578159e-05\n",
            "Loss: 1.5776544e-05\n",
            "Loss: 1.5772071e-05\n",
            "Loss: 1.5806672e-05\n",
            "Loss: 1.5771964e-05\n",
            "Loss: 1.5769476e-05\n",
            "Loss: 1.5764097e-05\n",
            "Loss: 1.5760137e-05\n",
            "Loss: 1.575377e-05\n",
            "Loss: 1.5745329e-05\n",
            "Loss: 1.5738215e-05\n",
            "Loss: 1.5729278e-05\n",
            "Loss: 1.5711292e-05\n",
            "Loss: 1.570209e-05\n",
            "Loss: 1.569934e-05\n",
            "Loss: 1.56943e-05\n",
            "Loss: 1.5691596e-05\n",
            "Loss: 1.5683974e-05\n",
            "Loss: 1.5681353e-05\n",
            "Loss: 1.577625e-05\n",
            "Loss: 1.567965e-05\n",
            "Loss: 1.566975e-05\n",
            "Loss: 1.5657935e-05\n",
            "Loss: 1.5650414e-05\n",
            "Loss: 1.5642878e-05\n",
            "Loss: 1.563731e-05\n",
            "Loss: 1.563551e-05\n",
            "Loss: 1.563419e-05\n",
            "Loss: 1.5634905e-05\n",
            "Loss: 1.5632293e-05\n",
            "Loss: 1.562747e-05\n",
            "Loss: 1.5621195e-05\n",
            "Loss: 1.560792e-05\n",
            "Loss: 1.5626387e-05\n",
            "Loss: 1.5599384e-05\n",
            "Loss: 1.5633084e-05\n",
            "Loss: 1.559583e-05\n",
            "Loss: 1.5584865e-05\n",
            "Loss: 1.5577176e-05\n",
            "Loss: 1.5574102e-05\n",
            "Loss: 1.5568603e-05\n",
            "Loss: 1.5564778e-05\n",
            "Loss: 1.573475e-05\n",
            "Loss: 1.5562568e-05\n",
            "Loss: 1.5556994e-05\n",
            "Loss: 1.555317e-05\n",
            "Loss: 1.5551377e-05\n",
            "Loss: 1.5547945e-05\n",
            "Loss: 1.5543454e-05\n",
            "Loss: 1.5534206e-05\n",
            "Loss: 1.5522819e-05\n",
            "Loss: 1.5516029e-05\n",
            "Loss: 1.550833e-05\n",
            "Loss: 1.550412e-05\n",
            "Loss: 1.5496667e-05\n",
            "Loss: 1.5492718e-05\n",
            "Loss: 1.5579784e-05\n",
            "Loss: 1.5492384e-05\n",
            "Loss: 1.548576e-05\n",
            "Loss: 1.5478741e-05\n",
            "Loss: 1.547205e-05\n",
            "Loss: 1.550755e-05\n",
            "Loss: 1.5471125e-05\n",
            "Loss: 1.5466288e-05\n",
            "Loss: 1.5457543e-05\n",
            "Loss: 1.5442893e-05\n",
            "Loss: 1.5433261e-05\n",
            "Loss: 1.5430325e-05\n",
            "Loss: 1.5424048e-05\n",
            "Loss: 1.5412505e-05\n",
            "Loss: 1.5403813e-05\n",
            "Loss: 1.5397754e-05\n",
            "Loss: 1.5401118e-05\n",
            "Loss: 1.5395988e-05\n",
            "Loss: 1.5392503e-05\n",
            "Loss: 1.5391397e-05\n",
            "Loss: 1.5390542e-05\n",
            "Loss: 1.5389433e-05\n",
            "Loss: 1.5386946e-05\n",
            "Loss: 1.5385342e-05\n",
            "Loss: 1.5388297e-05\n",
            "Loss: 1.538315e-05\n",
            "Loss: 1.5380843e-05\n",
            "Loss: 1.5375796e-05\n",
            "Loss: 1.5367916e-05\n",
            "Loss: 1.5353837e-05\n",
            "Loss: 1.5381656e-05\n",
            "Loss: 1.5350623e-05\n",
            "Loss: 1.5389047e-05\n",
            "Loss: 1.5334455e-05\n",
            "Loss: 1.5366706e-05\n",
            "Loss: 1.5331469e-05\n",
            "Loss: 1.5324498e-05\n",
            "Loss: 1.5378653e-05\n",
            "Loss: 1.532066e-05\n",
            "Loss: 1.5314588e-05\n",
            "Loss: 1.5306689e-05\n",
            "Loss: 1.5300373e-05\n",
            "Loss: 1.529592e-05\n",
            "Loss: 1.529369e-05\n",
            "Loss: 1.5291744e-05\n",
            "Loss: 1.5289603e-05\n",
            "Loss: 1.5288942e-05\n",
            "Loss: 1.5287358e-05\n",
            "Loss: 1.5284955e-05\n",
            "Loss: 1.5283109e-05\n",
            "Loss: 1.528117e-05\n",
            "Loss: 1.5277787e-05\n",
            "Loss: 1.527298e-05\n",
            "Loss: 1.5313506e-05\n",
            "Loss: 1.5268524e-05\n",
            "Loss: 1.5265196e-05\n",
            "Loss: 1.5259624e-05\n",
            "Loss: 1.525612e-05\n",
            "Loss: 1.5251992e-05\n",
            "Loss: 1.5241545e-05\n",
            "Loss: 1.5238152e-05\n",
            "Loss: 1.5226754e-05\n",
            "Loss: 1.5219349e-05\n",
            "Loss: 1.52123275e-05\n",
            "Loss: 1.52013345e-05\n",
            "Loss: 1.5197233e-05\n",
            "Loss: 1.5211141e-05\n",
            "Loss: 1.5193537e-05\n",
            "Loss: 1.5190762e-05\n",
            "Loss: 1.518464e-05\n",
            "Loss: 1.5181936e-05\n",
            "Loss: 1.5172888e-05\n",
            "Loss: 1.5167035e-05\n",
            "Loss: 1.5163435e-05\n",
            "Loss: 1.5158572e-05\n",
            "Loss: 1.515509e-05\n",
            "Loss: 1.51566e-05\n",
            "Loss: 1.5150998e-05\n",
            "Loss: 1.527066e-05\n",
            "Loss: 1.5145961e-05\n",
            "Loss: 1.5139669e-05\n",
            "Loss: 1.51358445e-05\n",
            "Loss: 1.5131601e-05\n",
            "Loss: 1.5122467e-05\n",
            "Loss: 1.5115057e-05\n",
            "Loss: 1.51205595e-05\n",
            "Loss: 1.5111485e-05\n",
            "Loss: 1.5249876e-05\n",
            "Loss: 1.5106774e-05\n",
            "Loss: 1.5101576e-05\n",
            "Loss: 1.5096533e-05\n",
            "Loss: 1.5093318e-05\n",
            "Loss: 1.508573e-05\n",
            "Loss: 1.5080532e-05\n",
            "Loss: 1.5226799e-05\n",
            "Loss: 1.5078927e-05\n",
            "Loss: 1.5073679e-05\n",
            "Loss: 1.5069371e-05\n",
            "Loss: 1.506741e-05\n",
            "Loss: 1.5062821e-05\n",
            "Loss: 1.5059971e-05\n",
            "Loss: 1.505661e-05\n",
            "Loss: 1.5052843e-05\n",
            "Loss: 1.5081352e-05\n",
            "Loss: 1.5053367e-05\n",
            "Loss: 1.5052035e-05\n",
            "Loss: 1.50492915e-05\n",
            "Loss: 1.5046676e-05\n",
            "Loss: 1.504512e-05\n",
            "Loss: 1.5041767e-05\n",
            "Loss: 1.5037181e-05\n",
            "Loss: 1.5034404e-05\n",
            "Loss: 1.50305e-05\n",
            "Loss: 1.5028315e-05\n",
            "Loss: 1.5023994e-05\n",
            "Loss: 1.5043529e-05\n",
            "Loss: 1.5023853e-05\n",
            "Loss: 1.5020287e-05\n",
            "Loss: 1.5017796e-05\n",
            "Loss: 1.501383e-05\n",
            "Loss: 1.5009516e-05\n",
            "Loss: 1.5003169e-05\n",
            "Loss: 1.4999529e-05\n",
            "Loss: 1.4994563e-05\n",
            "Loss: 1.49891375e-05\n",
            "Loss: 1.4985932e-05\n",
            "Loss: 1.498516e-05\n",
            "Loss: 1.4980711e-05\n",
            "Loss: 1.49786065e-05\n",
            "Loss: 1.4976278e-05\n",
            "Loss: 1.4973594e-05\n",
            "Loss: 1.4971589e-05\n",
            "Loss: 1.5031655e-05\n",
            "Loss: 1.4968029e-05\n",
            "Loss: 1.4963215e-05\n",
            "Loss: 1.4955566e-05\n",
            "Loss: 1.4950936e-05\n",
            "Loss: 1.4946049e-05\n",
            "Loss: 1.4943392e-05\n",
            "Loss: 1.49384405e-05\n",
            "Loss: 1.493806e-05\n",
            "Loss: 1.4936336e-05\n",
            "Loss: 1.4932585e-05\n",
            "Loss: 1.4942966e-05\n",
            "Loss: 1.4931345e-05\n",
            "Loss: 1.4929328e-05\n",
            "Loss: 1.4926611e-05\n",
            "Loss: 1.5008725e-05\n",
            "Loss: 1.49247135e-05\n",
            "Loss: 1.492016e-05\n",
            "Loss: 1.4911881e-05\n",
            "Loss: 1.4898715e-05\n",
            "Loss: 1.48868185e-05\n",
            "Loss: 1.4880989e-05\n",
            "Loss: 1.4913054e-05\n",
            "Loss: 1.4877033e-05\n",
            "Loss: 1.4871299e-05\n",
            "Loss: 1.4860609e-05\n",
            "Loss: 1.4848078e-05\n",
            "Loss: 1.4906535e-05\n",
            "Loss: 1.4843718e-05\n",
            "Loss: 1.4829732e-05\n",
            "Loss: 1.4834855e-05\n",
            "Loss: 1.4824617e-05\n",
            "Loss: 1.4821301e-05\n",
            "Loss: 1.4821823e-05\n",
            "Loss: 1.48182135e-05\n",
            "Loss: 1.4814266e-05\n",
            "Loss: 1.4809747e-05\n",
            "Loss: 1.480618e-05\n",
            "Loss: 1.4804688e-05\n",
            "Loss: 1.4805126e-05\n",
            "Loss: 1.4802034e-05\n",
            "Loss: 1.4798599e-05\n",
            "Loss: 1.4796e-05\n",
            "Loss: 1.479282e-05\n",
            "Loss: 1.47903565e-05\n",
            "Loss: 1.4831354e-05\n",
            "Loss: 1.4789621e-05\n",
            "Loss: 1.4787564e-05\n",
            "Loss: 1.4783419e-05\n",
            "Loss: 1.4779653e-05\n",
            "Loss: 1.4775663e-05\n",
            "Loss: 1.47701785e-05\n",
            "Loss: 1.476817e-05\n",
            "Loss: 1.476324e-05\n",
            "Loss: 1.4758585e-05\n",
            "Loss: 1.4754476e-05\n",
            "Loss: 1.4752279e-05\n",
            "Loss: 1.4747939e-05\n",
            "Loss: 1.4750274e-05\n",
            "Loss: 1.4746712e-05\n",
            "Loss: 1.4743028e-05\n",
            "Loss: 1.4733484e-05\n",
            "Loss: 1.4728809e-05\n",
            "Loss: 1.4721941e-05\n",
            "Loss: 1.4712946e-05\n",
            "Loss: 1.4707987e-05\n",
            "Loss: 1.4694014e-05\n",
            "Loss: 1.4682232e-05\n",
            "Loss: 1.4953232e-05\n",
            "Loss: 1.4678098e-05\n",
            "Loss: 1.4669756e-05\n",
            "Loss: 1.4664571e-05\n",
            "Loss: 1.4662305e-05\n",
            "Loss: 1.4661472e-05\n",
            "Loss: 1.4659084e-05\n",
            "Loss: 1.46507955e-05\n",
            "Loss: 1.4635852e-05\n",
            "Loss: 1.4776068e-05\n",
            "Loss: 1.4632342e-05\n",
            "Loss: 1.4620101e-05\n",
            "Loss: 1.4610741e-05\n",
            "Loss: 1.4599549e-05\n",
            "Loss: 1.4589896e-05\n",
            "Loss: 1.4573831e-05\n",
            "Loss: 1.4564073e-05\n",
            "Loss: 1.4553096e-05\n",
            "Loss: 1.4546119e-05\n",
            "Loss: 1.454001e-05\n",
            "Loss: 1.4544004e-05\n",
            "Loss: 1.4537628e-05\n",
            "Loss: 1.4531608e-05\n",
            "Loss: 1.4526143e-05\n",
            "Loss: 1.4520887e-05\n",
            "Loss: 1.4507182e-05\n",
            "Loss: 1.450053e-05\n",
            "Loss: 1.4494657e-05\n",
            "Loss: 1.4489087e-05\n",
            "Loss: 1.4479121e-05\n",
            "Loss: 1.4466507e-05\n",
            "Loss: 1.4669987e-05\n",
            "Loss: 1.4465086e-05\n",
            "Loss: 1.4458487e-05\n",
            "Loss: 1.4469499e-05\n",
            "Loss: 1.4456459e-05\n",
            "Loss: 1.4453159e-05\n",
            "Loss: 1.4450839e-05\n",
            "Loss: 1.4457781e-05\n",
            "Loss: 1.4449086e-05\n",
            "Loss: 1.4447708e-05\n",
            "Loss: 1.4441651e-05\n",
            "Loss: 1.443932e-05\n",
            "Loss: 1.4436506e-05\n",
            "Loss: 1.4430955e-05\n",
            "Loss: 1.4430754e-05\n",
            "Loss: 1.4427476e-05\n",
            "Loss: 1.44850555e-05\n",
            "Loss: 1.4425088e-05\n",
            "Loss: 1.4418908e-05\n",
            "Loss: 1.4414724e-05\n",
            "Loss: 1.4412149e-05\n",
            "Loss: 1.4406325e-05\n",
            "Loss: 1.4408279e-05\n",
            "Loss: 1.4403465e-05\n",
            "Loss: 1.4395237e-05\n",
            "Loss: 1.4388425e-05\n",
            "Loss: 1.438181e-05\n",
            "Loss: 1.4379006e-05\n",
            "Loss: 1.4376008e-05\n",
            "Loss: 1.4373167e-05\n",
            "Loss: 1.43683255e-05\n",
            "Loss: 1.4789113e-05\n",
            "Loss: 1.4365029e-05\n",
            "Loss: 1.4361527e-05\n",
            "Loss: 1.4355412e-05\n",
            "Loss: 1.43545685e-05\n",
            "Loss: 1.4341266e-05\n",
            "Loss: 1.4334444e-05\n",
            "Loss: 1.4331903e-05\n",
            "Loss: 1.43194675e-05\n",
            "Loss: 1.4311863e-05\n",
            "Loss: 1.4305682e-05\n",
            "Loss: 1.4300717e-05\n",
            "Loss: 1.429607e-05\n",
            "Loss: 1.4291838e-05\n",
            "Loss: 1.4287181e-05\n",
            "Loss: 1.4305382e-05\n",
            "Loss: 1.428464e-05\n",
            "Loss: 1.4277922e-05\n",
            "Loss: 1.4275006e-05\n",
            "Loss: 1.4281111e-05\n",
            "Loss: 1.4274827e-05\n",
            "Loss: 1.4271015e-05\n",
            "Loss: 1.4267307e-05\n",
            "Loss: 1.4262644e-05\n",
            "Loss: 1.4262171e-05\n",
            "Loss: 1.4258003e-05\n",
            "Loss: 1.4255994e-05\n",
            "Loss: 1.4251607e-05\n",
            "Loss: 1.4248131e-05\n",
            "Loss: 1.4273033e-05\n",
            "Loss: 1.4246967e-05\n",
            "Loss: 1.424438e-05\n",
            "Loss: 1.4287468e-05\n",
            "Loss: 1.4243015e-05\n",
            "Loss: 1.42423905e-05\n",
            "Loss: 1.4239375e-05\n",
            "Loss: 1.4235816e-05\n",
            "Loss: 1.42330255e-05\n",
            "Loss: 1.4230332e-05\n",
            "Loss: 1.4226305e-05\n",
            "Loss: 1.4222703e-05\n",
            "Loss: 1.4216375e-05\n",
            "Loss: 1.42134795e-05\n",
            "Loss: 1.4206765e-05\n",
            "Loss: 1.4201949e-05\n",
            "Loss: 1.4213443e-05\n",
            "Loss: 1.41976025e-05\n",
            "Loss: 1.4183873e-05\n",
            "Loss: 1.4173469e-05\n",
            "Loss: 1.41625715e-05\n",
            "Loss: 1.4158447e-05\n",
            "Loss: 1.4152441e-05\n",
            "Loss: 1.4143329e-05\n",
            "Loss: 1.4140233e-05\n",
            "Loss: 1.4135448e-05\n",
            "Loss: 1.4130938e-05\n",
            "Loss: 1.4127184e-05\n",
            "Loss: 1.412364e-05\n",
            "Loss: 1.4112287e-05\n",
            "Loss: 1.4339714e-05\n",
            "Loss: 1.4108787e-05\n",
            "Loss: 1.4101222e-05\n",
            "Loss: 1.4091427e-05\n",
            "Loss: 1.4082162e-05\n",
            "Loss: 1.4072984e-05\n",
            "Loss: 1.4061613e-05\n",
            "Loss: 1.40546945e-05\n",
            "Loss: 1.4047078e-05\n",
            "Loss: 1.4044366e-05\n",
            "Loss: 1.404182e-05\n",
            "Loss: 1.40334105e-05\n",
            "Loss: 1.4024717e-05\n",
            "Loss: 1.4021252e-05\n",
            "Loss: 1.4153545e-05\n",
            "Loss: 1.4019975e-05\n",
            "Loss: 1.4016614e-05\n",
            "Loss: 1.4012777e-05\n",
            "Loss: 1.4007339e-05\n",
            "Loss: 1.4002793e-05\n",
            "Loss: 1.3998e-05\n",
            "Loss: 1.3990935e-05\n",
            "Loss: 1.3982832e-05\n",
            "Loss: 1.397741e-05\n",
            "Loss: 1.3967804e-05\n",
            "Loss: 1.39608455e-05\n",
            "Loss: 1.39522135e-05\n",
            "Loss: 1.5005323e-05\n",
            "Loss: 1.3949747e-05\n",
            "Loss: 1.3961929e-05\n",
            "Loss: 1.3945791e-05\n",
            "Loss: 1.3933256e-05\n",
            "Loss: 1.3921488e-05\n",
            "Loss: 1.3916102e-05\n",
            "Loss: 1.3913529e-05\n",
            "Loss: 1.3921491e-05\n",
            "Loss: 1.3911276e-05\n",
            "Loss: 1.3907962e-05\n",
            "Loss: 1.3896668e-05\n",
            "Loss: 1.3893479e-05\n",
            "Loss: 1.38927735e-05\n",
            "Loss: 1.3890303e-05\n",
            "Loss: 1.3888596e-05\n",
            "Loss: 1.3882458e-05\n",
            "Loss: 1.3882442e-05\n",
            "Loss: 1.3893525e-05\n",
            "Loss: 1.3880545e-05\n",
            "Loss: 1.3878046e-05\n",
            "Loss: 1.3874615e-05\n",
            "Loss: 1.3868312e-05\n",
            "Loss: 1.38616715e-05\n",
            "Loss: 1.3947241e-05\n",
            "Loss: 1.3859949e-05\n",
            "Loss: 1.3855711e-05\n",
            "Loss: 1.387205e-05\n",
            "Loss: 1.3853722e-05\n",
            "Loss: 1.3851635e-05\n",
            "Loss: 1.3848422e-05\n",
            "Loss: 1.3845707e-05\n",
            "Loss: 1.383577e-05\n",
            "Loss: 1.3866083e-05\n",
            "Loss: 1.3832886e-05\n",
            "Loss: 1.3834917e-05\n",
            "Loss: 1.3829362e-05\n",
            "Loss: 1.3823363e-05\n",
            "Loss: 1.3816379e-05\n",
            "Loss: 1.3811766e-05\n",
            "Loss: 1.3806601e-05\n",
            "Loss: 1.37947245e-05\n",
            "Loss: 1.3902755e-05\n",
            "Loss: 1.379315e-05\n",
            "Loss: 1.3784168e-05\n",
            "Loss: 1.3769618e-05\n",
            "Loss: 1.375756e-05\n",
            "Loss: 1.37459765e-05\n",
            "Loss: 1.3911119e-05\n",
            "Loss: 1.3745389e-05\n",
            "Loss: 1.3739366e-05\n",
            "Loss: 1.37332045e-05\n",
            "Loss: 1.3733973e-05\n",
            "Loss: 1.37304205e-05\n",
            "Loss: 1.3727194e-05\n",
            "Loss: 1.37246625e-05\n",
            "Loss: 1.3720345e-05\n",
            "Loss: 1.3725243e-05\n",
            "Loss: 1.3720446e-05\n",
            "Loss: 1.3720304e-05\n",
            "Loss: 1.3719637e-05\n",
            "Loss: 1.3714279e-05\n",
            "Loss: 1.3710138e-05\n",
            "Loss: 1.3704697e-05\n",
            "Loss: 1.369959e-05\n",
            "Loss: 1.3695801e-05\n",
            "Loss: 1.3692144e-05\n",
            "Loss: 1.3688895e-05\n",
            "Loss: 1.3685582e-05\n",
            "Loss: 1.37202e-05\n",
            "Loss: 1.36827075e-05\n",
            "Loss: 1.3680697e-05\n",
            "Loss: 1.3675588e-05\n",
            "Loss: 1.3671599e-05\n",
            "Loss: 1.3668729e-05\n",
            "Loss: 1.3665937e-05\n",
            "Loss: 1.3662357e-05\n",
            "Loss: 1.3661723e-05\n",
            "Loss: 1.3659357e-05\n",
            "Loss: 1.3653689e-05\n",
            "Loss: 1.3884359e-05\n",
            "Loss: 1.3652027e-05\n",
            "Loss: 1.36456565e-05\n",
            "Loss: 1.36317e-05\n",
            "Loss: 1.3619475e-05\n",
            "Loss: 1.3610374e-05\n",
            "Loss: 1.3605885e-05\n",
            "Loss: 1.3602135e-05\n",
            "Loss: 1.3595845e-05\n",
            "Loss: 1.35885875e-05\n",
            "Loss: 1.35858745e-05\n",
            "Loss: 1.3611124e-05\n",
            "Loss: 1.3586214e-05\n",
            "Loss: 1.3585612e-05\n",
            "Loss: 1.3583613e-05\n",
            "Loss: 1.3581453e-05\n",
            "Loss: 1.358026e-05\n",
            "Loss: 1.3576622e-05\n",
            "Loss: 1.3574167e-05\n",
            "Loss: 1.3571491e-05\n",
            "Loss: 1.3569394e-05\n",
            "Loss: 1.3566862e-05\n",
            "Loss: 1.3562512e-05\n",
            "Loss: 1.3558028e-05\n",
            "Loss: 1.3553192e-05\n",
            "Loss: 1.3549848e-05\n",
            "Loss: 1.3546342e-05\n",
            "Loss: 1.3543288e-05\n",
            "Loss: 1.3540809e-05\n",
            "Loss: 1.3538449e-05\n",
            "Loss: 1.3534843e-05\n",
            "Loss: 1.35304535e-05\n",
            "Loss: 1.3527421e-05\n",
            "Loss: 1.3522744e-05\n",
            "Loss: 1.3515307e-05\n",
            "Loss: 1.3507634e-05\n",
            "Loss: 1.3505095e-05\n",
            "Loss: 1.3499173e-05\n",
            "Loss: 1.3497042e-05\n",
            "Loss: 1.3493632e-05\n",
            "Loss: 1.3491125e-05\n",
            "Loss: 1.3486619e-05\n",
            "Loss: 1.3481479e-05\n",
            "Loss: 1.3473644e-05\n",
            "Loss: 1.3462867e-05\n",
            "Loss: 1.3479756e-05\n",
            "Loss: 1.3457428e-05\n",
            "Loss: 1.3445971e-05\n",
            "Loss: 1.343854e-05\n",
            "Loss: 1.3427382e-05\n",
            "Loss: 1.3426325e-05\n",
            "Loss: 1.34189195e-05\n",
            "Loss: 1.3416767e-05\n",
            "Loss: 1.3409418e-05\n",
            "Loss: 1.3405792e-05\n",
            "Loss: 1.3400711e-05\n",
            "Loss: 1.3399227e-05\n",
            "Loss: 1.3394204e-05\n",
            "Loss: 1.3391652e-05\n",
            "Loss: 1.338699e-05\n",
            "Loss: 1.3383073e-05\n",
            "Loss: 1.3392707e-05\n",
            "Loss: 1.3375837e-05\n",
            "Loss: 1.3361805e-05\n",
            "Loss: 1.3353473e-05\n",
            "Loss: 1.3350806e-05\n",
            "Loss: 1.3347474e-05\n",
            "Loss: 1.334e-05\n",
            "Loss: 1.33329995e-05\n",
            "Loss: 1.3327356e-05\n",
            "Loss: 1.3322451e-05\n",
            "Loss: 1.3322893e-05\n",
            "Loss: 1.3321479e-05\n",
            "Loss: 1.3318035e-05\n",
            "Loss: 1.3314962e-05\n",
            "Loss: 1.3311162e-05\n",
            "Loss: 1.3307737e-05\n",
            "Loss: 1.3305554e-05\n",
            "Loss: 1.330356e-05\n",
            "Loss: 1.3302666e-05\n",
            "Loss: 1.3300511e-05\n",
            "Loss: 1.3299865e-05\n",
            "Loss: 1.3297182e-05\n",
            "Loss: 1.3296213e-05\n",
            "Loss: 1.3292873e-05\n",
            "Loss: 1.32891e-05\n",
            "Loss: 1.3285848e-05\n",
            "Loss: 1.3282487e-05\n",
            "Loss: 1.32793675e-05\n",
            "Loss: 1.3276847e-05\n",
            "Loss: 1.3272913e-05\n",
            "Loss: 1.3274405e-05\n",
            "Loss: 1.3270708e-05\n",
            "Loss: 1.3269475e-05\n",
            "Loss: 1.3262655e-05\n",
            "Loss: 1.3259987e-05\n",
            "Loss: 1.3256114e-05\n",
            "Loss: 1.3254501e-05\n",
            "Loss: 1.3253009e-05\n",
            "Loss: 1.3250134e-05\n",
            "Loss: 1.3247218e-05\n",
            "Loss: 1.3242668e-05\n",
            "Loss: 1.32402465e-05\n",
            "Loss: 1.3239501e-05\n",
            "Loss: 1.3237309e-05\n",
            "Loss: 1.3236524e-05\n",
            "Loss: 1.3235354e-05\n",
            "Loss: 1.3239451e-05\n",
            "Loss: 1.3233156e-05\n",
            "Loss: 1.3229629e-05\n",
            "Loss: 1.3222132e-05\n",
            "Loss: 1.3218298e-05\n",
            "Loss: 1.3210216e-05\n",
            "Loss: 1.3245771e-05\n",
            "Loss: 1.3205187e-05\n",
            "Loss: 1.3197418e-05\n",
            "Loss: 1.31902225e-05\n",
            "Loss: 1.31833995e-05\n",
            "Loss: 1.3178861e-05\n",
            "Loss: 1.3175409e-05\n",
            "Loss: 1.3174053e-05\n",
            "Loss: 1.3169309e-05\n",
            "Loss: 1.3163194e-05\n",
            "Loss: 1.3157935e-05\n",
            "Loss: 1.3153707e-05\n",
            "Loss: 1.31441975e-05\n",
            "Loss: 1.31382885e-05\n",
            "Loss: 1.3135305e-05\n",
            "Loss: 1.3132775e-05\n",
            "Loss: 1.3134165e-05\n",
            "Loss: 1.31307215e-05\n",
            "Loss: 1.3128547e-05\n",
            "Loss: 1.3126207e-05\n",
            "Loss: 1.3124518e-05\n",
            "Loss: 1.3123585e-05\n",
            "Loss: 1.3120955e-05\n",
            "Loss: 1.3119403e-05\n",
            "Loss: 1.3120483e-05\n",
            "Loss: 1.3119171e-05\n",
            "Loss: 1.3117829e-05\n",
            "Loss: 1.3116705e-05\n",
            "Loss: 1.3114181e-05\n",
            "Loss: 1.3113615e-05\n",
            "Loss: 1.3112161e-05\n",
            "Loss: 1.3108438e-05\n",
            "Loss: 1.3143339e-05\n",
            "Loss: 1.3105862e-05\n",
            "Loss: 1.3101165e-05\n",
            "Loss: 1.3098292e-05\n",
            "Loss: 1.3094835e-05\n",
            "Loss: 1.3093023e-05\n",
            "Loss: 1.3086227e-05\n",
            "Loss: 1.3082738e-05\n",
            "Loss: 1.307755e-05\n",
            "Loss: 1.30730905e-05\n",
            "Loss: 1.306856e-05\n",
            "Loss: 1.306203e-05\n",
            "Loss: 1.3058711e-05\n",
            "Loss: 1.3056639e-05\n",
            "Loss: 1.3052932e-05\n",
            "Loss: 1.3052932e-05\n",
            "Loss: 1.3051449e-05\n",
            "Loss: 1.30453245e-05\n",
            "Loss: 1.3041184e-05\n",
            "Loss: 1.30381295e-05\n",
            "Loss: 1.3034984e-05\n",
            "Loss: 1.3030747e-05\n",
            "Loss: 1.31293145e-05\n",
            "Loss: 1.3030164e-05\n",
            "Loss: 1.3025808e-05\n",
            "Loss: 1.3023457e-05\n",
            "Loss: 1.30209855e-05\n",
            "Loss: 1.3017359e-05\n",
            "Loss: 1.30117005e-05\n",
            "Loss: 1.3008464e-05\n",
            "Loss: 1.3005766e-05\n",
            "Loss: 1.2998611e-05\n",
            "Loss: 1.3253566e-05\n",
            "Loss: 1.299587e-05\n",
            "Loss: 1.2987198e-05\n",
            "Loss: 1.29928585e-05\n",
            "Loss: 1.2983847e-05\n",
            "Loss: 1.29802775e-05\n",
            "Loss: 1.2974431e-05\n",
            "Loss: 1.2971352e-05\n",
            "Loss: 1.2973409e-05\n",
            "Loss: 1.2968185e-05\n",
            "Loss: 1.2964072e-05\n",
            "Loss: 1.2958172e-05\n",
            "Loss: 1.29545e-05\n",
            "Loss: 1.2948857e-05\n",
            "Loss: 1.294364e-05\n",
            "Loss: 1.2943341e-05\n",
            "Loss: 1.2939027e-05\n",
            "Loss: 1.2933736e-05\n",
            "Loss: 1.2926976e-05\n",
            "Loss: 1.2922346e-05\n",
            "Loss: 1.2939949e-05\n",
            "Loss: 1.2918094e-05\n",
            "Loss: 1.2912406e-05\n",
            "Loss: 1.2909612e-05\n",
            "Loss: 1.2907606e-05\n",
            "Loss: 1.2904559e-05\n",
            "Loss: 1.2902507e-05\n",
            "Loss: 1.2900666e-05\n",
            "Loss: 1.2898752e-05\n",
            "Loss: 1.2894576e-05\n",
            "Loss: 1.2890345e-05\n",
            "Loss: 1.2959931e-05\n",
            "Loss: 1.2888045e-05\n",
            "Loss: 1.2885538e-05\n",
            "Loss: 1.2881259e-05\n",
            "Loss: 1.2876225e-05\n",
            "Loss: 1.2869759e-05\n",
            "Loss: 1.28628135e-05\n",
            "Loss: 1.2875952e-05\n",
            "Loss: 1.2861428e-05\n",
            "Loss: 1.2855945e-05\n",
            "Loss: 1.2852981e-05\n",
            "Loss: 1.2836749e-05\n",
            "Loss: 1.2827394e-05\n",
            "Loss: 1.2827661e-05\n",
            "Loss: 1.2821024e-05\n",
            "Loss: 1.2814645e-05\n",
            "Loss: 1.2809264e-05\n",
            "Loss: 1.2802049e-05\n",
            "Loss: 1.2792909e-05\n",
            "Loss: 1.2790476e-05\n",
            "Loss: 1.2777462e-05\n",
            "Loss: 1.276783e-05\n",
            "Loss: 1.2759024e-05\n",
            "Loss: 1.2751956e-05\n",
            "Loss: 1.2743963e-05\n",
            "Loss: 1.2732604e-05\n",
            "Loss: 1.2720551e-05\n",
            "Loss: 1.2710479e-05\n",
            "Loss: 1.2705795e-05\n",
            "Loss: 1.2694447e-05\n",
            "Loss: 1.2728288e-05\n",
            "Loss: 1.2690574e-05\n",
            "Loss: 1.2683016e-05\n",
            "Loss: 1.26769455e-05\n",
            "Loss: 1.2670301e-05\n",
            "Loss: 1.2662582e-05\n",
            "Loss: 1.2661398e-05\n",
            "Loss: 1.2656663e-05\n",
            "Loss: 1.2650748e-05\n",
            "Loss: 1.2647128e-05\n",
            "Loss: 1.2640799e-05\n",
            "Loss: 1.26283485e-05\n",
            "Loss: 1.2622993e-05\n",
            "Loss: 1.2619493e-05\n",
            "Loss: 1.2614502e-05\n",
            "Loss: 1.26082905e-05\n",
            "Loss: 1.2592056e-05\n",
            "Loss: 1.2599533e-05\n",
            "Loss: 1.2588757e-05\n",
            "Loss: 1.2584127e-05\n",
            "Loss: 1.2578217e-05\n",
            "Loss: 1.2572132e-05\n",
            "Loss: 1.2561816e-05\n",
            "Loss: 1.2549729e-05\n",
            "Loss: 1.2536245e-05\n",
            "Loss: 1.2525003e-05\n",
            "Loss: 1.2513863e-05\n",
            "Loss: 1.2509414e-05\n",
            "Loss: 1.2494474e-05\n",
            "Loss: 1.2484326e-05\n",
            "Loss: 1.2473973e-05\n",
            "Loss: 1.24693e-05\n",
            "Loss: 1.2461953e-05\n",
            "Loss: 1.2457574e-05\n",
            "Loss: 1.2451668e-05\n",
            "Loss: 1.2443564e-05\n",
            "Loss: 1.3598766e-05\n",
            "Loss: 1.2441883e-05\n",
            "Loss: 1.2436512e-05\n",
            "Loss: 1.24332e-05\n",
            "Loss: 1.2440241e-05\n",
            "Loss: 1.2428578e-05\n",
            "Loss: 1.2422039e-05\n",
            "Loss: 1.247036e-05\n",
            "Loss: 1.2412735e-05\n",
            "Loss: 1.2404422e-05\n",
            "Loss: 1.23988075e-05\n",
            "Loss: 1.2391423e-05\n",
            "Loss: 1.238662e-05\n",
            "Loss: 1.2379769e-05\n",
            "Loss: 1.237186e-05\n",
            "Loss: 1.2364112e-05\n",
            "Loss: 1.2363974e-05\n",
            "Loss: 1.23596255e-05\n",
            "Loss: 1.2354611e-05\n",
            "Loss: 1.2351288e-05\n",
            "Loss: 1.2344176e-05\n",
            "Loss: 1.2339258e-05\n",
            "Loss: 1.23352975e-05\n",
            "Loss: 1.2331633e-05\n",
            "Loss: 1.2327991e-05\n",
            "Loss: 1.2323368e-05\n",
            "Loss: 1.23203035e-05\n",
            "Loss: 1.2316994e-05\n",
            "Loss: 1.2310874e-05\n",
            "Loss: 1.2306071e-05\n",
            "Loss: 1.2311704e-05\n",
            "Loss: 1.2299686e-05\n",
            "Loss: 1.2292998e-05\n",
            "Loss: 1.2282788e-05\n",
            "Loss: 1.22790225e-05\n",
            "Loss: 1.226905e-05\n",
            "Loss: 1.2442531e-05\n",
            "Loss: 1.2266795e-05\n",
            "Loss: 1.2262854e-05\n",
            "Loss: 1.2257321e-05\n",
            "Loss: 1.2253675e-05\n",
            "Loss: 1.2246814e-05\n",
            "Loss: 1.223879e-05\n",
            "Loss: 1.2232864e-05\n",
            "Loss: 1.2329079e-05\n",
            "Loss: 1.2230735e-05\n",
            "Loss: 1.22238e-05\n",
            "Loss: 1.2219012e-05\n",
            "Loss: 1.2213818e-05\n",
            "Loss: 1.2209053e-05\n",
            "Loss: 1.2206891e-05\n",
            "Loss: 1.2203503e-05\n",
            "Loss: 1.2200956e-05\n",
            "Loss: 1.2195263e-05\n",
            "Loss: 1.21905405e-05\n",
            "Loss: 1.2243303e-05\n",
            "Loss: 1.2188732e-05\n",
            "Loss: 1.2184428e-05\n",
            "Loss: 1.217412e-05\n",
            "Loss: 1.2165024e-05\n",
            "Loss: 1.2578505e-05\n",
            "Loss: 1.216127e-05\n",
            "Loss: 1.2153308e-05\n",
            "Loss: 1.2141786e-05\n",
            "Loss: 1.213204e-05\n",
            "Loss: 1.2124805e-05\n",
            "Loss: 1.2117824e-05\n",
            "Loss: 1.2108254e-05\n",
            "Loss: 1.2146547e-05\n",
            "Loss: 1.2107126e-05\n",
            "Loss: 1.2101924e-05\n",
            "Loss: 1.209295e-05\n",
            "Loss: 1.2083618e-05\n",
            "Loss: 1.2117394e-05\n",
            "Loss: 1.2078051e-05\n",
            "Loss: 1.20711375e-05\n",
            "Loss: 1.3009446e-05\n",
            "Loss: 1.206968e-05\n",
            "Loss: 1.2059778e-05\n",
            "Loss: 1.2055928e-05\n",
            "Loss: 1.2047705e-05\n",
            "Loss: 1.2045316e-05\n",
            "Loss: 1.2039667e-05\n",
            "Loss: 1.2035953e-05\n",
            "Loss: 1.2031137e-05\n",
            "Loss: 1.2024349e-05\n",
            "Loss: 1.2017083e-05\n",
            "Loss: 1.2027153e-05\n",
            "Loss: 1.2011785e-05\n",
            "Loss: 1.2003791e-05\n",
            "Loss: 1.20018185e-05\n",
            "Loss: 1.1996658e-05\n",
            "Loss: 1.1994627e-05\n",
            "Loss: 1.1987844e-05\n",
            "Loss: 1.1979858e-05\n",
            "Loss: 1.1975044e-05\n",
            "Loss: 1.197219e-05\n",
            "Loss: 1.1965879e-05\n",
            "Loss: 1.1957285e-05\n",
            "Loss: 1.2575167e-05\n",
            "Loss: 1.1956498e-05\n",
            "Loss: 1.1949276e-05\n",
            "Loss: 1.1945058e-05\n",
            "Loss: 1.20421955e-05\n",
            "Loss: 1.1945365e-05\n",
            "Loss: 1.1944941e-05\n",
            "Loss: 1.1943928e-05\n",
            "Loss: 1.19418655e-05\n",
            "Loss: 1.1939253e-05\n",
            "Loss: 1.1936879e-05\n",
            "Loss: 1.1933481e-05\n",
            "Loss: 1.192959e-05\n",
            "Loss: 1.1925405e-05\n",
            "Loss: 1.1922165e-05\n",
            "Loss: 1.1919406e-05\n",
            "Loss: 1.1917667e-05\n",
            "Loss: 1.1916078e-05\n",
            "Loss: 1.1914278e-05\n",
            "Loss: 1.1912952e-05\n",
            "Loss: 1.1915341e-05\n",
            "Loss: 1.1912537e-05\n",
            "Loss: 1.191118e-05\n",
            "Loss: 1.1907829e-05\n",
            "Loss: 1.1903338e-05\n",
            "Loss: 1.1899642e-05\n",
            "Loss: 1.18937205e-05\n",
            "Loss: 1.1890337e-05\n",
            "Loss: 1.1887288e-05\n",
            "Loss: 1.1886262e-05\n",
            "Loss: 1.1884601e-05\n",
            "Loss: 1.1884284e-05\n",
            "Loss: 1.1880027e-05\n",
            "Loss: 1.1880392e-05\n",
            "Loss: 1.1877968e-05\n",
            "Loss: 1.1874626e-05\n",
            "Loss: 1.1900495e-05\n",
            "Loss: 1.1871158e-05\n",
            "Loss: 1.1869312e-05\n",
            "Loss: 1.1875015e-05\n",
            "Loss: 1.1862788e-05\n",
            "Loss: 1.18497865e-05\n",
            "Loss: 1.1841588e-05\n",
            "Loss: 1.1838243e-05\n",
            "Loss: 1.1825611e-05\n",
            "Loss: 1.181952e-05\n",
            "Loss: 1.180813e-05\n",
            "Loss: 1.1805106e-05\n",
            "Loss: 1.1828185e-05\n",
            "Loss: 1.1800903e-05\n",
            "Loss: 1.1797085e-05\n",
            "Loss: 1.1791369e-05\n",
            "Loss: 1.1789868e-05\n",
            "Loss: 1.1785002e-05\n",
            "Loss: 1.1832198e-05\n",
            "Loss: 1.1782744e-05\n",
            "Loss: 1.1777408e-05\n",
            "Loss: 1.1769095e-05\n",
            "Loss: 1.1759497e-05\n",
            "Loss: 1.1752611e-05\n",
            "Loss: 1.1744345e-05\n",
            "Loss: 1.1731738e-05\n",
            "Loss: 1.1722559e-05\n",
            "Loss: 1.1717133e-05\n",
            "Loss: 1.1714816e-05\n",
            "Loss: 1.2765512e-05\n",
            "Loss: 1.171445e-05\n",
            "Loss: 1.1713191e-05\n",
            "Loss: 1.1710128e-05\n",
            "Loss: 1.1708694e-05\n",
            "Loss: 1.1707392e-05\n",
            "Loss: 1.1702952e-05\n",
            "Loss: 1.1697819e-05\n",
            "Loss: 1.1695301e-05\n",
            "Loss: 1.1693339e-05\n",
            "Loss: 1.169965e-05\n",
            "Loss: 1.1693089e-05\n",
            "Loss: 1.1690498e-05\n",
            "Loss: 1.168395e-05\n",
            "Loss: 1.1675176e-05\n",
            "Loss: 1.1678798e-05\n",
            "Loss: 1.1672095e-05\n",
            "Loss: 1.1667133e-05\n",
            "Loss: 1.1664168e-05\n",
            "Loss: 1.166317e-05\n",
            "Loss: 1.16588735e-05\n",
            "Loss: 1.16509145e-05\n",
            "Loss: 1.16443925e-05\n",
            "Loss: 1.1636766e-05\n",
            "Loss: 1.1635438e-05\n",
            "Loss: 1.1627504e-05\n",
            "Loss: 1.1621536e-05\n",
            "Loss: 1.1615143e-05\n",
            "Loss: 1.1607094e-05\n",
            "Loss: 1.1622079e-05\n",
            "Loss: 1.1604737e-05\n",
            "Loss: 1.1597093e-05\n",
            "Loss: 1.1592984e-05\n",
            "Loss: 1.1587934e-05\n",
            "Loss: 1.15805e-05\n",
            "Loss: 1.157167e-05\n",
            "Loss: 1.1564156e-05\n",
            "Loss: 1.1559876e-05\n",
            "Loss: 1.15548355e-05\n",
            "Loss: 1.1577109e-05\n",
            "Loss: 1.1553238e-05\n",
            "Loss: 1.1549453e-05\n",
            "Loss: 1.1543482e-05\n",
            "Loss: 1.153801e-05\n",
            "Loss: 1.1530474e-05\n",
            "Loss: 1.1523457e-05\n",
            "Loss: 1.1517757e-05\n",
            "Loss: 1.1513239e-05\n",
            "Loss: 1.1506813e-05\n",
            "Loss: 1.1500281e-05\n",
            "Loss: 1.1494513e-05\n",
            "Loss: 1.1490269e-05\n",
            "Loss: 1.148647e-05\n",
            "Loss: 1.1486159e-05\n",
            "Loss: 1.1485476e-05\n",
            "Loss: 1.1482894e-05\n",
            "Loss: 1.1482059e-05\n",
            "Loss: 1.1479427e-05\n",
            "Loss: 1.1478115e-05\n",
            "Loss: 1.1533564e-05\n",
            "Loss: 1.1477259e-05\n",
            "Loss: 1.1476111e-05\n",
            "Loss: 1.1474981e-05\n",
            "Loss: 1.1474148e-05\n",
            "Loss: 1.1473019e-05\n",
            "Loss: 1.1472566e-05\n",
            "Loss: 1.1473123e-05\n",
            "Loss: 1.1473441e-05\n",
            "Loss: 1.1472566e-05\n",
            "Loss: 1.1471247e-05\n",
            "Loss: 1.1469154e-05\n",
            "Loss: 1.1465108e-05\n",
            "Loss: 1.1514285e-05\n",
            "Loss: 1.1464303e-05\n",
            "Loss: 1.146026e-05\n",
            "Loss: 1.1455491e-05\n",
            "Loss: 1.1488947e-05\n",
            "Loss: 1.1454322e-05\n",
            "Loss: 1.1453629e-05\n",
            "Loss: 1.1449678e-05\n",
            "Loss: 1.1445597e-05\n",
            "Loss: 1.1440437e-05\n",
            "Loss: 1.1436093e-05\n",
            "Loss: 1.1454887e-05\n",
            "Loss: 1.1433184e-05\n",
            "Loss: 1.14271015e-05\n",
            "Loss: 1.1421268e-05\n",
            "Loss: 1.1430969e-05\n",
            "Loss: 1.1420216e-05\n",
            "Loss: 1.1417771e-05\n",
            "Loss: 1.1413961e-05\n",
            "Loss: 1.1410077e-05\n",
            "Loss: 1.1407638e-05\n",
            "Loss: 1.1407727e-05\n",
            "Loss: 1.1406675e-05\n",
            "Loss: 1.1403625e-05\n",
            "Loss: 1.1398344e-05\n",
            "Loss: 1.1395911e-05\n",
            "Loss: 1.1391562e-05\n",
            "Loss: 1.1390645e-05\n",
            "Loss: 1.13879005e-05\n",
            "Loss: 1.1384136e-05\n",
            "Loss: 1.137778e-05\n",
            "Loss: 1.13759725e-05\n",
            "Loss: 1.1366118e-05\n",
            "Loss: 1.1363798e-05\n",
            "Loss: 1.1361706e-05\n",
            "Loss: 1.13576025e-05\n",
            "Loss: 1.1351077e-05\n",
            "Loss: 1.134918e-05\n",
            "Loss: 1.1351528e-05\n",
            "Loss: 1.134697e-05\n",
            "Loss: 1.1341291e-05\n",
            "Loss: 1.13355e-05\n",
            "Loss: 1.1327773e-05\n",
            "Loss: 1.133456e-05\n",
            "Loss: 1.1326766e-05\n",
            "Loss: 1.133024e-05\n",
            "Loss: 1.13199785e-05\n",
            "Loss: 1.13119095e-05\n",
            "Loss: 1.1306985e-05\n",
            "Loss: 1.1303696e-05\n",
            "Loss: 1.1298344e-05\n",
            "Loss: 1.1294567e-05\n",
            "Loss: 1.1290352e-05\n",
            "Loss: 1.1287431e-05\n",
            "Loss: 1.1283478e-05\n",
            "Loss: 1.127774e-05\n",
            "Loss: 1.1268218e-05\n",
            "Loss: 1.1259905e-05\n",
            "Loss: 1.1254228e-05\n",
            "Loss: 1.125231e-05\n",
            "Loss: 1.1250336e-05\n",
            "Loss: 1.1248365e-05\n",
            "Loss: 1.1248042e-05\n",
            "Loss: 1.1245289e-05\n",
            "Loss: 1.1242503e-05\n",
            "Loss: 1.1239897e-05\n",
            "Loss: 1.1238256e-05\n",
            "Loss: 1.1238099e-05\n",
            "Loss: 1.123591e-05\n",
            "Loss: 1.1234585e-05\n",
            "Loss: 1.1233994e-05\n",
            "Loss: 1.123178e-05\n",
            "Loss: 1.1230211e-05\n",
            "Loss: 1.1227485e-05\n",
            "Loss: 1.12221505e-05\n",
            "Loss: 1.1214883e-05\n",
            "Loss: 1.137302e-05\n",
            "Loss: 1.1212601e-05\n",
            "Loss: 1.1201923e-05\n",
            "Loss: 1.1205421e-05\n",
            "Loss: 1.1197312e-05\n",
            "Loss: 1.1189379e-05\n",
            "Loss: 1.1178371e-05\n",
            "Loss: 1.1202168e-05\n",
            "Loss: 1.117749e-05\n",
            "Loss: 1.1170563e-05\n",
            "Loss: 1.116444e-05\n",
            "Loss: 1.1157073e-05\n",
            "Loss: 1.1315605e-05\n",
            "Loss: 1.1156295e-05\n",
            "Loss: 1.1151561e-05\n",
            "Loss: 1.1147252e-05\n",
            "Loss: 1.1145372e-05\n",
            "Loss: 1.1142463e-05\n",
            "Loss: 1.1138817e-05\n",
            "Loss: 1.113377e-05\n",
            "Loss: 1.1130255e-05\n",
            "Loss: 1.1126174e-05\n",
            "Loss: 1.1123948e-05\n",
            "Loss: 1.1129395e-05\n",
            "Loss: 1.1115321e-05\n",
            "Loss: 1.110581e-05\n",
            "Loss: 1.1100216e-05\n",
            "Loss: 1.1095282e-05\n",
            "Loss: 1.1092074e-05\n",
            "Loss: 1.1103297e-05\n",
            "Loss: 1.1090895e-05\n",
            "Loss: 1.1087375e-05\n",
            "Loss: 1.1083501e-05\n",
            "Loss: 1.1092757e-05\n",
            "Loss: 1.1080807e-05\n",
            "Loss: 1.1078736e-05\n",
            "Loss: 1.1077276e-05\n",
            "Loss: 1.1076096e-05\n",
            "Loss: 1.1073467e-05\n",
            "Loss: 1.1069955e-05\n",
            "Loss: 1.1063345e-05\n",
            "Loss: 1.1058084e-05\n",
            "Loss: 1.10524325e-05\n",
            "Loss: 1.1050676e-05\n",
            "Loss: 1.1048389e-05\n",
            "Loss: 1.1047146e-05\n",
            "Loss: 1.1040131e-05\n",
            "Loss: 1.1038708e-05\n",
            "Loss: 1.1034699e-05\n",
            "Loss: 1.1032097e-05\n",
            "Loss: 1.1031707e-05\n",
            "Loss: 1.1027097e-05\n",
            "Loss: 1.11519985e-05\n",
            "Loss: 1.1025364e-05\n",
            "Loss: 1.1023969e-05\n",
            "Loss: 1.1020947e-05\n",
            "Loss: 1.10172905e-05\n",
            "Loss: 1.1011234e-05\n",
            "Loss: 1.10051005e-05\n",
            "Loss: 1.1039269e-05\n",
            "Loss: 1.1002639e-05\n",
            "Loss: 1.09974535e-05\n",
            "Loss: 1.099486e-05\n",
            "Loss: 1.0992134e-05\n",
            "Loss: 1.09900575e-05\n",
            "Loss: 1.0986454e-05\n",
            "Loss: 1.0984078e-05\n",
            "Loss: 1.0981358e-05\n",
            "Loss: 1.0976131e-05\n",
            "Loss: 1.0966389e-05\n",
            "Loss: 1.1042695e-05\n",
            "Loss: 1.0962688e-05\n",
            "Loss: 1.09548655e-05\n",
            "Loss: 1.0939033e-05\n",
            "Loss: 1.0934466e-05\n",
            "Loss: 1.0927696e-05\n",
            "Loss: 1.0921067e-05\n",
            "Loss: 1.0914723e-05\n",
            "Loss: 1.09073535e-05\n",
            "Loss: 1.0901832e-05\n",
            "Loss: 1.0896869e-05\n",
            "Loss: 1.08933455e-05\n",
            "Loss: 1.0888873e-05\n",
            "Loss: 1.0885587e-05\n",
            "Loss: 1.0879453e-05\n",
            "Loss: 1.0874584e-05\n",
            "Loss: 1.0869577e-05\n",
            "Loss: 1.0863947e-05\n",
            "Loss: 1.086153e-05\n",
            "Loss: 1.0856717e-05\n",
            "Loss: 1.087978e-05\n",
            "Loss: 1.0855156e-05\n",
            "Loss: 1.0851147e-05\n",
            "Loss: 1.0850097e-05\n",
            "Loss: 1.084801e-05\n",
            "Loss: 1.0845826e-05\n",
            "Loss: 1.0842355e-05\n",
            "Loss: 1.0838161e-05\n",
            "Loss: 1.0835533e-05\n",
            "Loss: 1.0833414e-05\n",
            "Loss: 1.0844748e-05\n",
            "Loss: 1.0828889e-05\n",
            "Loss: 1.0825546e-05\n",
            "Loss: 1.0819843e-05\n",
            "Loss: 1.0838858e-05\n",
            "Loss: 1.0817133e-05\n",
            "Loss: 1.0812713e-05\n",
            "Loss: 1.0808734e-05\n",
            "Loss: 1.0807168e-05\n",
            "Loss: 1.080608e-05\n",
            "Loss: 1.08046725e-05\n",
            "Loss: 1.0825763e-05\n",
            "Loss: 1.080382e-05\n",
            "Loss: 1.0802252e-05\n",
            "Loss: 1.0799001e-05\n",
            "Loss: 1.0794993e-05\n",
            "Loss: 1.07909955e-05\n",
            "Loss: 1.0784727e-05\n",
            "Loss: 1.0809495e-05\n",
            "Loss: 1.0781794e-05\n",
            "Loss: 1.0775233e-05\n",
            "Loss: 1.076719e-05\n",
            "Loss: 1.076185e-05\n",
            "Loss: 1.0753143e-05\n",
            "Loss: 1.0779574e-05\n",
            "Loss: 1.0748705e-05\n",
            "Loss: 1.0742753e-05\n",
            "Loss: 1.0736849e-05\n",
            "Loss: 1.0731854e-05\n",
            "Loss: 1.0721279e-05\n",
            "Loss: 1.0722246e-05\n",
            "Loss: 1.071609e-05\n",
            "Loss: 1.0714522e-05\n",
            "Loss: 1.070408e-05\n",
            "Loss: 1.0699371e-05\n",
            "Loss: 1.0692476e-05\n",
            "Loss: 1.0720317e-05\n",
            "Loss: 1.0691382e-05\n",
            "Loss: 1.0685413e-05\n",
            "Loss: 1.0678556e-05\n",
            "Loss: 1.0676949e-05\n",
            "Loss: 1.0668756e-05\n",
            "Loss: 1.0664227e-05\n",
            "Loss: 1.0658459e-05\n",
            "Loss: 1.0652454e-05\n",
            "Loss: 1.0648182e-05\n",
            "Loss: 1.0679739e-05\n",
            "Loss: 1.0645258e-05\n",
            "Loss: 1.0641987e-05\n",
            "Loss: 1.0637343e-05\n",
            "Loss: 1.0634708e-05\n",
            "Loss: 1.0628864e-05\n",
            "Loss: 1.22600695e-05\n",
            "Loss: 1.0628684e-05\n",
            "Loss: 1.0623658e-05\n",
            "Loss: 1.0617773e-05\n",
            "Loss: 1.0613899e-05\n",
            "Loss: 1.0599798e-05\n",
            "Loss: 1.0593454e-05\n",
            "Loss: 1.0585587e-05\n",
            "Loss: 1.0580311e-05\n",
            "Loss: 1.0574873e-05\n",
            "Loss: 1.0570637e-05\n",
            "Loss: 1.0568801e-05\n",
            "Loss: 1.0565815e-05\n",
            "Loss: 1.0563578e-05\n",
            "Loss: 1.0560512e-05\n",
            "Loss: 1.0582963e-05\n",
            "Loss: 1.0558518e-05\n",
            "Loss: 1.0556997e-05\n",
            "Loss: 1.05552845e-05\n",
            "Loss: 1.05518275e-05\n",
            "Loss: 1.0546812e-05\n",
            "Loss: 1.056054e-05\n",
            "Loss: 1.0546054e-05\n",
            "Loss: 1.0541372e-05\n",
            "Loss: 1.05392355e-05\n",
            "Loss: 1.0538362e-05\n",
            "Loss: 1.05362105e-05\n",
            "Loss: 1.0533341e-05\n",
            "Loss: 1.0528548e-05\n",
            "Loss: 1.0526294e-05\n",
            "Loss: 1.0523479e-05\n",
            "Loss: 1.0521906e-05\n",
            "Loss: 1.051924e-05\n",
            "Loss: 1.0529195e-05\n",
            "Loss: 1.0517823e-05\n",
            "Loss: 1.05152285e-05\n",
            "Loss: 1.0510736e-05\n",
            "Loss: 1.0507792e-05\n",
            "Loss: 1.0503057e-05\n",
            "Loss: 1.0503461e-05\n",
            "Loss: 1.04982055e-05\n",
            "Loss: 1.0490079e-05\n",
            "Loss: 1.0484214e-05\n",
            "Loss: 1.0479691e-05\n",
            "Loss: 1.0475219e-05\n",
            "Loss: 1.0467589e-05\n",
            "Loss: 1.045648e-05\n",
            "Loss: 1.0438505e-05\n",
            "Loss: 1.0431925e-05\n",
            "Loss: 1.0415815e-05\n",
            "Loss: 1.0405789e-05\n",
            "Loss: 1.0395439e-05\n",
            "Loss: 1.0388849e-05\n",
            "Loss: 1.0382503e-05\n",
            "Loss: 1.0373409e-05\n",
            "Loss: 1.0368609e-05\n",
            "Loss: 1.0364552e-05\n",
            "Loss: 1.0359779e-05\n",
            "Loss: 1.0354921e-05\n",
            "Loss: 1.0341211e-05\n",
            "Loss: 1.0873094e-05\n",
            "Loss: 1.0338494e-05\n",
            "Loss: 1.03271195e-05\n",
            "Loss: 1.0319893e-05\n",
            "Loss: 1.0311598e-05\n",
            "Loss: 1.0308057e-05\n",
            "Loss: 1.0303713e-05\n",
            "Loss: 1.0298531e-05\n",
            "Loss: 1.0289691e-05\n",
            "Loss: 1.02833665e-05\n",
            "Loss: 1.0275214e-05\n",
            "Loss: 1.0316526e-05\n",
            "Loss: 1.0274235e-05\n",
            "Loss: 1.0267464e-05\n",
            "Loss: 1.026108e-05\n",
            "Loss: 1.0256002e-05\n",
            "Loss: 1.0244129e-05\n",
            "Loss: 1.0236856e-05\n",
            "Loss: 1.02257445e-05\n",
            "Loss: 1.0223188e-05\n",
            "Loss: 1.021178e-05\n",
            "Loss: 1.0203373e-05\n",
            "Loss: 1.0195563e-05\n",
            "Loss: 1.0188746e-05\n",
            "Loss: 1.0184568e-05\n",
            "Loss: 1.0183064e-05\n",
            "Loss: 1.01771975e-05\n",
            "Loss: 1.0166867e-05\n",
            "Loss: 1.0160908e-05\n",
            "Loss: 1.0155445e-05\n",
            "Loss: 1.0143549e-05\n",
            "Loss: 1.0133288e-05\n",
            "Loss: 1.0120374e-05\n",
            "Loss: 1.0107208e-05\n",
            "Loss: 1.0099547e-05\n",
            "Loss: 1.00857005e-05\n",
            "Loss: 1.0076221e-05\n",
            "Loss: 1.0073749e-05\n",
            "Loss: 1.0056185e-05\n",
            "Loss: 1.00464695e-05\n",
            "Loss: 1.0031184e-05\n",
            "Loss: 1.0020139e-05\n",
            "Loss: 1.00018115e-05\n",
            "Loss: 9.983845e-06\n",
            "Loss: 9.970777e-06\n",
            "Loss: 1.01916785e-05\n",
            "Loss: 9.96892e-06\n",
            "Loss: 9.964068e-06\n",
            "Loss: 9.961442e-06\n",
            "Loss: 9.95502e-06\n",
            "Loss: 9.94979e-06\n",
            "Loss: 9.944804e-06\n",
            "Loss: 9.945592e-06\n",
            "Loss: 9.936935e-06\n",
            "Loss: 9.931839e-06\n",
            "Loss: 9.937754e-06\n",
            "Loss: 9.930547e-06\n",
            "Loss: 9.927448e-06\n",
            "Loss: 9.922028e-06\n",
            "Loss: 9.913608e-06\n",
            "Loss: 9.907676e-06\n",
            "Loss: 9.912836e-06\n",
            "Loss: 9.905595e-06\n",
            "Loss: 9.902754e-06\n",
            "Loss: 9.900691e-06\n",
            "Loss: 9.893342e-06\n",
            "Loss: 9.8838755e-06\n",
            "Loss: 9.8926e-06\n",
            "Loss: 9.880315e-06\n",
            "Loss: 9.875732e-06\n",
            "Loss: 9.864843e-06\n",
            "Loss: 9.85645e-06\n",
            "Loss: 9.841306e-06\n",
            "Loss: 9.821662e-06\n",
            "Loss: 9.808267e-06\n",
            "Loss: 9.810646e-06\n",
            "Loss: 9.800641e-06\n",
            "Loss: 9.793993e-06\n",
            "Loss: 9.783479e-06\n",
            "Loss: 9.784455e-06\n",
            "Loss: 9.774267e-06\n",
            "Loss: 9.763489e-06\n",
            "Loss: 9.784812e-06\n",
            "Loss: 9.7570055e-06\n",
            "Loss: 9.743484e-06\n",
            "Loss: 9.733522e-06\n",
            "Loss: 9.72084e-06\n",
            "Loss: 9.713221e-06\n",
            "Loss: 9.706226e-06\n",
            "Loss: 9.696563e-06\n",
            "Loss: 9.689877e-06\n",
            "Loss: 9.682449e-06\n",
            "Loss: 9.672226e-06\n",
            "Loss: 9.659023e-06\n",
            "Loss: 9.644237e-06\n",
            "Loss: 9.62873e-06\n",
            "Loss: 9.617163e-06\n",
            "Loss: 9.610371e-06\n",
            "Loss: 9.605102e-06\n",
            "Loss: 9.601465e-06\n",
            "Loss: 9.594931e-06\n",
            "Loss: 9.5886435e-06\n",
            "Loss: 9.579588e-06\n",
            "Loss: 9.591025e-06\n",
            "Loss: 9.576114e-06\n",
            "Loss: 9.574693e-06\n",
            "Loss: 9.57115e-06\n",
            "Loss: 9.569381e-06\n",
            "Loss: 9.5674895e-06\n",
            "Loss: 9.564202e-06\n",
            "Loss: 9.560886e-06\n",
            "Loss: 9.556815e-06\n",
            "Loss: 9.553092e-06\n",
            "Loss: 9.550582e-06\n",
            "Loss: 9.54612e-06\n",
            "Loss: 9.54016e-06\n",
            "Loss: 9.536772e-06\n",
            "Loss: 9.607694e-06\n",
            "Loss: 9.532522e-06\n",
            "Loss: 9.528966e-06\n",
            "Loss: 9.525648e-06\n",
            "Loss: 9.524156e-06\n",
            "Loss: 9.520848e-06\n",
            "Loss: 9.515408e-06\n",
            "Loss: 9.517028e-06\n",
            "Loss: 9.513615e-06\n",
            "Loss: 9.507242e-06\n",
            "Loss: 9.504282e-06\n",
            "Loss: 9.500707e-06\n",
            "Loss: 9.494688e-06\n",
            "Loss: 9.488767e-06\n",
            "Loss: 9.482508e-06\n",
            "Loss: 9.473722e-06\n",
            "Loss: 9.460042e-06\n",
            "Loss: 9.450354e-06\n",
            "Loss: 9.437608e-06\n",
            "Loss: 9.434005e-06\n",
            "Loss: 9.427555e-06\n",
            "Loss: 9.425617e-06\n",
            "Loss: 9.420101e-06\n",
            "Loss: 9.4151455e-06\n",
            "Loss: 9.409607e-06\n",
            "Loss: 9.405417e-06\n",
            "Loss: 9.401714e-06\n",
            "Loss: 9.396007e-06\n",
            "Loss: 9.389236e-06\n",
            "Loss: 9.381488e-06\n",
            "Loss: 9.3785475e-06\n",
            "Loss: 9.373426e-06\n",
            "Loss: 9.370175e-06\n",
            "Loss: 9.36267e-06\n",
            "Loss: 9.486882e-06\n",
            "Loss: 9.361673e-06\n",
            "Loss: 9.356875e-06\n",
            "Loss: 9.351307e-06\n",
            "Loss: 9.344358e-06\n",
            "Loss: 9.340132e-06\n",
            "Loss: 9.334552e-06\n",
            "Loss: 9.33243e-06\n",
            "Loss: 9.33025e-06\n",
            "Loss: 9.328245e-06\n",
            "Loss: 9.326196e-06\n",
            "Loss: 9.324578e-06\n",
            "Loss: 9.320018e-06\n",
            "Loss: 9.33099e-06\n",
            "Loss: 9.318818e-06\n",
            "Loss: 9.316792e-06\n",
            "Loss: 9.312716e-06\n",
            "Loss: 9.3094295e-06\n",
            "Loss: 9.342621e-06\n",
            "Loss: 9.3094595e-06\n",
            "Loss: 9.308909e-06\n",
            "Loss: 9.3058625e-06\n",
            "Loss: 9.302798e-06\n",
            "Loss: 9.301357e-06\n",
            "Loss: 9.2960545e-06\n",
            "Loss: 9.294713e-06\n",
            "Loss: 9.290564e-06\n",
            "Loss: 9.287575e-06\n",
            "Loss: 9.281774e-06\n",
            "Loss: 9.340308e-06\n",
            "Loss: 9.2801365e-06\n",
            "Loss: 9.272217e-06\n",
            "Loss: 9.267368e-06\n",
            "Loss: 9.26477e-06\n",
            "Loss: 9.260244e-06\n",
            "Loss: 9.254572e-06\n",
            "Loss: 9.249271e-06\n",
            "Loss: 9.243697e-06\n",
            "Loss: 9.241039e-06\n",
            "Loss: 9.2854625e-06\n",
            "Loss: 9.234575e-06\n",
            "Loss: 9.225627e-06\n",
            "Loss: 9.216984e-06\n",
            "Loss: 9.240396e-06\n",
            "Loss: 9.213866e-06\n",
            "Loss: 9.209201e-06\n",
            "Loss: 1.07029455e-05\n",
            "Loss: 9.207752e-06\n",
            "Loss: 9.202738e-06\n",
            "Loss: 9.196323e-06\n",
            "Loss: 9.188729e-06\n",
            "Loss: 9.180046e-06\n",
            "Loss: 9.170946e-06\n",
            "Loss: 9.165397e-06\n",
            "Loss: 9.160514e-06\n",
            "Loss: 9.151033e-06\n",
            "Loss: 9.143998e-06\n",
            "Loss: 9.146377e-06\n",
            "Loss: 9.140202e-06\n",
            "Loss: 9.135934e-06\n",
            "Loss: 9.130031e-06\n",
            "Loss: 9.123323e-06\n",
            "Loss: 9.113009e-06\n",
            "Loss: 9.103022e-06\n",
            "Loss: 9.097593e-06\n",
            "Loss: 9.091228e-06\n",
            "Loss: 9.08586e-06\n",
            "Loss: 9.0811145e-06\n",
            "Loss: 9.069191e-06\n",
            "Loss: 9.41248e-06\n",
            "Loss: 9.066498e-06\n",
            "Loss: 9.05906e-06\n",
            "Loss: 9.052443e-06\n",
            "Loss: 9.048867e-06\n",
            "Loss: 9.046702e-06\n",
            "Loss: 9.044874e-06\n",
            "Loss: 9.094216e-06\n",
            "Loss: 9.040569e-06\n",
            "Loss: 9.0349995e-06\n",
            "Loss: 9.0334615e-06\n",
            "Loss: 9.026518e-06\n",
            "Loss: 9.016025e-06\n",
            "Loss: 9.011001e-06\n",
            "Loss: 8.995939e-06\n",
            "Loss: 8.986705e-06\n",
            "Loss: 8.979539e-06\n",
            "Loss: 8.975434e-06\n",
            "Loss: 8.9717005e-06\n",
            "Loss: 8.968329e-06\n",
            "Loss: 8.987506e-06\n",
            "Loss: 8.967467e-06\n",
            "Loss: 8.966001e-06\n",
            "Loss: 8.965376e-06\n",
            "Loss: 8.962983e-06\n",
            "Loss: 8.961536e-06\n",
            "Loss: 8.989713e-06\n",
            "Loss: 8.960211e-06\n",
            "Loss: 8.957874e-06\n",
            "Loss: 8.952971e-06\n",
            "Loss: 8.944036e-06\n",
            "Loss: 8.940903e-06\n",
            "Loss: 8.937285e-06\n",
            "Loss: 8.928842e-06\n",
            "Loss: 8.926983e-06\n",
            "Loss: 8.9232835e-06\n",
            "Loss: 8.917921e-06\n",
            "Loss: 8.91566e-06\n",
            "Loss: 8.912679e-06\n",
            "Loss: 8.9086725e-06\n",
            "Loss: 8.905578e-06\n",
            "Loss: 8.902839e-06\n",
            "Loss: 8.900726e-06\n",
            "Loss: 8.896452e-06\n",
            "Loss: 8.893299e-06\n",
            "Loss: 8.889893e-06\n",
            "Loss: 8.990944e-06\n",
            "Loss: 8.887049e-06\n",
            "Loss: 8.884092e-06\n",
            "Loss: 8.879557e-06\n",
            "Loss: 8.876853e-06\n",
            "Loss: 8.868933e-06\n",
            "Loss: 8.8628085e-06\n",
            "Loss: 8.857221e-06\n",
            "Loss: 8.855835e-06\n",
            "Loss: 8.853541e-06\n",
            "Loss: 8.851722e-06\n",
            "Loss: 8.850575e-06\n",
            "Loss: 8.864229e-06\n",
            "Loss: 8.850398e-06\n",
            "Loss: 8.849675e-06\n",
            "Loss: 8.847095e-06\n",
            "Loss: 8.845535e-06\n",
            "Loss: 8.843305e-06\n",
            "Loss: 8.841018e-06\n",
            "Loss: 8.836072e-06\n",
            "Loss: 8.9550895e-06\n",
            "Loss: 8.834025e-06\n",
            "Loss: 8.831712e-06\n",
            "Loss: 8.827729e-06\n",
            "Loss: 8.826105e-06\n",
            "Loss: 8.824708e-06\n",
            "Loss: 8.822438e-06\n",
            "Loss: 8.820525e-06\n",
            "Loss: 8.853325e-06\n",
            "Loss: 8.818469e-06\n",
            "Loss: 8.814996e-06\n",
            "Loss: 8.809237e-06\n",
            "Loss: 8.904924e-06\n",
            "Loss: 8.807213e-06\n",
            "Loss: 8.804267e-06\n",
            "Loss: 8.801633e-06\n",
            "Loss: 8.796906e-06\n",
            "Loss: 8.791386e-06\n",
            "Loss: 8.828222e-06\n",
            "Loss: 8.789666e-06\n",
            "Loss: 8.7836725e-06\n",
            "Loss: 8.774379e-06\n",
            "Loss: 8.770557e-06\n",
            "Loss: 8.766673e-06\n",
            "Loss: 8.7634835e-06\n",
            "Loss: 8.7605185e-06\n",
            "Loss: 8.7565695e-06\n",
            "Loss: 9.442644e-06\n",
            "Loss: 8.756895e-06\n",
            "Loss: 8.756391e-06\n",
            "Loss: 8.754562e-06\n",
            "Loss: 8.756463e-06\n",
            "Loss: 8.7529015e-06\n",
            "Loss: 8.769578e-06\n",
            "Loss: 8.750157e-06\n",
            "Loss: 8.748587e-06\n",
            "Loss: 8.743359e-06\n",
            "Loss: 8.738207e-06\n",
            "Loss: 8.731934e-06\n",
            "Loss: 8.736823e-06\n",
            "Loss: 8.7261715e-06\n",
            "Loss: 8.721648e-06\n",
            "Loss: 8.718286e-06\n",
            "Loss: 8.726775e-06\n",
            "Loss: 8.717698e-06\n",
            "Loss: 8.715325e-06\n",
            "Loss: 8.709854e-06\n",
            "Loss: 8.706817e-06\n",
            "Loss: 8.704737e-06\n",
            "Loss: 8.700188e-06\n",
            "Loss: 8.697687e-06\n",
            "Loss: 8.694861e-06\n",
            "Loss: 8.69206e-06\n",
            "Loss: 8.6885475e-06\n",
            "Loss: 8.684372e-06\n",
            "Loss: 8.683467e-06\n",
            "Loss: 8.6746995e-06\n",
            "Loss: 8.673137e-06\n",
            "Loss: 8.669874e-06\n",
            "Loss: 8.665853e-06\n",
            "Loss: 8.657408e-06\n",
            "Loss: 8.667942e-06\n",
            "Loss: 8.655627e-06\n",
            "Loss: 8.643564e-06\n",
            "Loss: 8.637352e-06\n",
            "Loss: 8.632189e-06\n",
            "Loss: 8.630623e-06\n",
            "Loss: 8.628918e-06\n",
            "Loss: 8.627172e-06\n",
            "Loss: 8.625588e-06\n",
            "Loss: 8.623169e-06\n",
            "Loss: 8.6197915e-06\n",
            "Loss: 8.6176515e-06\n",
            "Loss: 8.616262e-06\n",
            "Loss: 8.614471e-06\n",
            "Loss: 8.610284e-06\n",
            "Loss: 8.605394e-06\n",
            "Loss: 8.60174e-06\n",
            "Loss: 9.043006e-06\n",
            "Loss: 8.599721e-06\n",
            "Loss: 8.597573e-06\n",
            "Loss: 8.593997e-06\n",
            "Loss: 8.591553e-06\n",
            "Loss: 8.587485e-06\n",
            "Loss: 8.5944e-06\n",
            "Loss: 8.586331e-06\n",
            "Loss: 8.58395e-06\n",
            "Loss: 8.580996e-06\n",
            "Loss: 9.072474e-06\n",
            "Loss: 8.580189e-06\n",
            "Loss: 8.578131e-06\n",
            "Loss: 8.575985e-06\n",
            "Loss: 8.5739675e-06\n",
            "Loss: 8.571948e-06\n",
            "Loss: 8.574119e-06\n",
            "Loss: 8.571008e-06\n",
            "Loss: 8.569953e-06\n",
            "Loss: 8.567833e-06\n",
            "Loss: 8.566114e-06\n",
            "Loss: 8.57207e-06\n",
            "Loss: 8.564564e-06\n",
            "Loss: 8.561949e-06\n",
            "Loss: 8.56098e-06\n",
            "Loss: 8.556439e-06\n",
            "Loss: 8.554678e-06\n",
            "Loss: 8.553092e-06\n",
            "Loss: 8.547642e-06\n",
            "Loss: 8.543966e-06\n",
            "Loss: 8.537493e-06\n",
            "Loss: 8.53538e-06\n",
            "Loss: 8.533107e-06\n",
            "Loss: 8.531383e-06\n",
            "Loss: 8.5297725e-06\n",
            "Loss: 8.525289e-06\n",
            "Loss: 8.520821e-06\n",
            "Loss: 8.51532e-06\n",
            "Loss: 8.511145e-06\n",
            "Loss: 8.503012e-06\n",
            "Loss: 8.52212e-06\n",
            "Loss: 8.500187e-06\n",
            "Loss: 8.939845e-06\n",
            "Loss: 8.49837e-06\n",
            "Loss: 8.492487e-06\n",
            "Loss: 8.487759e-06\n",
            "Loss: 8.564361e-06\n",
            "Loss: 8.48645e-06\n",
            "Loss: 8.484054e-06\n",
            "Loss: 8.480438e-06\n",
            "Loss: 8.477135e-06\n",
            "Loss: 8.472839e-06\n",
            "Loss: 8.467534e-06\n",
            "Loss: 8.461558e-06\n",
            "Loss: 8.452742e-06\n",
            "Loss: 8.449562e-06\n",
            "Loss: 8.444529e-06\n",
            "Loss: 9.311069e-06\n",
            "Loss: 8.443166e-06\n",
            "Loss: 8.441674e-06\n",
            "Loss: 8.440546e-06\n",
            "Loss: 8.440072e-06\n",
            "Loss: 8.439742e-06\n",
            "Loss: 8.437055e-06\n",
            "Loss: 8.435884e-06\n",
            "Loss: 8.433576e-06\n",
            "Loss: 8.4293315e-06\n",
            "Loss: 8.502591e-06\n",
            "Loss: 8.427364e-06\n",
            "Loss: 8.423852e-06\n",
            "Loss: 8.421923e-06\n",
            "Loss: 8.427966e-06\n",
            "Loss: 8.420585e-06\n",
            "Loss: 8.4196545e-06\n",
            "Loss: 8.414469e-06\n",
            "Loss: 8.420336e-06\n",
            "Loss: 8.413881e-06\n",
            "Loss: 8.410671e-06\n",
            "Loss: 8.406017e-06\n",
            "Loss: 8.399405e-06\n",
            "Loss: 8.386573e-06\n",
            "Loss: 8.392407e-06\n",
            "Loss: 8.383745e-06\n",
            "Loss: 8.378911e-06\n",
            "Loss: 8.3824925e-06\n",
            "Loss: 8.3757295e-06\n",
            "Loss: 8.37467e-06\n",
            "Loss: 8.37212e-06\n",
            "Loss: 8.366853e-06\n",
            "Loss: 8.70538e-06\n",
            "Loss: 8.36436e-06\n",
            "Loss: 8.360429e-06\n",
            "Loss: 8.356539e-06\n",
            "Loss: 8.349462e-06\n",
            "Loss: 8.341044e-06\n",
            "Loss: 8.331383e-06\n",
            "Loss: 8.365443e-06\n",
            "Loss: 8.327673e-06\n",
            "Loss: 8.318816e-06\n",
            "Loss: 8.310545e-06\n",
            "Loss: 8.298027e-06\n",
            "Loss: 8.296887e-06\n",
            "Loss: 8.288338e-06\n",
            "Loss: 8.277419e-06\n",
            "Loss: 8.266774e-06\n",
            "Loss: 8.266359e-06\n",
            "Loss: 8.26374e-06\n",
            "Loss: 8.257051e-06\n",
            "Loss: 8.2518845e-06\n",
            "Loss: 8.243835e-06\n",
            "Loss: 8.235206e-06\n",
            "Loss: 8.228215e-06\n",
            "Loss: 8.214812e-06\n",
            "Loss: 8.204259e-06\n",
            "Loss: 8.194926e-06\n",
            "Loss: 8.185553e-06\n",
            "Loss: 8.182994e-06\n",
            "Loss: 8.180367e-06\n",
            "Loss: 8.177254e-06\n",
            "Loss: 8.190413e-06\n",
            "Loss: 8.176033e-06\n",
            "Loss: 8.174726e-06\n",
            "Loss: 8.172748e-06\n",
            "Loss: 8.17039e-06\n",
            "Loss: 8.16666e-06\n",
            "Loss: 8.163827e-06\n",
            "Loss: 8.1593935e-06\n",
            "Loss: 8.154703e-06\n",
            "Loss: 8.151578e-06\n",
            "Loss: 8.148238e-06\n",
            "Loss: 8.150674e-06\n",
            "Loss: 8.1464295e-06\n",
            "Loss: 8.144459e-06\n",
            "Loss: 8.140939e-06\n",
            "Loss: 8.136676e-06\n",
            "Loss: 8.16375e-06\n",
            "Loss: 8.135284e-06\n",
            "Loss: 8.133151e-06\n",
            "Loss: 8.131013e-06\n",
            "Loss: 8.130775e-06\n",
            "Loss: 8.127762e-06\n",
            "Loss: 8.125461e-06\n",
            "Loss: 8.12219e-06\n",
            "Loss: 8.3020195e-06\n",
            "Loss: 8.122329e-06\n",
            "Loss: 8.122096e-06\n",
            "Loss: 8.120384e-06\n",
            "Loss: 8.118193e-06\n",
            "Loss: 8.115616e-06\n",
            "Loss: 8.114086e-06\n",
            "Loss: 8.112418e-06\n",
            "Loss: 8.109117e-06\n",
            "Loss: 8.106081e-06\n",
            "Loss: 8.0998025e-06\n",
            "Loss: 8.094338e-06\n",
            "Loss: 8.090906e-06\n",
            "Loss: 8.105779e-06\n",
            "Loss: 8.089135e-06\n",
            "Loss: 8.087328e-06\n",
            "Loss: 8.0856735e-06\n",
            "Loss: 8.084243e-06\n",
            "Loss: 8.0828395e-06\n",
            "Loss: 8.081223e-06\n",
            "Loss: 8.078454e-06\n",
            "Loss: 8.0767195e-06\n",
            "Loss: 8.072867e-06\n",
            "Loss: 8.064608e-06\n",
            "Loss: 8.055521e-06\n",
            "Loss: 8.114254e-06\n",
            "Loss: 8.053857e-06\n",
            "Loss: 8.046653e-06\n",
            "Loss: 8.0449945e-06\n",
            "Loss: 8.041767e-06\n",
            "Loss: 8.055528e-06\n",
            "Loss: 8.041831e-06\n",
            "Loss: 8.041794e-06\n",
            "Loss: 8.042119e-06\n",
            "Loss: 8.041599e-06\n",
            "Loss: 8.041801e-06\n",
            "Loss: 8.041599e-06\n",
            "Loss: 1.7725013e-05\n",
            "Loss: 8.040559e-06\n",
            "Loss: 8.039878e-06\n",
            "Loss: 8.0357295e-06\n",
            "Loss: 8.032243e-06\n",
            "Loss: 8.030956e-06\n",
            "Loss: 8.028603e-06\n",
            "Loss: 8.027597e-06\n",
            "Loss: 8.026005e-06\n",
            "Loss: 8.024553e-06\n",
            "Loss: 8.021756e-06\n",
            "Loss: 8.018838e-06\n",
            "Loss: 8.015936e-06\n",
            "Loss: 8.014292e-06\n",
            "Loss: 8.011375e-06\n",
            "Loss: 8.009303e-06\n",
            "Loss: 8.004929e-06\n",
            "Loss: 1.4063838e-05\n",
            "Loss: 8.004286e-06\n",
            "Loss: 8.000678e-06\n",
            "Loss: 7.997703e-06\n",
            "Loss: 7.997116e-06\n",
            "Loss: 7.9960455e-06\n",
            "Loss: 7.9947185e-06\n",
            "Loss: 7.997969e-06\n",
            "Loss: 7.9946385e-06\n",
            "Loss: 7.992884e-06\n",
            "Loss: 7.9909e-06\n",
            "Loss: 7.989934e-06\n",
            "Loss: 7.986441e-06\n",
            "Loss: 7.983194e-06\n",
            "Loss: 7.979062e-06\n",
            "Loss: 7.977885e-06\n",
            "Loss: 7.977618e-06\n",
            "Loss: 7.974766e-06\n",
            "Loss: 7.972182e-06\n",
            "Loss: 7.970185e-06\n",
            "Loss: 7.96866e-06\n",
            "Loss: 7.966607e-06\n",
            "Loss: 7.969059e-06\n",
            "Loss: 7.965939e-06\n",
            "Loss: 7.963934e-06\n",
            "Loss: 7.960346e-06\n",
            "Loss: 7.959091e-06\n",
            "Loss: 7.954673e-06\n",
            "Loss: 7.953533e-06\n",
            "Loss: 7.951688e-06\n",
            "Loss: 7.949087e-06\n",
            "Loss: 8.068797e-06\n",
            "Loss: 7.948015e-06\n",
            "Loss: 7.945039e-06\n",
            "Loss: 7.942322e-06\n",
            "Loss: 7.939845e-06\n",
            "Loss: 7.93925e-06\n",
            "Loss: 7.936768e-06\n",
            "Loss: 7.935277e-06\n",
            "Loss: 7.932958e-06\n",
            "Loss: 7.9322335e-06\n",
            "Loss: 7.928479e-06\n",
            "Loss: 7.965962e-06\n",
            "Loss: 7.928089e-06\n",
            "Loss: 7.925572e-06\n",
            "Loss: 7.924666e-06\n",
            "Loss: 7.923275e-06\n",
            "Loss: 7.920776e-06\n",
            "Loss: 7.917971e-06\n",
            "Loss: 7.915819e-06\n",
            "Loss: 7.913281e-06\n",
            "Loss: 7.913379e-06\n",
            "Loss: 7.913619e-06\n",
            "Loss: 7.913152e-06\n",
            "Loss: 7.9133215e-06\n",
            "Loss: 7.913152e-06\n",
            "Loss: 8.510242e-06\n",
            "Loss: 7.912228e-06\n",
            "Loss: 7.911371e-06\n",
            "Loss: 7.9040665e-06\n",
            "Loss: 7.900772e-06\n",
            "Loss: 7.894446e-06\n",
            "Loss: 7.918514e-06\n",
            "Loss: 7.891957e-06\n",
            "Loss: 7.890711e-06\n",
            "Loss: 7.933031e-06\n",
            "Loss: 7.889196e-06\n",
            "Loss: 7.886716e-06\n",
            "Loss: 7.884274e-06\n",
            "Loss: 7.881922e-06\n",
            "Loss: 7.881937e-06\n",
            "Loss: 7.880012e-06\n",
            "Loss: 7.878389e-06\n",
            "Loss: 7.87402e-06\n",
            "Loss: 7.873304e-06\n",
            "Loss: 7.871013e-06\n",
            "Loss: 7.869895e-06\n",
            "Loss: 7.865461e-06\n",
            "Loss: 7.862525e-06\n",
            "Loss: 7.861542e-06\n",
            "Loss: 7.860991e-06\n",
            "Loss: 7.860169e-06\n",
            "Loss: 7.858552e-06\n",
            "Loss: 7.856438e-06\n",
            "Loss: 7.861871e-06\n",
            "Loss: 7.855287e-06\n",
            "Loss: 7.8525045e-06\n",
            "Loss: 7.848262e-06\n",
            "Loss: 7.845729e-06\n",
            "Loss: 7.844081e-06\n",
            "Loss: 7.842984e-06\n",
            "Loss: 7.839767e-06\n",
            "Loss: 7.837285e-06\n",
            "Loss: 7.83109e-06\n",
            "Loss: 7.826179e-06\n",
            "Loss: 7.822422e-06\n",
            "Loss: 7.819538e-06\n",
            "Loss: 7.819292e-06\n",
            "Loss: 7.813325e-06\n",
            "Loss: 7.808586e-06\n",
            "Loss: 7.802458e-06\n",
            "Loss: 7.818012e-06\n",
            "Loss: 7.800052e-06\n",
            "Loss: 7.809671e-06\n",
            "Loss: 7.7965615e-06\n",
            "Loss: 7.792925e-06\n",
            "Loss: 7.792355e-06\n",
            "Loss: 7.790747e-06\n",
            "Loss: 7.7884915e-06\n",
            "Loss: 7.786619e-06\n",
            "Loss: 7.784615e-06\n",
            "Loss: 7.797342e-06\n",
            "Loss: 7.783437e-06\n",
            "Loss: 7.778696e-06\n",
            "Loss: 7.897078e-06\n",
            "Loss: 7.778051e-06\n",
            "Loss: 7.775501e-06\n",
            "Loss: 7.771741e-06\n",
            "Loss: 7.765164e-06\n",
            "Loss: 7.760666e-06\n",
            "Loss: 7.7557415e-06\n",
            "Loss: 7.752591e-06\n",
            "Loss: 7.7499235e-06\n",
            "Loss: 7.748653e-06\n",
            "Loss: 7.757595e-06\n",
            "Loss: 7.747952e-06\n",
            "Loss: 7.746583e-06\n",
            "Loss: 7.745346e-06\n",
            "Loss: 7.744373e-06\n",
            "Loss: 7.74416e-06\n",
            "Loss: 7.751031e-06\n",
            "Loss: 7.743014e-06\n",
            "Loss: 7.741517e-06\n",
            "Loss: 7.737736e-06\n",
            "Loss: 7.733332e-06\n",
            "Loss: 7.728788e-06\n",
            "Loss: 7.873857e-06\n",
            "Loss: 7.7287605e-06\n",
            "Loss: 7.725699e-06\n",
            "Loss: 7.723123e-06\n",
            "Loss: 7.721273e-06\n",
            "Loss: 7.719836e-06\n",
            "Loss: 7.717228e-06\n",
            "Loss: 7.715232e-06\n",
            "Loss: 8.645934e-06\n",
            "Loss: 7.713652e-06\n",
            "Loss: 7.710311e-06\n",
            "Loss: 7.706393e-06\n",
            "Loss: 7.704573e-06\n",
            "Loss: 7.69931e-06\n",
            "Loss: 7.694359e-06\n",
            "Loss: 7.68756e-06\n",
            "Loss: 7.682438e-06\n",
            "Loss: 7.680244e-06\n",
            "Loss: 7.677657e-06\n",
            "Loss: 7.6745655e-06\n",
            "Loss: 7.671802e-06\n",
            "Loss: 7.667163e-06\n",
            "Loss: 7.6601145e-06\n",
            "Loss: 7.651235e-06\n",
            "Loss: 7.642966e-06\n",
            "Loss: 7.635723e-06\n",
            "Loss: 7.632077e-06\n",
            "Loss: 7.6302895e-06\n",
            "Loss: 7.655219e-06\n",
            "Loss: 7.629986e-06\n",
            "Loss: 7.6291735e-06\n",
            "Loss: 7.627672e-06\n",
            "Loss: 7.627558e-06\n",
            "Loss: 7.6259157e-06\n",
            "Loss: 7.6256165e-06\n",
            "Loss: 7.6259194e-06\n",
            "Loss: 7.6254623e-06\n",
            "Loss: 7.625263e-06\n",
            "Loss: 7.6234055e-06\n",
            "Loss: 7.6220904e-06\n",
            "Loss: 7.6199203e-06\n",
            "Loss: 7.6178826e-06\n",
            "Loss: 7.614313e-06\n",
            "Loss: 7.61041e-06\n",
            "Loss: 7.608535e-06\n",
            "Loss: 7.6081114e-06\n",
            "Loss: 7.6026436e-06\n",
            "Loss: 7.6035903e-06\n",
            "Loss: 7.598991e-06\n",
            "Loss: 7.5976573e-06\n",
            "Loss: 7.5973544e-06\n",
            "Loss: 7.5956145e-06\n",
            "Loss: 7.594681e-06\n",
            "Loss: 7.5934254e-06\n",
            "Loss: 7.5906137e-06\n",
            "Loss: 7.5882613e-06\n",
            "Loss: 7.5849985e-06\n",
            "Loss: 7.663852e-06\n",
            "Loss: 7.584675e-06\n",
            "Loss: 7.582145e-06\n",
            "Loss: 7.5809703e-06\n",
            "Loss: 7.5759085e-06\n",
            "Loss: 7.5726307e-06\n",
            "Loss: 7.571246e-06\n",
            "Loss: 7.5700787e-06\n",
            "Loss: 7.568189e-06\n",
            "Loss: 7.566393e-06\n",
            "Loss: 7.5641683e-06\n",
            "Loss: 7.56207e-06\n",
            "Loss: 7.561073e-06\n",
            "Loss: 7.5604003e-06\n",
            "Loss: 7.557255e-06\n",
            "Loss: 7.5542803e-06\n",
            "Loss: 7.5538655e-06\n",
            "Loss: 7.551379e-06\n",
            "Loss: 7.5451126e-06\n",
            "Loss: 7.5387666e-06\n",
            "Loss: 7.5261487e-06\n",
            "Loss: 7.5891994e-06\n",
            "Loss: 7.523087e-06\n",
            "Loss: 7.5156313e-06\n",
            "Loss: 7.526816e-06\n",
            "Loss: 7.5116495e-06\n",
            "Loss: 7.5091552e-06\n",
            "Loss: 7.503899e-06\n",
            "Loss: 7.500654e-06\n",
            "Loss: 7.4956147e-06\n",
            "Loss: 7.4989766e-06\n",
            "Loss: 7.4935283e-06\n",
            "Loss: 7.48908e-06\n",
            "Loss: 7.4862382e-06\n",
            "Loss: 7.4821164e-06\n",
            "Loss: 7.48809e-06\n",
            "Loss: 7.4800914e-06\n",
            "Loss: 7.4773493e-06\n",
            "Loss: 7.560078e-06\n",
            "Loss: 7.4755844e-06\n",
            "Loss: 7.473251e-06\n",
            "Loss: 7.468042e-06\n",
            "Loss: 7.4642703e-06\n",
            "Loss: 7.460699e-06\n",
            "Loss: 7.4589084e-06\n",
            "Loss: 7.4579148e-06\n",
            "Loss: 7.4569652e-06\n",
            "Loss: 7.453248e-06\n",
            "Loss: 7.451809e-06\n",
            "Loss: 7.451448e-06\n",
            "Loss: 7.4508844e-06\n",
            "Loss: 7.4497234e-06\n",
            "Loss: 7.447779e-06\n",
            "Loss: 7.445123e-06\n",
            "Loss: 7.4405516e-06\n",
            "Loss: 7.4580294e-06\n",
            "Loss: 7.437861e-06\n",
            "Loss: 7.4336513e-06\n",
            "Loss: 7.4299764e-06\n",
            "Loss: 7.4275918e-06\n",
            "Loss: 7.4263485e-06\n",
            "Loss: 7.4263257e-06\n",
            "Loss: 7.424677e-06\n",
            "Loss: 7.423909e-06\n",
            "Loss: 7.422352e-06\n",
            "Loss: 7.4201957e-06\n",
            "Loss: 7.4173113e-06\n",
            "Loss: 7.417493e-06\n",
            "Loss: 7.4172412e-06\n",
            "Loss: 7.4160994e-06\n",
            "Loss: 7.414865e-06\n",
            "Loss: 7.414957e-06\n",
            "Loss: 7.414874e-06\n",
            "Loss: 7.41592e-06\n",
            "Loss: 7.415546e-06\n",
            "Loss: 7.414865e-06\n",
            "Loss: 7.414865e-06\n",
            "Loss: 7.414865e-06\n",
            "Loss: 7.414865e-06\n",
            "Loss: 7.414865e-06\n",
            "Loss: 7.414865e-06\n",
            "Loss: 7.414865e-06\n",
            "Loss: 7.414865e-06\n",
            "Loss: 7.414865e-06\n",
            "Loss: 7.414865e-06\n",
            "Loss: 7.414865e-06\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.000007\n",
            "  Number of iterations: 6725\n",
            "  Number of functions evaluations: 7712\n",
            "Training time: 00:02:01.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYyC2vNbk0rT"
      },
      "source": [
        "# print(loss)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "HFFbY9kiDOpw"
      },
      "source": [
        "###### Prediction ###########\n",
        "u_pred, f_pred = model.predict(X_star)\n",
        "# print(u_pred)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "HU3v3HVWDOp-",
        "outputId": "b4e4af05-2110-465d-e837-ee3212483084",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "print('Error u: %e' % (error_u))\n",
        "# print(Exact.shape)\n",
        "U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error u: 1.905525e-03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend"
        ],
        "id": "1HisA2FODOqI"
      },
      "source": [
        "# print(u_star.shape)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "JLdknnuhDOqQ"
      },
      "source": [
        "# error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "# print('Error u: %e' % (error_u))\n",
        "\n",
        "# # # print(Exact.shape)\n",
        "# # U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
        "# print(U_pred.shape)\n",
        "# U_int_pred = U_pred[0, :]\n",
        "# U_int_exact= Exact[0, :] # Exact[-2, :], 'b-', linewidth=2, label='Exact')\n",
        "# plt.plot(X[0:1, :].T, U_int_pred, 'r--', linewidth=2, label='Predicted')\n",
        "# plt.plot(X[0:1, :].T, U_int_exact, 'b', linewidth=1, label='Exact')\n",
        "# plt.xlabel(\"x\")\n",
        "# plt.ylabel(\"u(t,x)\")\n",
        "# plt.legend(frameon=False, loc='best')\n",
        "# savefig('figures/U_pred_at_t_150s_=_t_new_loss')\n",
        "# print(\"Energy Calculation: \\n\")\n",
        "# Energy_exact = 2*np.pi*np.mean(U_int_exact)\n",
        "# print(\"At t = t Energy (Exact) = \", Energy_exact)\n",
        "# Energy_pred = 2*np.pi*np.mean(U_int_pred)\n",
        "# print(\"At t = t Energy (Pred) = \", Energy_pred)\n",
        "# # energy_error = (Energy_exact - Energy_pred) *(100/Energy_exact)  # from energy conservation law\n",
        "# # print(\"Energy Error:\", energy_error, \"%\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM6-6dzsDOqa",
        "outputId": "4c26c881-b7e0-4c38-c5f3-715a567d79cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## ## Error ###\n",
        "Error = np.abs(Exact - U_pred)\n",
        "# # print(U_pred.shape)\n",
        "# # print(Error.shape)\n",
        "ax = plt.subplot(111)\n",
        "h = plt.imshow(Error, interpolation='nearest',cmap='jet', extent=[t.min(), t.max(), x.min(), x.max()],origin='lower', aspect='auto')\n",
        "# plt.colorbar(h)\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "plt.colorbar(h, cax=cax)\n",
        "ax.set_xlabel('$t$')\n",
        "ax.set_ylabel('$x$')\n",
        "ax.title.set_text('Abs Error Plot')\n",
        "savefig('/content/drive/My Drive/ColabNotebooks/PINN/figures/abs_error')# + str(N_u) + 'N_f=' + str(N_f))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36m_run_checked_subprocess\u001b[0;34m(self, command, tex)\u001b[0m\n\u001b[1;32m    305\u001b[0m                                              \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexcache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                                              stderr=subprocess.STDOUT)\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 356\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1363\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'latex': 'latex'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-da6ca0693feb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'$x$'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Abs Error Plot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/ColabNotebooks/PINN/figures/abs_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# + str(N_u) + 'N_f=' + str(N_f))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/drive/My Drive/ColabNotebooks/PINN/Utilities/plotting.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(filename, crop)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcrop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m#        plt.savefig('{}.pgf'.format(filename), bbox_inches='tight', pad_inches=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}.pdf'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_inches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;31m# plt.savefig('{}.eps'.format(filename), bbox_inches='tight', pad_inches=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                            else suppress())\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2588\u001b[0m                 \u001b[0martists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_title_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxison\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_title_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2536\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m                     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2538\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_window_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymin\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2539\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m                 \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get window extent w/o renderer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    291\u001b[0m         _, lp_h, lp_d = renderer.get_text_width_height_descent(\n\u001b[1;32m    292\u001b[0m             \u001b[0;34m\"lp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             ismath=\"TeX\" if self.get_usetex() else False)\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mmin_dy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlp_h\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlp_d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linespacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/_backend_pdf_ps.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mfontsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_size_in_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             w, h, d = texmanager.get_text_width_height_descent(\n\u001b[0;32m---> 47\u001b[0;31m                 s, fontsize, renderer=self)\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mismath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, tex, fontsize, renderer)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# use dviread.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mdvifile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dvi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mdviread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDvi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdvifile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m72\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdpi_fraction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdvi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdvi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36mmake_dvi\u001b[0;34m(self, tex, fontsize)\u001b[0m\n\u001b[1;32m    338\u001b[0m                 self._run_checked_subprocess(\n\u001b[1;32m    339\u001b[0m                     [\"latex\", \"-interaction=nonstopmode\", \"--halt-on-error\",\n\u001b[0;32m--> 340\u001b[0;31m                      texfile], tex)\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasefile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dvi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36m_run_checked_subprocess\u001b[0;34m(self, command, tex)\u001b[0m\n\u001b[1;32m    308\u001b[0m             raise RuntimeError(\n\u001b[1;32m    309\u001b[0m                 \u001b[0;34m'Failed to process string with tex because {} could not be '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 'found'.format(command[0])) from exc\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to process string with tex because latex could not be found"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Error in callback <function install_repl_displayhook.<locals>.post_execute at 0x7f955b1f0d08> (for post_execute):\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36m_run_checked_subprocess\u001b[0;34m(self, command, tex)\u001b[0m\n\u001b[1;32m    305\u001b[0m                                              \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexcache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                                              stderr=subprocess.STDOUT)\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 356\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1363\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'latex': 'latex'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mpost_execute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mpost_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mdraw_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# IPython >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/_pylab_helpers.py\u001b[0m in \u001b[0;36mdraw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf_mgr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mforce\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mdraw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1945\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3.2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    392\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2588\u001b[0m                 \u001b[0martists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_title_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxison\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_title_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2536\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m                     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2538\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_window_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymin\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2539\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m                 \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get window extent w/o renderer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    291\u001b[0m         _, lp_h, lp_d = renderer.get_text_width_height_descent(\n\u001b[1;32m    292\u001b[0m             \u001b[0;34m\"lp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             ismath=\"TeX\" if self.get_usetex() else False)\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mmin_dy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlp_h\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlp_d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linespacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mfontsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_size_in_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             w, h, d = texmanager.get_text_width_height_descent(\n\u001b[0;32m--> 204\u001b[0;31m                 s, fontsize, renderer=self)\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, tex, fontsize, renderer)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# use dviread.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mdvifile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dvi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mdviread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDvi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdvifile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m72\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdpi_fraction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdvi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdvi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36mmake_dvi\u001b[0;34m(self, tex, fontsize)\u001b[0m\n\u001b[1;32m    338\u001b[0m                 self._run_checked_subprocess(\n\u001b[1;32m    339\u001b[0m                     [\"latex\", \"-interaction=nonstopmode\", \"--halt-on-error\",\n\u001b[0;32m--> 340\u001b[0;31m                      texfile], tex)\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasefile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dvi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36m_run_checked_subprocess\u001b[0;34m(self, command, tex)\u001b[0m\n\u001b[1;32m    308\u001b[0m             raise RuntimeError(\n\u001b[1;32m    309\u001b[0m                 \u001b[0;34m'Failed to process string with tex because {} could not be '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 'found'.format(command[0])) from exc\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to process string with tex because latex could not be found"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36m_run_checked_subprocess\u001b[0;34m(self, command, tex)\u001b[0m\n\u001b[1;32m    305\u001b[0m                                              \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexcache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                                              stderr=subprocess.STDOUT)\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 356\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1363\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'latex': 'latex'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                            else suppress())\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2588\u001b[0m                 \u001b[0martists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_title_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxison\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_title_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2536\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m                     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2538\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_window_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymin\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2539\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m                 \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get window extent w/o renderer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    291\u001b[0m         _, lp_h, lp_d = renderer.get_text_width_height_descent(\n\u001b[1;32m    292\u001b[0m             \u001b[0;34m\"lp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             ismath=\"TeX\" if self.get_usetex() else False)\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mmin_dy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlp_h\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlp_d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linespacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mfontsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_size_in_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             w, h, d = texmanager.get_text_width_height_descent(\n\u001b[0;32m--> 204\u001b[0;31m                 s, fontsize, renderer=self)\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, tex, fontsize, renderer)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# use dviread.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mdvifile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dvi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mdviread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDvi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdvifile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m72\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdpi_fraction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdvi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdvi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36mmake_dvi\u001b[0;34m(self, tex, fontsize)\u001b[0m\n\u001b[1;32m    338\u001b[0m                 self._run_checked_subprocess(\n\u001b[1;32m    339\u001b[0m                     [\"latex\", \"-interaction=nonstopmode\", \"--halt-on-error\",\n\u001b[0;32m--> 340\u001b[0;31m                      texfile], tex)\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasefile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dvi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36m_run_checked_subprocess\u001b[0;34m(self, command, tex)\u001b[0m\n\u001b[1;32m    308\u001b[0m             raise RuntimeError(\n\u001b[1;32m    309\u001b[0m                 \u001b[0;34m'Failed to process string with tex because {} could not be '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 'found'.format(command[0])) from exc\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to process string with tex because latex could not be found"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 388.543x240.133 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q_hYX4cDOqj"
      },
      "source": [
        "# print(t[-1])\n",
        "t_25_percent = int(len(t) * 0.25)\n",
        "t_50_percent = int(len(t) * 0.50)\n",
        "t_75_percent = int(len(t) * 0.75)\n",
        "# print(t_25_percent)\n",
        "# time = float(t[-1])\n",
        "# time = np.around(time, decimals=3)\n",
        "# print(time)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdMSvFJPDOqs"
      },
      "source": [
        "# # ######################################################################\n",
        "# # ############################# Plotting ###############################\n",
        "# # ######################################################################\n",
        "fig, ax = newfig(1.0, 1.1)\n",
        "ax.axis('off')\n",
        "\n",
        "################## Row 0: u(t,x) ##################\n",
        "gs0 = gridspec.GridSpec(1, 2)\n",
        "gs0.update(top=1 - 0.06, bottom=1 - 1 / 3, left=0.15, right=0.85, wspace=0)\n",
        "ax = plt.subplot(gs0[:, :])\n",
        "\n",
        "h = ax.imshow(U_pred.T, interpolation='nearest', cmap='jet',extent=[t.min(), t.max(), x.min(), x.max()],origin='lower', aspect='auto')\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(h, cax=cax)\n",
        "\n",
        "ax.plot(X_u_train[:, 1], X_u_train[:, 0], 'kx', label='Data (%d points)' % (u_train.shape[0]), markersize=4, clip_on=False)\n",
        "\n",
        "line = np.linspace(x.min(), x.max(), 2)[:, None]\n",
        "ax.plot(t[t_25_percent] * np.ones((2, 1)), line, 'w-', linewidth=1)\n",
        "ax.plot(t[t_50_percent] * np.ones((2, 1)), line, 'w-', linewidth=1)\n",
        "ax.plot(t[t_75_percent] * np.ones((2, 1)), line, 'w-', linewidth=1)\n",
        "\n",
        "ax.set_xlabel('$t$')\n",
        "ax.set_ylabel('$x$')\n",
        "ax.legend(frameon=False, loc='best')\n",
        "ax.set_title('$u(t,x)$', fontsize=10)\n",
        "\n",
        "# ####### Row 1: u(t,x) slices ##################\n",
        "gs1 = gridspec.GridSpec(1, 3)\n",
        "gs1.update(top=1 - 1 / 3, bottom=0, left=0.1, right=0.9, wspace=0.5)\n",
        "ax = plt.subplot(gs1[0, 0])\n",
        "ax.plot(x, Exact[t_25_percent, :], 'b-', linewidth=2, label='Exact')\n",
        "ax.plot(x, U_pred[t_25_percent, :], 'r--', linewidth=2, label='Prediction')\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('$u(t,x)$')\n",
        "time = float(t[t_25_percent])\n",
        "time = np.around(time, decimals=3)\n",
        "ax.set_title('$t = $' + str(time), fontsize=10)\n",
        "ax.axis('square')\n",
        "# ax.set_xlim([x.min(), x.max()])\n",
        "# ax.set_ylim([U_pred[t_25_percent, :].min(), U_pred[t_25_percent,:.max()])\n",
        "# ax.set_xlim([-3.5, 3.5])\n",
        "# ax.set_ylim([-1, 2.0])\n",
        "ax.set_xlim([-1.1, 1.1])\n",
        "ax.set_ylim([-1.1, 1.1])\n",
        "\n",
        "ax = plt.subplot(gs1[0, 1])\n",
        "ax.plot(x, Exact[t_50_percent, :], 'b-', linewidth=2, label='Exact')\n",
        "ax.plot(x, U_pred[t_50_percent, :], 'r--', linewidth=2, label='Prediction')\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('$u(t,x)$')\n",
        "time = float(t[t_50_percent])\n",
        "time = np.around(time, decimals=3)\n",
        "ax.set_title('$t = $' + str(time), fontsize=10)\n",
        "ax.axis('square')\n",
        "# ax.set_xlim([x.min(), x.max()])\n",
        "# ax.set_ylim([U_pred[t_50_percent, :].min(), U_pred[t_50_percent, :].max()])\n",
        "# ax.set_xlim([-3.5, 3.5])\n",
        "# ax.set_ylim([-1, 2.0])\n",
        "ax.set_xlim([-1.1, 1.1])\n",
        "ax.set_ylim([-1.1, 1.1])\n",
        "\n",
        "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
        "\n",
        "ax = plt.subplot(gs1[0, 2])\n",
        "ax.plot(x, Exact[t_75_percent, :], 'b-', linewidth=2, label='Exact')\n",
        "ax.plot(x, U_pred[t_75_percent, :], 'r--', linewidth=2, label='Prediction')\n",
        "# ax.plot(x, Exact[-2, :], 'b-', linewidth=2, label='Exact')\n",
        "# ax.plot(x, U_pred[-2, :], 'r--', linewidth=2, label='Prediction')\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('$u(t,x)$')\n",
        "# time = float(t[-2])\n",
        "time = float(t[t_75_percent])\n",
        "time = np.around(time, decimals=3)\n",
        "ax.set_title('$t = $'+ str(time), fontsize=10)\n",
        "ax.axis('square')\n",
        "# ax.set_xlim([-3.5, 3.5])\n",
        "# ax.set_ylim([-1, 2.0])\n",
        "ax.set_xlim([-1.1, 1.1])\n",
        "ax.set_ylim([-1.1, 1.1])\n",
        "# savefig('/content/drive/My Drive/ColabNotebooks/PINN/figures/abs_error')\n",
        "savefig('/content/drive/My Drive/ColabNotebooks/PINN/figures/Burgers_shock_new_arch=_new_loss' + str(N_u) + 'N_f=' + str(N_f))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaDHj_NOIAtJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}